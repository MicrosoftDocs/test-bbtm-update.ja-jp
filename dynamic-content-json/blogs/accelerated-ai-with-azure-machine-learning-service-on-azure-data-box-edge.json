{
    "Slug": "accelerated-ai-with-azure-machine-learning-service-on-azure-data-box-edge",
    "Title": "Azure Data Box Edge Azure Machine Learning サービスを使用した高速 AI",
    "Summary": "Along with the general availability of Azure Data Box Edge that was announced today, we are announcing the preview of Azure Machine Learning hardware accelerated models on Data Box Edge. ",
    "Content": "<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ecff20db-356d-4ef1-a5c2-390e9de7f18b.png\"><img alt=\"FPGA acceleration at the edge\" border=\"0\" height=\"625\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7d729155-a005-4089-a19e-989b3f30be97.png\" style=\"border: 0px currentcolor; border-image: none; display: inline; background-image: none;\" title=\"エッジでの FPGA アクセラレーション\" width=\"2000\"></a></p>\n\n<p><a href=\"https://aka.ms/AnnouncingDataBoxEdgeGA\" target=\"_blank\">本日発表された</a> <a href=\"https://docs.microsoft.com/en-us/azure/databox-online/data-box-edge-overview\" target=\"_blank\">Azure Data Box Edge</a> の一般提供に加え、Data Box Edge 上の brainwave Projectを活用したAzure Machine Learningハードウェア 高速化モデル&nbsp;のプレビューをお知らせします。 実際のアプリケーションのワールド&rsquo; データの大部分がエッジで使用されます。 たとえば、工場、小売店、病院から収集された画像やビデオは、製造の欠陥分析、在庫切れの検出、診断に使用されます。 Data Box Edge 上のデータに機械学習モデルを適用すると、待機時間が短縮され、帯域幅コストが削減される一方で、ビジネス上の重要な意思決定に対するリアルタイムの分析情報と迅速なアクションが可能になります。</p>\n\n<p>Azure Machine Learning サービスは、既に一般公開されているエンド ツー エンドのエンタープライズ レベルの準拠データ サイエンス プラットフォームです。 Azure Machine Learning サービスを使用すると、データ サイエンティストは機械学習モデルの構築、トレーニング、デプロイを簡素化および高速化できます。 これらの機能はすべて、PyTorch、TensorFlow、scikit-learn などの最新のオープンソース フレームワークを使用して、お気に入りの Python 環境からアクセスできます。 これらのモデルは現在、CPU と GPU で実行できますが、このプレビューでは、Data Box Edge のフィールド プログラマブル ゲート アレイ (FPGA) に拡張されています。</p>\n\n<h2>このプレビューの内容</h2>\n\n<p>このプレビューでは、イメージ分類シナリオ用に TensorFlow モデルをトレーニングし、Docker コンテナーにモデルをコンテナー化し、Azure IoT Hubを使用して Data Box Edge デバイスにコンテナーをデプロイできるようにすることで、Azure Machine Learning サービスを強化します。 現在、ResNet 50、ResNet 152、DenseNet-121、VGG-16 がサポートされています。 このモデルは、すべての Data Box Edge に含まれる Intel Arria 10 FPGA の ONNX ランタイムによって高速化されます。</p>\n\n<h2>なぜこれが重要なのでしょうか。</h2>\n\n<p>長年にわたり、AI は私たちの日常生活と業界に注ぎ込まれています。 スマート ホーム アシスタントは、私たちの言うことを理解し、ソーシャル メディア サービスは、アップロードした画像の誰&rsquo;にタグを付けることができます。 すべてではないにしても、ほとんどの場合、これはディープ ニューラル ネットワーク (DNN) を利用します。これは、画像、音声、テキストなどの非構造化データを処理する高度なアルゴリズムです。 DNN も計算コストが高くなります。 たとえば、人気のある DNN である ResNet 50 を使用して 1 つの画像を分析するには、約 80 億の計算が必要です。</p>\n\n<p>現在、DNN を実行するハードウェア オプションは数多くあり、CPU と GPU でよく使用されています。 Azure Machine Learningサービスは、FPGA と呼ばれる再構成可能なハードウェアで DNN を実行するために、Microsoft Research (この最近の<a href=\"https://www.fastcompany.com/90305091/this-is-microsofts-ai-pipeline-from-research-to-reality\" target=\"_blank\">ファースト カンパニーの記事</a>で取り上げられる) に由来する最先端のイノベーションをお客様に提供します。 この機能と <a href=\"https://azure.microsoft.com/en-us/blog/onnx-runtime-for-inferencing-machine-learning-models-now-in-preview/\" target=\"_blank\">ONNX ランタイムを Azure Machine Learning サービスに</a>統合することで、モデルの待機時間が大幅に向上します。</p>\n\n<h2>まとめる</h2>\n\n<p>Azure Machine Learningサービスによって、高速 AI モデルの機能が Data Box Edge に直接提供されるようになりました。 カメラが開発のさまざまな段階で製品を撮影している製造組立ラインシナリオの例を見てみましょう&rsquo;。</p>\n\n<p>画像は製造ラインから工場内の Data Box Edge に送信されます。ここで、ai モデルは、Azure Machine Learning サービスを使用してトレーニング、コンテナー化、FPGA にデプロイされます。 Data Box Edge はAzure IoT Hubに登録されるため、デプロイするモデルを制御できます。 これで、製造上の欠陥を検出するために、受信画像をほぼリアルタイムで処理するために必要なものがすべて揃いました。 これにより、機械と組立ラインマネージャーは、製品に関する時間の影響を受けやすい意思決定を行い、製品の品質を向上させ、下流の生産コストを削減することができます。</p>\n\n<h2>プレビューに参加する</h2>\n\n<p><a href=\"https://azure.microsoft.com/en-us/services/machine-learning-service/\" target=\"_blank\">Azure Machine Learningサービス</a>は現在一般公開されています。 ハードウェア高速化 AI モデルのコンテナー化のプレビューに参加するには、 <a href=\"https://aka.ms/AccelerateAI\" target=\"_blank\">要求フォームに記入</a> し、 <a href=\"https://aka.ms/aml-forum-service\" target=\"_blank\">フォーラムでサポートを受けてください</a>。</p>\n"
}