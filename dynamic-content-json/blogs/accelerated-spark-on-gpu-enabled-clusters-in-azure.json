{
    "Slug": "accelerated-spark-on-gpu-enabled-clusters-in-azure",
    "Title": "Azure での GPU 対応クラスターでの高速 Spark",
    "Summary": "AZTK lets you to provision on-demand GPU enabled Spark clusters on top of Azure Batch's infrastructure, helping you take your high-performance GPU code and distribute it across your Spark cluster.",
    "Content": "<p>GPU 対応クラスターで Spark を実行する機能は、ビッグ データとハイ パフォーマンス コンピューティング (HPC) テクノロジの独自のコンバージェンスを示しています。 過去数年間で、世界中の企業が AI やその他の HPC ワークフローをビジネスに統合するにつれて、GPU 市場が爆発的に広がったことが&#39;。 数値計算やニューラル ネットワークに GPU を利用するように設計されたフレームワークである Tensorflow は、AI の台頭とその結果として GPU の需要の証となり、人気が急上昇しました。 同時に、何百もの企業がペタバイト範囲でデータを収集し始めるにつれて、ビッグ データと強力なデータ処理エンジンの必要性はかつてないほど高くなっています。</p>\n\n<p>SPARK などのビッグ データ エンジンを使用して GPU などのハイ パフォーマンス ハードウェアのインフラストラクチャを提供することで、データ サイエンティストやデータ エンジニアは、実現が困難な多くのシナリオを実現できます。</p>\n\n<p><a href=\"https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-gpu\" target=\"_blank\">最新の GPU SKU の最近</a>のリリースと共に、<a href=\"https://github.com/Azure/aztk/\" target=\"_blank\">Azure Distributed Data Engineering Toolkit (AZTK)</a> を使用した GPU 対応クラスターでの Spark の実行がサポートされていることを共有&#39;。 AZTK では、1 つのコマンドで、Azure Batch&#39;のインフラストラクチャの上にオンデマンドの GPU 対応 Spark クラスターをプロビジョニングできるため、通常は単一ノードのみの高パフォーマンスの実装を実行し、Spark クラスター全体に分散できます。</p>\n\n<p>このリリースでは、Anaconda、Jupyter、PySpark にパッケージ化された Python イメージ、および Tidyverse、RStudio-Server、SparklyR でパッケージ化された R イメージなど、AZTK 用の GPU 対応 Docker イメージをいくつか追加で作成しました。</p>\n\n<ul>\n    <li><a href=\"https://hub.docker.com/r/aztk/gpu/\" target=\"_blank\">Aztk/gpu:spark2.2.0</a></li>\n    <li><a href=\"https://hub.docker.com/r/aztk/python/\" target=\"_blank\">Aztk/python:spark2.2.0-python3.6.2-gpu</a></li>\n    <li><a href=\"https://hub.docker.com/r/aztk/r-base\">aztk/r-base:spark2.1.0-r3.4.1-gpu</a></li>\n</ul>\n\n<p>これらのイメージは <a href=\"https://github.com/NVIDIA/nvidia-docker\" target=\"_blank\">、NVIDIA Docker Engine</a> を使用して、ホスト&#39;GPU への Docker イメージ アクセスを提供します。 AZTK は完全にコンテナー化された方法で Spark を実行するため、ユーザーは特定のニーズに合わせて独自の GPU Docker イメージをカスタマイズできます。 ただし、GPU 対応クラスターで Spark を実行するだけのユーザーは、Docker についても心配する必要なく実行できます。 AZTK は適切なイメージを自動的にプルし、ホスト コンピューターで GPU が検出された場合に GPU アクセスを提供します。</p>\n\n<p>ここでは&#39;、AZTK を使用して 4 ノード GPU 対応 Spark クラスター (合計 224 GB、1 つの GPU = 1/2 K80 カード、24 vCPU) を作成する方法の例を示します。</p>\n\n<pre class=\"prettyprint\">\n$ aztk spark cluster create --id my_gpu_cluster --size 4 --vm-size standard_nc6</pre>\n\n<p>AZTK は、Standard NC6 VM に NVIDIA&#39;Tesla K80s が付属していることを認識しているため、AZTK はクラスターのプロビジョニング時に GPU 対応の Docker イメージの 1 つを自動的に選択します。 または、--docker-repo フラグを設定して、使用するイメージを手動で指定することもできます。</p>\n\n<p>また、GPU と Numba を使用する <a href=\"https://github.com/Azure/aztk/blob/master/node_scripts/jupyter-samples/GPU%2Bvs%2BCPU%2Busing%2BNumba.ipynb\" target=\"_blank\">単純な PySpark ジョブ</a> と CPU の使用を比較して、GPU で Spark ジョブを実行するときに得られるパフォーマンスの向上を強調するサンプルも提供します。</p>\n\n<p>Tensoflow/Tensorframes、分散 CTNK などの AI ワークフローに SPARK と GPU を使用する場合でも、計算コストの高い Spark ジョブを高速化するために使用する場合でも、HPC テクノロジとビッグ データ テクノロジのこの独自のコンバージェンスを利用する方法についてお知らせください。</p>\n\n<p>私たちは、これらの機能を使用して、あなたのフィードバックを聞いてあなたを楽しみにしています。 フィードバックについては、お問い合わせいただく <a href=\"mailto:askaztk@microsoft.com\">askaztk@microsoft.com</a> か、 <a href=\"https://www.github.com/Azure/aztk\" target=\"_blank\">GitHub リポジトリ</a>に投稿してください。</p>\n\n<h3>関連情報</h3>\n\n<ul>\n    <li><a href=\"https://www.github.com/azure/aztk\" target=\"_blank\">Azure Distributed Data Engineering Toolkit (AZTK)</a> のダウンロードと使用を開始する</li>\n    <li><a href=\"https://www.github.com/Azure/thunderbolt/issues\" target=\"_blank\">GitHub を使用して問題を送信</a>してください</li>\n</ul>\n\n<h3>その他のリソース</h3>\n\n<ul>\n    <li>Azure 分散データ エンジニアリング <a href=\"https://www.github.com/Azure/thunderbolt/issues\" target=\"_blank\">Toolkit</a>で使用される基になる Azure サービスAzure Batchを参照してください。</li>\n    <li><a href=\"https://azure.microsoft.com/en-us/solutions/high-performance-computing\" target=\"_blank\">Azure でのより汎用的な HPC</a></li>\n</ul>\n"
}