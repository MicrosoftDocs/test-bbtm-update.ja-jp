{
    "Slug": "an-introduction-to-live-encoding-with-azure-media-services",
    "Title": "Azure Media Servicesを使用したライブ エンコードの概要",
    "Summary": "In this blog, I will provide an overview of this Live Encoding feature, which adds the following capabilities to Azure Media Services.",
    "Content": "<div style=\"background:#eee;border:1px solid #ccc;padding:5px 10px;\"><strong>2019 年 4 月 19 日に更新: </strong>Azure Media Servicesは、この 2015 年のブログ記事から進化しています。 サービスの現在の機能については、ドキュメント、&ldquo;<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-streaming-overview\">Azure Media Services v3</a>&rdquo; と<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-events-outputs-concept\">ライブ イベント</a>と&ldquo;ライブ出力を使用したライブ ストリーミングを参照してください。&rdquo;特に、サポートされている形式、コーデック、および入力プロトコルに関する以下のセクションは、その後更新されています。</div>\n\n<p>昨年Azure Media Servicesライブ ストリーミングのリリース以降、配信者が何百万人もの顧客にライブ イベントを配信するために何度も使用してきたのと同じ、瞬時にスケーラブルで常に利用可能なストリーミング ソリューションにアクセスできるようになりました。 <a href=\"https://azure.microsoft.com/blog/2014/09/10/getting-started-with-live-streaming-using-the-azure-management-portal/\" target=\"_blank\">Azure 管理ポータル</a>または <a href=\"https://azure.microsoft.com/blog/2014/11/04/getting-started-with-live-streaming-using-the-media-services-sdk-2/\" target=\"_blank\">.NET SDK</a> を使用してライブ イベントを管理する方法と、<a href=\"https://azure.microsoft.com/blog/2014/09/18/azure-media-services-rtmp-support-and-live-encoders/\" target=\"_blank\">ライブ フィードを生成</a>する方法について、同僚&rsquo;のブログを読んでいるかもしれません。&nbsp;ただし、以前は、ライブ ストリーミングを使用するには、オンプレミス エンコーダーを使用してアダプティブ ビットレート ビデオ ストリームを生成し、クラウドにプッシュする必要がありました。 ライブ エンコードのプレビュー リリースでは、代わりに単一ビットレートのライブ フィードをAzure Media Servicesに送信し、アダプティブ ビットレート ストリームにエンコードし、MPEG-DASH、Microsoft Smooth Streaming、Apple HLS、Adobe HDS 形式で配信するさまざまなクライアントに配信できます。 このブログでは、次の機能をAzure Media Servicesに追加するこのライブ エンコード機能の概要について説明します。</p>\n\n<ul>\n <li>アダプティブ ビットレート ストリームへのシングル ビットレート ライブ フィードのライブ エンコード</li>\n <li>RTP プロトコル (MPEG トランスポート ストリーム)、RTMP、Smooth Streaming 経由でライブ フィードを取り込む機能</li>\n <li>スレートの挿入を制御し、クライアントへの広告の挿入を通知する機能</li>\n <li>ライブ フィードのサムネイル プレビューを取得する機能</li>\n</ul>\n\n<h2>ライブ エンコードとは</h2>\n\n<p>ライブ イベントをストリーミングする場合の目標は&nbsp; 、さまざまなネットワーク条件下で、顧客が持つことができるすべてのデバイスに高品質のビデオを配信することです。 品質とネットワークの状態の問題には、 <a href=\"https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming\" target=\"_blank\">アダプティブ ビットレート ストリーミング</a>という解決策があります。 また、複数のデバイス (およびその機能) の問題の解決策は、動的パッケージ化などの再 <a href=\"https://go.microsoft.com/fwlink/?linkid=276874\" target=\"_blank\">パッケージ</a>化システムです。 アダプティブ ビットレート ストリーミングは、ビデオを異なる解像度とビットレートで複数のビデオ ストリームにエンコードし、同期を維持することで機能します。 さらに、ライブ イベントの場合は、受信ビデオをリアルタイムで処理することで、管理可能な数までの待機時間を維持する必要があります。 このリアルタイム ビデオ圧縮はライブ エンコードであり、多くのコンピューティング サイクルが必要です。 ライブ イベントをストリーミングするために、高速 CPU (GPU アクセラレーション) を備えたハードウェア ボックスを見ています。 さらに、複数の (6 から 10 の) ビデオ ストリームを生成しています。つまり、それらのストリームをCDNに取得するために多くの帯域幅が&nbsp;必要になり、その後、顧客にイベントを配信できます。 インフラストラクチャのコストは、このようなインフラストラクチャの問題に対処するクラウドベースのワークフローであるAzure Media Servicesで Live Encoding を追加&hellip;し始めます。 この機能を使用すると、単一の (高品質の) ビデオ フィードを Azure データ センターに送信するだけで済み、サービスは、アダプティブ ビットレート ストリームにエンコードするコンピューティング集中型の作業を処理します。 つまり、リモートの場所からライブ イベントを実行できます (優れた高速 WiFi またはモバイル ネットワークに対してのみ料金を支払う)、カメラに組み込まれているエンコーダー、またはより少ない電力を必要とする低コスト (無料でも) エンコーダー。 当社のサービスは即座にスケーラブルです。つまり、イベントスケジュールの急増を処理して、使用した分だけ支払うことができます。</p>\n\n<h2>ライブ エンコード操作方法使用しますか?</h2>\n\n<p>ライブ エンコードは、次の手順でライブ イベントを配信するように設定できます。</p>\n\n<ol>\n <li>入力ライブ フィードに使用するプロトコルを決定します (下記のセクションを参照)。</li>\n <li>API または Azure 管理ポータルを使用してライブ チャネルを作成し、ライブ エンコードのニーズを満たす設定を選択します</li>\n <li>単一 (高品質) のビデオ フィードで送信するようにオンプレミス エンコーダーを設定する</li>\n <li>Azure 管理ポータルを使用して出力ストリームをプレビューする</li>\n <li>イベントを管理するプログラム <a href=\"https://azure.microsoft.com/en-us/documentation/articles/media-services-manage-channels-overview/\" target=\"_blank\">を作成する</a></li>\n</ol>\n\n<p>注: API の詳細と構成手順については、今後のブログ記事を参照してください。</p>\n\n<h2>サポートされている形式とコーデック</h2>\n\n<p>ライブ エンコードでサポートされる入力プロトコルは、RTMP、RTP (MPEG TS)、Smooth Streaming です。 ビデオが MPEG-2 (最大 422 プロファイル) または H.264 (最大高 422 プロファイル) でエンコードされているライブ フィードで送信でき、オーディオは AAC-LC (最大 7.1 チャンネル)、または Dolby&reg; Digital/AC-3 (最大 7.1 チャンネル) または MPEG オーディオ (レイヤー II と III、ステレオまで) でエンコードされます。 Live Encoder では、4:2:2 から 4:2:0 までの彩度サブサンプリングとインターレース解除、オーディオ チャンネルダウンミックス、オーディオリサンプリング、オーディオダイナミック レンジ圧縮がサポートされています。 出力では、Live Encoder はビデオを H.264 (最大高 4:2:0 プログレッシブ) にエンコードし、オーディオからステレオまたはモノラル チャネル AAC (LC、HE v1、HE v2 プロファイル) にエンコードできます。 Live Encoder は、入力ビデオ フィードに存在する場合は、EIA/CEA-708 クローズド キャプションのパススルーもサポートします。 シグナリング アドバタイズの場合、Live Encoder は API 呼び出しを介した入力をサポートします。または、input プロトコルが RTP の場合&nbsp;は、in-bandSCTE-35&nbsp; SpliceInsert コマンドと TimeSignal コマンドがサポートされます。 出力では、サービスは HLS プレイリスト タグ (SCTE-67)、Smooth Streaming Sparse Tracks (SCTE-35)、HDS CueInfo 要素を出力できます。</p>\n\n<h2>取り込みプロトコルの選択</h2>\n\n<p>次のいずれかを使用して、入力ライブ フィードをチャネルに送信できます。</p>\n\n<ol>\n <li>RTMP: 最も一般的なシナリオでは、入力フィードをオープン インターネット経由で近くの Azure データ センターに送信したり、カメラに組み込まれているエンコーダーを使用したり、Telestream Wirecast、Flash Media Live Encoder、Tricaster などのツール&nbsp; を使用したりできます。</li>\n <li>RTP: プロの放送業者向けに提供され、Elemental Technologies、Ericsson、Ateme&nbsp;、Envivio などのベンダーのオンプレミス ライブ エンコーダーを使用します。&nbsp;入力ストリームは通常、IT 部門と&nbsp;連携して設定され、Microsoft <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\">Azure ExpressRoute</a> などのプライベート/専用ネットワークを使用します</li>\n <li>HTTP 経由のスムーズ ストリーミング: 通常&nbsp;、Elemental Technologies、Ericsson、Ateme、&nbsp;Envivio などのベンダーからのオンプレミスライブ エンコーダーで使用&nbsp;されます。通常、オープン インターネット経由で入力ストリームを近くの Azure データ センターに送信できます。</li>\n</ol>\n\n<h2>RTMP の使用に関する注意事項</h2>\n\n<p>RTMP 経由でチャネルにライブ フィードを送信する場合、次の制約が適用されます。</p>\n\n<ol>\n <li>最大 1080p30 の解像度で H.264 でエンコードされたビデオと、AAC-LC でエンコードされたステレオ オーディオ</li>\n <li>オーディオ サンプリング レートは 44.1 kHz にする必要があります</li>\n <li>閉じた GOP および CBR モードのエンコードが推奨されます</li>\n <li>使用可能な帯域幅は、ビデオとオーディオの合計ビットレートを超える必要があります</li>\n</ol>\n\n<h2>RTP の使用に関する注意事項</h2>\n\n<p>RTP を使用してライブ ストリームで送信する予定の場合は、ネットワーク接続から次のものが必要です。</p>\n\n<ol>\n <li>高スループット (入力ストリームのビットレートの最大 1.5 倍)。 高い帯域幅は高プロファイル イベント中にのみ必要になる場合がありますが、1 年中は必要ないため、ネットワークに対する選択により、コストを削減するために帯域幅コミットメントを簡単に変更できる必要があります</li>\n <li>traceroute によって報告される約 10 ~ 15 ホップの低待機時間 (150 ミリ秒未満)</li>\n <li>QoS と&nbsp;利用可能性に関する SLA</li>\n</ol>\n\n<p>推奨される 2 つの方法を以下に示します。 選択したオプションに関係なく、階層 1 ネットワーク プロバイダーを使用する必要があります。 階層 1 のネットワーク プロバイダーの一覧 <a href=\"https://en.wikipedia.org/wiki/Tier_1_network\">については、こちらを参照してください</a>。</p>\n\n<h2>パブリック インターネットおよび Border GatewayProtocol&nbsp; (BGP) ピアリング経由の&nbsp; RTP</h2>\n\n<p>パブリック インターネット経由の RTP と、Microsoft Azure ネットワークでの BGP ピアリングを使用できます。 この場合、高速 IP (HSIP) とも呼ばれるインターネット容量は、1 つ以上のネットワーク プロバイダーによって提供されます。 ビデオ データはパブリック インターネットを経由し、ネットワーク プロバイダー&rsquo;のインターネット IP エッジと Microsoft Azure ネットワーク間のクロス接続が必要です。 この併置場所は、ネットワーク プロバイダーと Microsoft に依存し、 <a href=\"https://www.peeringdb.com/\" target=\"_blank\">PeeringDB</a> から見つけることができます。 ネットワーク プロバイダーは、業界標準の SLA を使用して Azure へのインターネット配信サービスを担当します。 これは、現在の <a href=\"https://news.microsoft.com/2014/02/06/nbc-olympics-production-of-the-2014-olympic-winter-games-to-utilize-microsoft-for-live-and-on-demand-streaming/\">NBC スポーツ/ソチ オリンピック ソリューション</a>で使用したアプローチであり、ネットワーク コストが低くなることがよくあります。</p>\n\n<h2>プライベート/専用ネットワーク経由の RTP</h2>\n\n<p>専用プライベート ネットワーク経由で (ビデオ固有のデータではなく) 一般的なデータ転送用に設計されたネットワーク ソリューションを使用できます。 多くの場合、このオプションは、ネットワーク プロバイダーのマネージド サービス パッケージを通じて提供されます。 必要なのは、パッケージで提供されるサービスのサブセットのみです。 このようなマネージド サービスの利点は、エンド ツー エンドの配信が提供され、強化された SLA で管理される点です。 このカテゴリには、次の 2 種類のサービスがあります。</p>\n\n<ol>\n <li>ネットワーク サービス プロバイダー (NSP) または Exchange プロバイダー (Azure <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\">ExpressRoute</a> + レベル 3 クラウド Connect ソリューション、&nbsp;<a href=\"https://www.equinix.com/services/interconnection-connectivity/cloud-exchange/\">Azure ExpressRoute + Equinix Cloud など) 経由の Microsoft Azure ExpressRoute Exchange</a></li>\n <li><a href=\"https://www.level3.com/en/products/vyvx-solutions/\">レベル 3 VYVX ソリューション</a>など、ネットワーク プロバイダーによって提供されるマネージド ビデオ サービス</li>\n</ol>\n\n<p>&nbsp; RTP 経由でライブ フィードを送信する場合、使用される一般的な転送中エンコード/コンテナーとプロトコルは次のとおりです。</p>\n\n<ul>\n <li>エンコード: H264/AAC</li>\n <li>コンテナー形式: MPEG-2 TS</li>\n <li>ネットワーク プロトコル &ndash; アプリケーション 層: RTP ユニキャスト</li>\n <li>ネットワーク プロトコル &ndash; トランスポート層: UDP</li>\n</ul>\n\n<h2>スレートとシグナリング アドバタイズの使用</h2>\n\n<p>Live Encoding が有効なチャネルがある場合、パイプライン内のコンポーネントでビデオを処理し、操作することができます。 このサービスでは、チャネルで送信アダプティブ ビットレート ストリームにスレートや広告信号を挿入できます。 スレートは静止画像で、(コマーシャルの時間など) 特定のケースで入力ライブ フィードに被せるために使用できます。 広告信号は、名前が示すように、送信ストリームに埋め込む時間同期信号であり、ビデオ プレーヤーに対して、適切なタイミングで広告に切り替えるなどの特別なアクション &ndash; を実行するように指示します。 このために使用する SCTE-35 信号メカニズムの概要については、こちらの<a href=\"https://codesequoia.wordpress.com/2014/02/24/understanding-scte-35/\" target=\"_blank\">ブログ</a>をご覧ください。 ライブ イベントに実装できる一般的なシナリオを次に示します (サンプル コードと API の詳細は、今後のブログ記事で入手できます)。</p>\n\n<ol>\n <li>イベントが開始される前に、閲覧者に事前イベント 画像を取得してもらう</li>\n <li>イベント終了後に視聴者に POST-EVENT 画像を取得させる</li>\n <li>イベント中に問題が発生した場合は、視聴者に ERROR-EVENT イメージを取得させます (例: スタジアムの電源障害)</li>\n <li>AD-BREAK イメージを送信して、商用の中断中にライブ イベント フィードを非表示にする</li>\n</ol>\n\n<h2>ライブ フィードの縮小表示プレビューを取得する</h2>\n\n<p>Live Encoding が有効な場合は、ライブ フィードがチャネルに到達するとそのプレビューを取得できます。 これは、ライブ フィードがチャネルに実際に到達しているかどうかを確認するための重要なツールとなります。 API を使用してサムネイルにアクセスできます。</p>\n\n<h2>まとめ</h2>\n\n<p>このブログでは、Azure Media Servicesのライブエンコード機能について紹介しました。 今後数日間で、Azure 管理ポータルを使用してライブ エンコードを使用&nbsp;する、入力ライブ フィードを生成するための&nbsp;オンプレミス エンコーダーの構成&nbsp;、スレートと広告の制御方法など、トピックに関する投稿が増える予定です。 それまでの間に、この機能について質問がある場合は、お問い合わせください <a href=\"mailto:AMSLiveD@microsoft.com\">AMSLiveD@microsoft.com</a></p>\n"
}