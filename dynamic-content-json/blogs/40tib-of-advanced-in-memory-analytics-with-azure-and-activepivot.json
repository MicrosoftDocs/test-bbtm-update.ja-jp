{
    "Slug": "40tib-of-advanced-in-memory-analytics-with-azure-and-activepivot",
    "Title": "Azure と ActivePivot を使用した高度なメモリ内分析の 40TiB",
    "Summary": "In-memory computing has accelerated the big compute capabilities and enabled customers to extend its experience beyond just the monte carlo simulation and into the analytics.  This blog will look to explore the new possibilities of a scale out architecture for in-memory analytics in Azure through ActivePivot.",
    "Content": "<p>インメモリ コンピューティングは、大規模なコンピューティング機能を高速化し、お客様のエクスペリエンスをモンテカルロ シミュレーションだけでなく分析にまで拡張できるようになりました。 これは、ビジネス ユーザーが事前に設定されたレポートから離れて、代わりにデータを直接操作することを望む Financial Services 内の注意事項です。&nbsp;Azure を使用すると、銀行はリアルタイムで分析し、&nbsp;日中に適切な意思決定を行い、規制基準を満たすためにより多くの設備を備えることができます。 このブログでは、ActivePivot を使用した Azure のメモリ内分析のためのスケールアウト アーキテクチャの新しい可能性について説明します。 ActivePivot は、ビッグ コンピューティングとビッグ データを近づける ActiveViam プラットフォームの一部です。</p>\n\n<p>ActivePivot は、増分処理、トランザクション処理、分析処理を通じて大量の高速移動データを集計して、顧客が短時間で適切な意思決定を行えるようにするメモリ内データベースです。 ActivePivot は、事前集計を必要とせずにすぐに更新されるデータの高度なメトリックを計算し、顧客は数百のディメンションにわたるメトリックを探索し、最も詳細なレベルでライブ データを分析し、比類のない速度で What-If シミュレーションを実行できます。</p>\n\n<p>このオンプレミスを有効にするため、十分なメモリを備えた購入サーバーはコストがかかり、ミッション クリティカルなワークロードのために保存されることがよくあります。&nbsp;ただし、パブリック クラウドでは、調査と実験のためのワークロードが増えるまでこれを開き、このシナリオを Azure に持ち込むのは魅力的です。&nbsp;Azure BLOB ストレージを使用して、一定期間&nbsp;にわたって生成された履歴データセットを収集して格納すると、ユーザー&nbsp;がコンピューティングを必要とするときにのみコンピューティングを使用できます。 ゼロから 30 分未満で完全にデプロイされるまで、総保有コストが大幅に削減され、ビジネスの機敏性が大幅に向上します。</p>\n\n<p>テストでは、400 日間の履歴データをまとめて処理し、15 分で 128 ノード クラスターに 40 TB を読み込み、10 秒未満で 200Bn レコードを照会する方法を示しました。 このためには、32 コア、448GiB の RAM を持つ G5 インスタンスを使用し、Java と ActivePivot で Linux イメージを実行し、10 日間のデータを含む 40 個のストレージ アカウント (それぞれ約 1 TB) を使用しました。</p>\n\n<p style=\"margin: 0in; text-align: center;\"><img height=\"435\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6996aab0-a811-4652-a0c5-5c080d37f2f0.gif\" style=\"width: 736px; height: 375px;\" width=\"870\"><br>\n<em>上のグラフは、5 分間のデータ転送速度を示しています。</em></p>\n\n<p style=\"margin: 0in; color: black; font-family: Calibri; font-size: 11pt;\">&nbsp;</p>\n\n<p>特殊なクラウド コネクタを使用して、ActivePivot は複数のストレージ アカウントからプルし、1 秒あたり 50 GiB で転送します。 この ActiveViam クラウド コネクタは、VM とストレージの帯域幅を完全に飽和させるためにいくつかの HTTP 接続を開き、大きなファイルに合わせて調整されます。</p>\n\n<p>ActivePivot では、データフェッチと並行して、このデータのインデックスがメモリ内に作成されるため、分析ワークロードが高速化されます。 ActivePivot クエリ ノードは、計算をデータ ノード全体に自動的に分散し、ノード間の転送は必要ありません。 CPU、メモリ、およびデータ サイズ&nbsp;を 2 倍にし、期待どおりに追跡することを非常に喜んでくれたので、ほぼ線形スケールのパフォーマンスが期待されていました。</p>\n\n<p>次のグラフでわかるように、データセットに 64 を乗算すると、600 GiB から 37.5 TiB まで、スループットが 54 倍に増加しました。</p>\n\n<p style=\"margin: 0in; text-align: center; color: black; font-family: Calibri; font-size: 11pt;\"><img src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e6d2be50-b2a6-449e-8107-a6c8cf5a5895.png\"></p>\n\n<p>このテストは、データセット全体に対して 10 秒未満で広範なクエリを実行できたため、非常に成功したことが判明しましたが、詳細と詳細な手順については、 <a href=\"https://activeviam.com/blog/advanced-memory-analytics-azure-activeviam-platform/\"><u>ActiveViam ブログ</u></a>を参照してください。 また、年の後半にさらなるスケールアップテストを行いますので、このスペースをご覧ください。</p>\n\n<div align=\"center\">\n<hr align=\"center\" size=\"2\" width=\"100%\"></div>\n\n<p>&nbsp;Financial Services 内のビッグ コンピューティングの詳細については、Azure の<a href=\"https://banking.azure.com/\"><u>HPCFinancial&nbsp; Services ページ</u></a>&nbsp;ー <a href=\"https://azure.microsoft.com/en-us/solutions/high-performance-computing\"><u>HPC</u></a> を参照&nbsp;してください。</p>\n"
}