### YamlMime:Yaml
ms.openlocfilehash: bcff925f2a599f71ce85643f007d2c12b9977cfb
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896340"
Slug: what-s-new-in-azure-machine-learning-service
Title: Azure Machine Learning サービスの新機能
Summary: 現在、Azure Machine Learning サービスの新機能をリリースしています。 最初のパブリックプレビューは2017年9月に開始されたため、非常に多くの貴重なフィードバックを受け取りました。
Content: "<p>現在、Azure Machine Learning サービスの新機能をリリースしています。 最初の <a href=\"https://azure.microsoft.com/en-us/blog/diving-deep-into-what-s-new-with-azure-machine-learning/\" target=\"_blank\">パブリックプレビューは2017年9月に開始</a>されたため、非常に多くの貴重なフィードバックを受け取りました。 過去12か月間、チームは、製品の強化、フィードバックの解決、および新機能の追加に取り組んでいます。 これらの新しい改善点を共有することは非常に魅力的です。 クラウドスケールで machine learning ソリューションを構築してデプロイする際に、データ科学者と機械学習の専門家の生産性が飛躍的に向上することを確信しています。</p>\n\n<p>この投稿では、リリースのコア機能のいくつかについて、さらに技術的な詳細を説明します。</p>\n\n<h2>Python SDK &amp; Machine Learning ワークスペース</h2>\n\n<p>最近の機械学習のイノベーションの多くは Python 言語空間で発生しています。そのため、Python SDK を通じてサービスのコア機能を公開することを選択しました。 単純な pip インストールコマンド (可能であれば、分離された <a href=\"https://conda.io/docs/index.html\" target=\"_blank\">conda</a> 仮想環境) を使用してインストールできます。</p>\n\n<pre>\n# install just the base package\n$ pip install azureml-sdk\n\n# or install additional capabilities such as automated machine learning\n$ pip install azureml-sdk[automl]</pre>\n\n<p>SDK を完全に活用するには、Azure サブスクリプションにアクセスする必要があります。 まず、Azure Machine Learning ワークスペースを作成する必要があると考えてください。 そのためには、Python SDK または Azure portal を使用します。 ワークスペースは、すべての資産の論理的なコンテナーであり、セキュリティと共有の境界でもあります。</p>\n\n<pre>\nworkspace = Workspace.create(name=&#39;my-workspace&#39;,\n                             subscription_id=&#39;&lt;azure-subscription-id&gt;&#39;,\n                             resource_group=&#39;my-resource-group&#39;)</pre>\n\n<p>ワークスペースを作成したら、SDK を使用して豊富な一連の Azure サービスにアクセスし、データサイエンスのロッキングを開始できます。 使用を開始する方法の詳細については、 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/quickstart-get-started\" target=\"_blank\">入門記事を</a> ご覧ください。</p>\n\n<h2>データの準備</h2>\n\n<p>データ準備は機械学習ワークフローの重要な部分です。 使いやすい形式のクリーン データにアクセスできれば、モデルは一層精確かつ効率的になります。 SDK を使用すると、さまざまな形式のデータを読み込んで、使用できるように変換し、モデルがアクセスできる場所にそのデータを書き込むことができます。 いくつかの例を示して、列を2つの新しい列に変換する場合の優れた例を次に示します。</p>\n\n<pre>\ndf2 = df1.derive_column_by_example(source_columns=&#39;start_time&#39;,\n                                   new_column_name=&#39;date&#39;,\n                                   example_data=[\n                                   (&#39;2017-12-31 16:57:39.6540&#39;, &#39;2017-12-31&#39;),\n                                   (&#39;2017-12-31 16:57:39&#39;, &#39;2017-12-31&#39;)])\ndf3 = df2.derive_column_by_example(source_columns=&#39;start_time&#39;,\n                                   new_column_name=&#39;wday&#39;,\n                                   example_data=[(&#39;2017-12-31 16:57:39.6540&#39;, &#39;Sunday&#39;)])</pre>\n\n<p>詳細については、こちらの <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-data-prep\" target=\"_blank\">記事をご覧</a>ください。</p>\n\n<h2>実験の追跡</h2>\n\n<p>モデリングトレーニングは反復的なプロセスです。 Azure Machine Learning サービスは、クラウドで実行されているすべての実験を追跡できます。 実験はローカルでもリモートでも実行でき、ログ Api を使用して任意のメトリックを記録したり、任意のファイルをアップロードしたりすることができます。</p>\n\n<pre>\nexp = Experiment(workspace, &quot;fraud detection&quot;)\nwith exp.start_logging() as run:\n      # your code to train the model omitted\n      ... ...\n     \n      run.log(&quot;overall accuracy&quot;, acc) # log a single value\n      run.log_list(&quot;errors&quot;, error_list) # log a list of values\n      run.log_row(&quot;boundaries&quot;, xmin=0, xmax=1, ymin=-1, ymax=1) # log arbitrary key/value pairs\n      run.log_image(&quot;AUC plot&quot;, plt) # log a matplotlib plot\n      run.upload(&quot;model&quot;, &quot;./model.pkl&quot;) # upload a file</pre>\n\n<p>実行が完了すると (または実行が実行されている間に)、追跡された情報が Azure portal に表示されます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5f332f33-7200-480b-bc70-a6badbd072de.png\"><img alt=\"image\" border=\"0\" height=\"369\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cef75029-4c67-4ca7-925f-05cab8843731.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"560\"></a></p>\n\n<p>また、実験の実行に対してクエリを実行すると、最も高い精度、最も低い平均二乗誤差など、ユーザーが定義した最適なメトリックを記録したものを見つけることができます。 その後、その実行によって生成されたモデルを、ワークスペースのモデルレジストリで登録できます。 また、そのモデルを取得してデプロイすることもできます。</p>\n\n<pre>\n# Find the run that has the highest accuracy metric recorded.\nbest_run_id = max(run_metrics, key=lambda k: run_metrics[k][&#39;accuracy&#39;])\n\n# reconstruct the run object based on run id\nbest_run = Run(experiment, best_run_id)\n\n# register the model produced by that run\nbest_run.register_model(&#39;best model&#39;, &#39;outputs/model.pkl&#39;)</pre>\n\n<p><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-track-experiments\" target=\"_blank\">実験ログ api を使用する方法</a>の詳細な例については、こちらを参照してください。</p>\n\n<h2>GPU クラスターでトレーニングをスケールする</h2>\n\n<p>Tinker は、ラップトップでローカルに小さなデータセットを使用することもできますが、高度なモデルをトレーニングすると、クラウドで大規模なコンピューティングリソースが必要になる場合があります。 Python SDK を使用すると、 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#dsvm\" target=\"_blank\">既存の Azure Linux vm をアタッチ</a>したり、 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#hdinsight\" target=\"_blank\">Spark クラスターに azure HDInsight をアタッチ</a> してトレーニングジョブを実行したりするだけで済みます。 また、スクリプトを実行するために、管理対象のコンピューティングクラスター (Azure Batch AI クラスターとも呼ばれます) を簡単に作成することもできます。</p>\n\n<pre>\npc = BatchAiCompute.provisioning_configuration(vm_size=&quot;STANDARD_NC6&quot;,\n                                               autoscale_enabled=True,\n                                               cluster_min_nodes=0,\n                                               cluster_max_nodes=4)\ncluster = compute_target = ComputeTarget.create(workspace, pc)</pre>\n\n<p>上記のコードでは、Gpu ( &ldquo; STANDARD_NC6 &rdquo; Azure VM タイプ) を備えたマネージコンピューティングクラスターが作成されます。 ジョブが送信されたときに自動的に4ノードまでスケールアップすることも、ジョブが完了してコストを節約するために0ノードにスケールバックすることもできます。 多くのジョブを並行して実行したり、インテリジェントなハイパーパラメーターのチューニングやバッチスコアリングのような機能をサポートしたり、分散方式で大規模なディープラーニングモデルをトレーニングしたりするのに最適です。</p>\n\n<p>管理された <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#batch\" target=\"_blank\">コンピュータークラスターを作成する方法</a>の詳細な例については、こちらを参照してください。</p>\n\n<h2>柔軟な実行環境</h2>\n\n<p>Azure Machine Learning サービスは、ローカルコンピューター、前述のリモート VM、Spark クラスター、管理されたコンピュータークラスターなど、さまざまなコンピューティングターゲットでのスクリプトの実行をサポートします。 コンピューティングターゲットごとに、柔軟な実行構成オブジェクトを通じてさまざまな実行環境もサポートします。 コンピューティングターゲットで既に構成されている Python 環境でスクリプトを実行するか、またはジョブを実行するために指定された依存関係に基づいて新しい conda 環境を構築するようシステムに指示できます。 また、ジョブを実行するために Docker イメージをダウンロードするようにシステムに依頼することもできます。 選択できる基本 Docker イメージはいくつか用意していますが、必要に応じ &rsquo; て独自の docker イメージを持ち込むこともできます。</p>\n\n<p>次に、システム管理の conda 環境で Docker イメージを指定する実行構成オブジェクトの例を示します。</p>\n\n<pre>\n# Create run configuration object\nrc = RunConfiguration()\nrc.target = &quot;my-vm-target&quot;\nrc.environment.docker.enabled = True\nrc.environment.python.user_managed_dependencies = False\nrc.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n\n# Specify conda dependencies with scikit-learn\ncd = CondaDependencies.create(conda_packages=[&#39;scikit-learn&#39;])\nrc.environment.python.conda_dependencies = cd\n\n# Submit experiment\nsrc = ScriptRunConfig(source_directory=&quot;./&quot;, script=&#39;train.py&#39;, run_config=rc)\nrun = experiment.submit(config=src)</pre>\n\n<p>また、SDK には、これらの構成の一部を PyTorch 実行用にラップして、環境をより簡単に定義できるようにするための高レベルの <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-train-ml-models#train-with-an-estimator\" target=\"_blank\">推定パターン</a> も含まれています。 これらの環境構成を使用すると、柔軟性が最大になり、再現性と制御のバランスを取ることができます。 詳細については、「HDInsight で <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#local\" target=\"_blank\">ローカル実行</a>、 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#local\" target=\"_blank\">リモート VM 実行</a>、 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#hdinsight\" target=\"_blank\">Spark ジョブ実行</a>を構成する方法」を参照してください。</p>\n\n<h2>データストア</h2>\n\n<p>多くのコンピューティングターゲットと実行環境がサポートされているため、スクリプトからデータファイルにアクセスするための一貫した方法を用意することが重要です。 すべてのワークスペースには、Azure blob ストレージアカウントに基づく既定のデータストアが付属しています。 データファイルを格納および取得するために使用できます。 また、ワークスペースの下に追加のデータストアを構成することもできます。 データストアを使用する簡単な例を次に示します。</p>\n\n<pre>\n# upload files from local computer into default datastore\nds = workspace.get_default_datastore()\nds.upload(src_dir=&#39;./data&#39;, target_path=&#39;mnist&#39;, overwrite=True)\n\n# pass in datastore&#39;s mounting point as an argument when submitting an experiment.\nscr = ScriptRunConfig(source_directory=&quot;./&quot;,\n                      script=&quot;train.py&quot;,\n                      run_config=rc,\n                      arguments={&#39;--data_folder&#39;: ds.as_mount()})\nrun = experiment.submit(src)</pre>\n\n<p>その一方で、コンピューティングクラスターで実行されるトレーニングスクリプトでは、データストアは自動的にマウントされます。 必要なのは、マウントパスを保持することだけです。</p>\n\n<pre>\nargs = parser.parse_args()\n# access data from the datastore mounting point\ntraining_data = os.path.join(args.data_folder, &#39;mnist&#39;, &#39;train-images.gz&#39;)</pre>\n\n<p><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data\" target=\"_blank\">データストア</a>の詳細については、「」を参照してください。</p>\n\n<h2>機械学習の自動化</h2>\n\n<p>トレーニングデータセットがある場合、適切なデータ前処理メカニズムと適切なアルゴリズムを選択することは、専門家にとっても困難な作業になる可能性があります。 Azure Machine Learning サービスには、最適な特性付け手順と最適なアルゴリズムで構成される機械学習パイプラインを自動的に推奨する高度な機能が含まれており、設定したターゲットメトリックに基づいて最適なハイパーパラメーターを使用できます。 次に示すのは、指定されたトレーニングデータセットを分類するための最大 AUC_Weighted 値を生成するパイプラインを自動的に検索する例です。</p>\n\n<pre>\n# automatically find the best pipeline that gives the highest AUC_weighted value.\ncfg = AutoMLConfig(task=&#39;classification&#39;,\n                   primary_metric=&quot;AUC_weighted&quot;,\n                   X = X_train,\n                   y = y_train,\n                   max_time_sec=3600,\n                   iterations=10,\n                   n_cross_validations=5)\nrun = experiment.submit(cfg)\n\n# return the best model\nbest_run, fitted_model = run.get_output()</pre>\n\n<p>実行の出力を次に示します。 イテレーション #6 は、 <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\" target=\"_blank\">Scikit-learn StandardScaler</a> と <a href=\"https://github.com/Microsoft/LightGBM\" target=\"_blank\">ライト gbm</a> 分類子を含む最適なパイプラインを表します。</p>\n\n<table border=\"1\" cellpadding=\"2\" cellspacing=\"0\">\n <tbody>\n  <tr>\n   <td valign=\"top\"><strong>繰返し</strong></td>\n   <td valign=\"top\"><strong>商談</strong></td>\n   <td valign=\"top\"><strong>DURATION</strong></td>\n   <td valign=\"top\"><strong>非対称</strong></td>\n   <td valign=\"top\"><strong>合っ</strong></td>\n  </tr>\n  <tr>\n   <td valign=\"top\">0</td>\n   <td valign=\"top\">SparseNormalizer LogisticRegression</td>\n   <td valign=\"top\">0:00: 46.451353</td>\n   <td valign=\"top\">0.998</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">1</td>\n   <td valign=\"top\">StandardScalerWrapper KNeighborsClassi</td>\n   <td valign=\"top\">0:00: 31.184009</td>\n   <td valign=\"top\">0.998</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">2</td>\n   <td valign=\"top\">MaxAbsScaler ライト Gbm分類器</td>\n   <td valign=\"top\">0:00: 16.193463</td>\n   <td valign=\"top\">0.998</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">3</td>\n   <td valign=\"top\">MaxAbsScaler DecisionTreeClassifier</td>\n   <td valign=\"top\">0:00: 12.379544</td>\n   <td valign=\"top\">0.828</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">4</td>\n   <td valign=\"top\">SparseNormalizer ライト Gbm分類器</td>\n   <td valign=\"top\">0:00: 21.779849</td>\n   <td valign=\"top\">0.998</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">5</td>\n   <td valign=\"top\">StandardScalerWrapper KNeighborsClassi</td>\n   <td valign=\"top\">0:00: 11.910200</td>\n   <td valign=\"top\">0.998</td>\n   <td valign=\"top\">0.998</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">6</td>\n   <td valign=\"top\">StandardScalerWrapper LightGBMClassifi</td>\n   <td valign=\"top\">0:00:33.010702</td>\n   <td valign=\"top\">0.999</td>\n   <td valign=\"top\">0.999</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">7</td>\n   <td valign=\"top\">StandardScalerWrapper SGDClassifierWra</td>\n   <td valign=\"top\">0:00:18.195307</td>\n   <td valign=\"top\">0.994</td>\n   <td valign=\"top\">0.999</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">8</td>\n   <td valign=\"top\">MaxAbsScaler LightGBMClassifier</td>\n   <td valign=\"top\">0:00:16.271614</td>\n   <td valign=\"top\">0.997</td>\n   <td valign=\"top\">0.999</td>\n  </tr>\n  <tr>\n   <td valign=\"top\">9</td>\n   <td valign=\"top\">StandardScalerWrapper KNeighborsClassi</td>\n   <td valign=\"top\">0:00:15.860538</td>\n   <td valign=\"top\">0.999</td>\n   <td valign=\"top\">0.999</td>\n  </tr>\n </tbody>\n</table>\n\n<p>自動機械学習&rsquo;では、分類と回帰の両方がサポートされ、欠損値の処理、メトリックの停止による早期終了、探索したくないブラックリストアルゴリズムなどの機能が含まれます。 詳細については、自動機械学習 <a href=\"https://aka.ms/aml-blog-automl\" target=\"_blank\">に関する記事を参照</a> してください。</p>\n\n<h2>インテリジェントハイパーパラメーターのチューニング</h2>\n\n<p>ハイパーパラメーター調整 (パラメーター スイープ) は、特定のアルゴリズムに最適なハイパーパラメーター値を見つけ出す一般的な機械学習手法です。 無分力なハイパーパラメーター検索や完全なハイパーパラメーター検索は、計算コストが高く、時間がかかる場合があります。 このAzure Machine Learningは、ユーザーの時間とリソースを大幅に節約できるインテリジェントなハイパーパラメーター調整機能を提供します。 パラメーター空間をランダムまたはベイジアン最適化で検索し、マネージド コンピューティング クラスター上のパラメーター検索ジョブを並列で自動的にスケジュールし、ユーザー定義の早期終了ポリシーを通じて検索プロセスを加速できます。 従来の機械学習アルゴリズムと反復ディープ ラーニング アルゴリズムの両方が、その利点を得る可能性があります。 エスティメーター オブジェクトでハイパーパラメーター調整を使用する例を次に示します。</p>\n\n<pre>\n# parameter grid to search\nparameter_samples = RandomParameterSampling{\n       &quot;--learning_rate&quot;: loguniform(-10, -3),\n       &quot;--batch_size&quot;: uniform(50,300),\n       &quot;--first_layer_neurons&quot;: choice(100, 300, 500),\n       &quot;--second_layer_neurons&quot;: choice(10, 20, 50, 100)\n}\n\n# early termination policy\npolicy = BanditPolicy(slack_factor=0.1, evaluation_interval=2)\n\n# hyperparameter tuning configuration\nhtc = HyperDriveRunConfig(estimator=my_estimator,\n                          hyperparameter_sampling=parameter_samples,\n                          policy=policy,\n                          primary_metric_name=&#39;accuracy&#39;,  \n                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                          max_total_runs=200,\n                          max_concurrent_runs=10,\n)\nrun = experiment.submit(htc)</pre>\n\n<p>上記のコードでは、指定されたパラメーター空間をランダムに検索し、エスティメーター オブジェクトに構成されているコンピューター ターゲットで最大 200 のジョブを起動し、最高の精度を返すジョブを探します。 BanditPolicy &ldquo;&rdquo; は、各ジョブによって生成された精度を 2 回のイテレーションごとにチェックし、精度の値が他の実行から報告された最も高い精度の 10% &ldquo;&rdquo; の緩みではない場合はジョブを終了します。 インテリジェントハイパーパラメーター調整の詳細 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-tune-hyperparameters\" target=\"_blank\">な説明を確認します</a>。</p>\n\n<h2>分散トレーニング</h2>\n\n<p>ディープ ニューラル ネットワークをトレーニングする場合は、GPU 搭載コンピューターのクラスターに対して計算を並列化する方が効率的です。 このようなクラスターを構成し、トレーニング スクリプトを並列化すると、時間のかかる、エラーが発生しやすいタスクになる可能性があります。 Azure Machine Learningは、分散トレーニング機能が既に有効になっているマネージド コンピューティング クラスターをプロビジョニングします。 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow#parameter-server\" target=\"_blank\">TensorFlow</a> に組み込むネイティブ パラメーター サーバー オプション、<a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow#horovod\" target=\"_blank\">または TensorFlow と組み合わせた Hovorod</a> フレームワークによって利用される MPI ベースのアプローチ、<a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch#horovod\" target=\"_blank\">PyTorch を使用した Horovod</a>、<a href=\"https://aka.ms/aml-notebook-cntk-mpi\" target=\"_blank\">または MPI</a> を使用した CNTK を使用している場合でも、ネットワークを簡単に並列でトレーニングできます。</p>\n\n<p>次に示すのは、MPI サポートを使用して TensorFlow トレーニング実行を構成する例です。この例では、distributed_backend フラグが mpi に設定されています。 このファイル word2vec.py 自動的にインストールされる Horovod を利用できます。</p>\n\n<pre>\ntf_estimator = TensorFlow(source_directory=&quot;./&quot;,\n                          compute_target=my_cluster,\n                          entry_script=&#39;word2vec.py&#39;,\n                          script_params=script_params,\n                          node_count=4,\n                          process_count_per_node=1,\n                          distributed_backend=&quot;mpi&quot;,\n                          use_gpu=True)</pre>\n\n<p>分散トレーニングの詳細<a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-train-ml-models?#distributed-training-and-custom-docker-images\" target=\"_blank\">については、Azure Machine Learningしてください</a>。</p>\n\n<h2>パイプライン</h2>\n\n<p>Azure Machine Learningパイプラインを使用すると、データ サイエンティストは複数のシンプルで複雑なワークフローを同時に作成および管理できます。 一般的なパイプラインには、データの準備、トレーニング、デプロイ、およびモデルの評価を行う複数のタスクがあります。 個々の手順では、さまざまなコンピューティング オプション (データ準備用の CPU、トレーニング用の GPU など) と言語を利用できます。 ユーザーは、バッチ スコアリングや再トレーニングのようなシナリオに対して公開されたパイプラインを使用することもできます。</p>\n\n<p>データ準備、トレーニング、バッチ スコアリングのシーケンシャル パイプラインを示す簡単な例を次に示します。</p>\n\n<pre>\n# Uses default values for PythonScriptStep construct.\ns1 = PythonScriptStep(script_name=&quot;prep.py&quot;, target=&#39;my-spark-cluster&#39;, source_directory=&quot;./&quot;)\ns2 = PythonScriptStep(script_name=&quot;train.py&quot;, target=&#39;my-gpu-cluster&#39;, source_directory=&quot;./&quot;)\ns3 = PythonScriptStep(script_name=&quot;batch_score.py&quot;, target=&#39;my-cpu-cluster&#39;, source_directory=&quot;./&quot;)\n\n# Run the steps as a pipeline\npipeline = Pipeline(workspace=ws, steps=[s1, s2, s3])\npipeline.validate()\npipeline_run = experiment.submit(pipeline)</pre>\n\n<p>パイプラインを使用すると、複数ステップのワークフローを整理し、ワークフロー全体を 1 回の実験実行として追跡することで管理性を向上し、すべての中間タスクとデータを記録することで使いやすさを向上することで、複雑さを大幅に軽減できます。 詳細については、このドキュメント <a href=\"https://docs.microsoft.com/azure/machine-learning/service/concept-ml-pipelines\" target=\"_blank\">を参照してください</a>。</p>\n\n<h2>モデル管理</h2>\n\n<p>モデルは、新しい実験からトレーニング実行からAzure Machine Learningできます。 シンプルな API を使用して、ワークスペースの下に登録できます。 また、モデルの外部で生成されたモデルをAzure Machine Learning登録する方法もあります。</p>\n\n<pre>\n# register a model that&#39;s generated from a run and stored in the experiment history\nmodel = best_run.register_model(model_name=&#39;best_model&#39;, model_path=&#39;outputs/model.pkl&#39;)\n\n# or, register a model from local file\nmodel = Model.register(model_name=&quot;best_model&quot;, model_path=&quot;./model.pkl&quot;, workspace=workspace)</pre>\n\n<p>登録したら、タグ付け、バージョン管理、検索、デプロイを行います。 モデル管理機能の詳細については、このノートブック <a href=\"https://aka.ms/aml-notebook-deployment-aci\" target=\"_blank\">を参照してください</a>。</p>\n\n<h2>コンテナー化されたデプロイ</h2>\n\n<p>登録されたモデルを作成したら、SDK のモデル管理 API を使用して Docker イメージを簡単に作成できます。 ローカル コンピューターからモデル ファイルを指定するか、ワークスペースで登録済みのモデルを使用して、トレーニング スクリプトとパッケージの依存関係ファイルを追加します。 システムは、すべてをクラウドにアップロードして Docker イメージを作成し、ワークスペースに登録します。</p>\n\n<pre>\nimg_conf = ContainerImage.image_configuration(runtime=&quot;python&quot;,\n                                                execution_script=&quot;score.py&quot;,\n                                                conda_file=&quot;dependencies.yml&quot;)\n# create a Docker image with model and scoring file\nimage = Image.create(name=&quot;my-image&quot;,                   \n                     models=[model_obj],\n                     image_config=image_config,\n                     workspace=workspace)</pre>\n\n<p><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-to-aci\" target=\"_blank\">イメージを Azure Container Instance (ACI)</a> サービスにデプロイするか、コンピューティング ファブリックを使用して開発/テスト シナリオ用の Docker コンテナーを実行するか、スケールアウトと安全な実稼働環境のために <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-to-aks\" target=\"_blank\">Azure Kubernetes Cluster (AKS)</a> サービスにデプロイすることができます。 その他のデプロイ <a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where\" target=\"_blank\">オプションを確認します</a>。</p>\n\n<h2>ノートブックの使用</h2>\n\n<p>Python SDK Azure Machine Learningは、選択した任意の Python 開発環境で使用できます。 さらに、次のノートブックサーフェス領域との緊密な統合を有効にしました。</p>\n\n<h2>Juypter Notebook</h2>\n\n<p>私が引用しているサンプルのほぼすべてが、GitHub で公開されている Jupyter ノートブックの形式であるのに気付いたGitHub。 Jupyter は、インタラクティビティと自己文書化の性質により、データ サイエンスの最も一般的なツールの 1 つになります。 実験の実行履歴を操作する Juypter ユーザーを容易にするために、実行オブジェクトを監視する実行履歴ウィジェットを作成しました。 ハイパーパラメーター調整の実行の例を次に示します。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/da9a91df-c225-47ab-822b-db03c9dc7875.png\"><img alt=\"image\" border=\"0\" height=\"836\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e6fb0ba2-e8c1-424a-8b27-5df4ada822ce.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"560\"></a></p>\n\n<p align=\"center\"><em>実行履歴ウィジェット</em></p>\n\n<p>実行履歴ウィジェットの動作を確認するには、次 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/tutorial-train-models-with-aml\" target=\"_blank\">のノートブックに従います</a>。</p>\n\n<h2>Azure Notebooks</h2>\n\n<p><a href=\"https://notebooks.azure.com/\" target=\"_blank\">Azure Notebooks</a> は、Jupyter を使用してブラウザーでコードを開発および実行するために使用できる無料のサービスです。 Azure Notebooks コンテナーの Python 3.6 カーネルに SDK がプレインストールされており、すべてのサンプル ノートブックを独自のライブラリに簡単に <a href=\"https://aka.ms/aml-clone-azure-notebooks\" target=\"_blank\">複製できます</a>。 さらに、ワークスペース内のワークスペース<strong>はじめに</strong>のAzure NotebooksボタンをクリックAzure portal。 ワークスペースの構成は、複製されたライブラリにも自動的にコピーされ、SDK から直接アクセスできます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b8136320-0ead-4d8d-98ac-06d105bd6ed3.png\"><img alt=\"image\" border=\"0\" height=\"440\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/31b2367b-a9a9-4c63-8d78-d268f47cb1dd.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"560\"></a></p>\n\n<h2>Azure Databricks との統合</h2>\n\n<p><a href=\"https://azure.microsoft.com/en-us/services/databricks/\" target=\"_blank\">Azure Databricks</a> は、ビッグ Apache Spark&ndash;分析を実行するための、データベースの分析サービスです。 sdk を Azure Databricks クラスターに簡単にインストールし、それを使用してトレーニングの実行メトリックをログに記録したり、Spark ML モデルをコンテナー化して、他のモデルと同様に ACI または AKS にデプロイすることができます。 Python SDK の使用Azure Databricks開始Azure Machine Learning、このノートブック<a href=\"https://aka.ms/aml-notebook-adb\" target=\"_blank\">を確認してください</a>。</p>\n\n<h2>Visual Studio Code Tools for AI</h2>\n\n<p><a href=\"https://code.visualstudio.com/\" target=\"_blank\">Visual Studio Code</a>は非常に一般的なコード編集ツールであり、Python 拡張機能は Python 開発者の間で広く採用されています。 <a href=\"https://aka.ms/vscodetoolsforai\" target=\"_blank\">Visual Studio Code Tool for AI は</a>、堅牢な実験機能Azure Machine Learningとシームレスに統合されます。 この拡張機能を使用すると、実験の実行送信から実行の追跡まで、コンピューティング ターゲットのプロビジョニングからモデルの管理とデプロイまで、すべての優れた機能に、親しげなユーザー インターフェイス内でアクセスできます。 次に示すのは、Visual Studio Code Tool for AI 拡張機能の動作のスクリーンショットです。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/60c50b41-5fd2-48a3-8308-241798c1d8ea.png\"><img alt=\"image\" border=\"0\" height=\"276\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/00036eee-3da9-4f8d-9de4-5eac15462634.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"560\"></a></p>\n\n<p align=\"left\"><a href=\"https://aka.ms/vscodetoolsforai\" target=\"_blank\">Visual Studio Code Tool for AI 拡張機能をダウンロード</a>して試してください。</p>\n\n<h2>概要、今すぐ!</h2>\n\n<p>これは非常に長い投稿なので、読んでもらってありがとうございます。 しかし、サービスの表面にほとんどAzure Machine Learningしました。 他にも非常に多くの便利な機能が備わっているので、この機能にはアクセスできない機能があります。 独自に探索する必要があります。</p>\n\n<ul>\n <li><a href=\"https://aka.ms/aml-notebook-tb\" target=\"_blank\">TensorBoard の統合</a> &ndash; TensorFlow を使用していない場合でも、TensorBoard で実験の実行を監視します。</li>\n <li><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-build-deploy-onnx\" target=\"_blank\">ONNX ランタイムのサポート</a> &ndash; オープン ONNX 形式で作成されたモデルをデプロイします。</li>\n <li><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-enable-data-collection\" target=\"_blank\">モデル テレメトリの収集</a> &ndash; ライブ実行中のモデルからテレメトリを収集します。</li>\n <li><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-fpga-web-service\" target=\"_blank\">フィールド プログラミング可能なゲートアレイ (FPGA) のインフェレンシング</a> &ndash; 高速で低コストで事前トレーニング済みのディープ ニューラル ネットワークを使用して、画像データのスコア付けまたはフィーチャー化を行います。</li>\n <li><a href=\"https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-to-iot\" target=\"_blank\">IoT のデプロイ</a> &ndash; IoT デバイスにモデルをデプロイする。</li>\n</ul>\n\n<p>さらに多くの情報が必要です。 お問い合 <a href=\"https://docs.microsoft.com/azure/machine-learning/service/quickstart-get-started\" target=\"_blank\">わせから始めるには、Getting Started</a> ガイドをご覧ください。</p>"
