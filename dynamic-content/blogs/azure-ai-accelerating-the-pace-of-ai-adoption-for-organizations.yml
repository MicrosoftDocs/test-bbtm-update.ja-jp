### YamlMime:Yaml
ms.openlocfilehash: 6f88c2012f52a00baddc59cbb4d7b10654746a6d
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139909359"
Slug: azure-ai-accelerating-the-pace-of-ai-adoption-for-organizations
Title: Azure AI – 組織の AI 導入のペースを加速する
Summary: 2018 年 9 月の Microsoft Ignite での発表を基に、組織が AI を簡単に適用してビジネスを変革するために行っているいくつかの新しい発表をお知らせします。
Content: >-
  <p>AI は、世界を変える変革的イノベーションの次の波を促進しています。 このAzure AIを使用すると、組織は次の機能を簡単に利用できます。</p>


  <ul>
      <li>機械学習を使用して、ビジネス プロセスを最適化する予測モデルを構築する</li>
      <li>高度なビジョン、音声、言語機能を利用して、パーソナライズされた魅力的なエクスペリエンスを提供するアプリケーションを構築する</li>
      <li>ナレッジ マイニングを適用して、ファイルの膨大なリポジトリから潜在的な分析情報を明らかにする</li>
  </ul>


  <p>9 月の <a href="https://azure.microsoft.com/en-gb/blog/azure-ai-making-ai-real-for-business/" target="_blank">Microsoft Ignite</a>&rsquo; での発表を基に、Microsoft Connect() で行っているいくつかの新しい発表を共有して、組織が AI を簡単に適用してビジネスを変革することを可能にすることを楽しみに思います。</p>


  <h2>Azure Machine Learning サービスの一般提供</h2>


  <p>本日は、サービスの一般提供をお<a href="https://azure.microsoft.com/en-us/blog/azure-machine-learning-service-a-look-under-the-hood/" target="_blank">知らせAzure Machine Learning</a>いたします。 Azure Machine Learningを使用すると、インテリジェント クラウドからインテリジェント エッジまで、機械学習モデルを迅速かつ簡単に構築、トレーニング、デプロイできます。 自動化された機械学習のような機能を使用すると、組織は適切なアルゴリズムと機械学習パイプラインをより迅速に識別することで、モデル開発を高速化できます。 これは、組織が開発時間を日から数時間に大幅に短縮するのに役立ちます。 ハイパーパラメーター チューニングを使用すると、組織はパラメーターを調整してモデルの精度を向上できます。</p>


  <p>モデルが開発された後、組織は統合 (CI/CD) ツールを使用して、クラウドとエッジ (IoT デバイスを含む) にモデルを簡単にデプロイして管理できます。 開発者は、Visual Studio Code、Visual Studio、PyCharm、Azure Databricks ノートブック、Jupyter Notebook など、好みの Python 開発環境を使用できます。 TAL のようなお客様が、サービスを使用してビジネスを既に変革Azure Machine Learningしています。</p>


  <blockquote>

  <p>&ldquo;損害保険業界は大きな変化に直面しています。TAL では、そのリーダーでありたく思っています。 つまり、データと機械学習によって提示される新しい機会を活用します。 またAzure Machine Learning&rdquo;これらのツールを非常に迅速に実稼働環境に置き、より迅速に市場に出す機能を提供できると、TAL のイノベーションのジェネラル マネージャーである Dan Taylor 氏は言います。</p>

  </blockquote>


  <p style="text-align: center;"><iframe allowfullscreen="" frameborder="0" height="540" scrolling="no" src="https://channel9.msdn.com/Shows/AI-Show/Azure-Machine-Learning-helps-Australian-Life-Insurer-Innovate/player?format=ny" width="960"></iframe></p>


  <p>詳細については、お知らせ&ldquo;ブログ「お知らせサービスの一般提供のお<a href="https://aka.ms/aml-ga-blog" target="_blank">知らせAzure Machine Learningしてください</a>。&rdquo;</p>


  <h2>オープン ニューラル ネットワーク Exchange (ONNX) ランタイムがオープン ソースに</h2>


  <p>Microsoft は、すべての組織が AI にアクセスしやすくするために取り組みです。 Open Neural Network Exchange (<a href="https://onnx.ai/" target="_blank">ONNX</a>) ランタイムがオープン ソースになExchangeお知らせします。 ONNX は、データ サイエンティストや開発者が、PyTorch、TensorFlow、scikit-learn など、最適なフレームワークとツールを使用できる機械学習モデルを表すオープンな形式です。 ONNX ランタイムは、ONNX 仕様を完全にサポートし、平均 2 倍のパフォーマンス向上を実現する最初の推論エンジンです。 Qualcomm、Intel、NVIDIA などの主要なハードウェア企業は、カスタム アクセラレータを ONNX Runtime に統合するために積極的に取り組しています。 詳細については、お知らせブログ&ldquo;「<a href="https://aka.ms/onnx-rt-os" target="_blank">ONNX Runtime is now open source」を参照してください</a>。&rdquo;</p>


  <blockquote>

  <p>&ldquo;ONNX Runtime の導入は、複数のデバイス カテゴリにわたるフレームワークの相互運用性、標準化、パフォーマンスの最適化をさらに推進する前向きな次のステップであり、開発者には Snapdragon&rdquo; モバイル プラットフォームでの ONNX Runtime のサポートを歓迎することを期待しています。Qualcomm Technologies のシニア ディレクターである Gary Brotman 氏は述べています。</p>

  </blockquote>


  <h2>Language Understanding コンテナープレビューでAzure Cognitive Services利用可能に</h2>


  <p>最近、Azure Cognitive Services コンテナーのプレビュー <a href="https://azure.microsoft.com/en-gb/blog/bringing-ai-to-the-edge/" target="_blank">を</a>発表しました。IoT デバイスを含め、クラウドとエッジにまたがるインテリジェントなアプリケーションを構築できます。 本日は、プレビューの一部としてLanguage Understandingがリリースされました。お知らせします。 <a href="https://azure.microsoft.com/en-us/blog/getting-started-with-cognitive-services-language-understanding-container/" target="_blank">Language Understanding のコンテナー</a>&mdash; &mdash; サポートを使用すると、データ サイエンスの深いスキルを持つことなく、物体検出、視覚認識、言語理解などのコグニティブ機能をアプリに簡単かつ迅速に追加できます。 Cognitive Servicesコンテナーを使用すると、堅牢なクラウド機能とエッジの局所性の両方を利用するために最適化された 1 つのアプリケーション アーキテクチャを構築できます。</p>


  <blockquote>

  <p>&ldquo;Azure Cognitive Servicesコンテナーを使用すると、一貫したパフォーマンスで、オンプレミスまたはオフのどちらで AI ソリューションを拡大およびデプロイするかについて、より多くのオプションが提供されます。 ワークロードの強度が増加したり&rdquo; 、エッジにスケールアウトしたりすると、スケールアップできます。Andy Vargas 氏は、Intel のソフトウェアとサービスの VP です。</p>

  </blockquote>


  <h2>カスタム翻訳機能の一般提供</h2>


  <p>本日は、カスタム翻訳機能の一般提供について、お知らせCognitive Services。 カスタム翻訳を使用すると、カスタマイズされたニューラル機械翻訳 (&ldquo;NMT) システムを&rdquo;構築できます。 これにより、既存のアプリケーション、ワークフロー、Web サイトへのシームレスな統合が可能です。 一般提供により、カスタム翻訳は 翻訳ツール Text Cognitive Service の長所に基いて構築され、毎日何十億もの翻訳を強化し、30 を超える言語をサポートしています。</p>


  <p>2018 年 12 月 6 日の DevIntersection での AI に関する講演中に、これらの発表について話し合うのを楽しみにしています。 Azure を AI に最適な場所にし続ける中で、組織がビジネスを変革する方法を見ていけるのは楽しみです。 機会は無限です。 今すぐお試しください。</p>


  <h2>その他の技術情報</h2>


  <ul>
      <li><a href="https://azure.microsoft.com/en-us/blog/azure-machine-learning-service-a-look-under-the-hood/" target="_blank">Azure Machine Learning サービスの一般提供</a></li>
      <li><a href="https://azure.microsoft.com/en-us/blog/onnx-runtime-is-now-open-source/" target="_blank">ONNX Runtime オープン ソース</a></li>
      <li><a href="https://azure.microsoft.com/en-gb/blog/bringing-ai-to-the-edge/" target="_blank">AI をエッジに持ち込む</a></li>
  </ul>
