### YamlMime:Yaml
ms.openlocfilehash: ee40ae1733697ca5d57e03ef258373b90689079d
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896866"
Slug: bringing-ai-supercomputing-to-customers
Title: AI supercomputing を顧客に導入する
Summary: 膨大な数の AI モデルを使用して大量のタスクを処理することに向けた傾向は、強力な新機能を実現するために AI を構築して適用する方法を変更することです。
Content: >-
  <p>大量の AI モデルを使用して多数のタスクを処理することに向けた傾向は、AI の構築方法を変更することです。 Microsoft ビルド2020では、Azure の最先端の<a href="https://blogs.microsoft.com/ai/openai-azure-supercomputer/" target="_blank">ai supercomputing</a>と、次世代の ai モデルの新しいクラスを利用して、ai 向けの構想を大規模<a href="https://innovation.microsoft.com/en-us/ai-at-scale" target="_blank">に</a>共有しています。 大規模なモデルの利点は、AI supercomputing を使用して大量のデータを1回トレーニングするだけで済みます。これにより、データセットとリソースがはるかに少ないさまざまなタスクやドメインに対して、これらのモデルを微調整 &rdquo; することができ &ldquo; ます。 モデルに含まれるパラメーターの数が多いほど、170億-parameter チューリング自然言語生成 (T-NLG) モデルによって示されているように、データの困難な差異を取り込むことができます。また、最初に表示されたドキュメントからの質問に回答したり、要約 &nbsp; したりする言語を理解することができます。 このような自然言語モデルは、1年前 &nbsp; のモデルの状態よりも大幅に大きくなっており、以前のイメージ中心モデルのサイズの大きさが非常に多いため、Bing、Word、Outlook、および Dynamics 全体でさまざまなタスクを実行しています。</p>


  <p>このスケールでモデルをトレーニングするには、数百台のコンピューターに大規模なクラスターを配置する必要があります。これらのマシンには、高帯域幅のネットワークで相互接続された特殊な AI アクセラレータがあります。 Microsoft では、新しい自然言語の生成と Microsoft 製品全体の機能の理解を可能にするために、Azure でこのようなクラスターを構築してきました。また、その任務で OpenAI を活用して、安全な人工一般インテリジェンスを構築しています。 最新のクラスターでは、世界中で公開されている最大5つのスーパーコンピューターである OpenAI 向けに構築されたコンピューティング能力が非常に多く提供されています。 この cray を使用すると、の OpenAI 公開は、 <a href="https://github.com/openai/gpt-3" target="_blank">1750億パラメーターの GPT 3 モデル</a> と、poetry や翻訳の記述など、特にトレーニングされて &rsquo; いない広範なタスクをサポートする能力を持つことができます。</p>


  <p>大規模なコンピューティングクラスター、最先端のネットワーク設計、ソフトウェアスタック (Azure Machine Learning、ONNX ランタイム、その他の Azure AI サービスを含む) で行った作業は、大規模な戦略で AI に直接合わせて調整されます。 このプロセスによって生成されるイノベーションは、最終的には、スケールに関係なく、すべてのお客様の AI ニーズに対応できるように Azure を強化することです。 たとえば、NDv2 VM シリーズでは、Azure は、NVIDIA &rsquo; s V100 を使用する vm のクラスターを提供する唯一のパブリッククラウドであり、高帯域幅の低待機時間の Nvidia Mellanox InfiniBand ネットワークによって接続されています。 優れたたとえるとして、自動車テクノロジをハイエンドレース業界で開拓にして、毎日ドライブを車にすることができます。</p>


  <h2>かつてない規模の新しいフロンティア</h2>


  <blockquote>

  <p style="margin-left: 40px;"><em> &ldquo; AI を一般インテリジェンスに進化させるには、より多くの機能を備えたモデルをトレーニングできる強力なシステムが必要です。必要なコンピューティング能力は、最近までは不可能でした。Azure AI とその supercomputing 機能によって、進歩 &rdquo; &nbsp; を促進するための主要なシステムが提供</em>され、openai CEO、 -</p>

  </blockquote>


  <p>私たちは、Azure イノベーションの最先端で、新しい ND A100 v4 VM シリーズを発表しています。これ &rsquo; は、最も強力で非常にスケーラブルな AI vm であり、必要に応じて8から数千の vm で相互接続された NVIDIA gpu まで利用できます。</p>


  <p>ND A100 v4 VM シリーズは、1つの仮想マシン (VM) と8つの NVIDIA アンペア A100 を使用して開始されます。ただし、人間の脳が相互接続された neurons で構成されているのと同様に、ND A100 v4 ベースのクラスターは、VM あたり 1.6 Tb/秒の相互接続帯域幅を備えた数千 各 GPU には、独自の専用トポロジである 200 Gb/秒 NVIDIA Mellanox HDR InfiniBand 接続が用意されています。 数十、数百、または数千の Gpu が、Mellanox InfiniBand HDR クラスターの一部として連携して、任意のレベルの AI 視野を実現できます。 AI 目標 (最初からモデルをトレーニングしたり、独自のデータを使用してトレーニングを続行したり、必要なタスクに合わせて微調整したりする) は、GPU から GPU への専用帯域幅16x、その他のパブリッククラウドサービスよりもはるかに高速になります。</p>


  <p>ND A100 v4 VM シリーズは、すべての主要なシステムコンポーネントに組み込まれている PCIe Gen4 のような最新のハードウェア標準を使用して、Azure で設計されたすべての新しい AMD ローマ-powered プラットフォームによって支えられています。 PCIe Gen 4 と NVIDIA &rsquo; s の3世代の NVLINK アーキテクチャでは、各 VM 内の gpu から gpu への最も高速な相互接続に対応しており、システムを通過するデータを以前よりも2倍以上に保つことができます。&nbsp;</p>


  <p>ほとんどのお客様は、エンジニアリング作業を行わずに NVIDIA V100 Gpu に基づいて、以前の世代のシステムに対して 2 ~ 3 倍のコンピューティングパフォーマンスが即座に向上しています。 低密度のアクセラレーションとマルチインスタンス GPU (MIG) を備えた高精度の A100 機能などの新しい機能を利用しているお客様は、最大20倍の向上を実現できます。</p>


  <blockquote>

  <p style="margin-left: 40px;"><em> &ldquo; NVIDIA &rsquo; s の高度なコンピューティングおよびネットワーク機能を利用することで、Azure はクラウドで大規模な AI 用の非常に優れたプラットフォームを構築しました。 &nbsp;NVIDIA A100 GPU の1つのパーティションから、NVIDIA Mellanox Infiniband の相互接続を使用する数千の A100 Gpu に拡張できるエラスティックアーキテクチャにより、Azure のお客様は、世界 &rsquo; で最も厳しい AI ワークロードを実行できます。 &rdquo;  - &nbsp; </em>Buck、General Manager、および NVIDIA での高速コンピューティングの副社長</p>

  </blockquote>


  <p>ND A100 v4 VM シリーズでは、任意のサイズのクラスターを自動および動的に透過的に構成するために、VM Scale Sets のような Azure のコアスケーラビリティブロックを利用しています。 これにより、どこでもどこでも AI を任意のスケールで実現できるようになります。また、必要に応じて数分で AI cray をインスタンス化することができます。 その後、vm に個別にアクセスしたり、Azure Machine Learning サービスを使用してクラスター全体でトレーニングジョブを起動したり管理したりすることができます。</p>


  <p>ND A100 v4 VM シリーズとクラスターは現在プレビュー段階にあり、Azure ポートフォリオでは標準のサービスとなります。これにより、あらゆるユーザーがクラウドで <a href="https://innovation.microsoft.com/en-us/ai-at-scale" target="_blank">大規模な AI</a> の可能性を最大限に引き出すことができます。 詳細については、ローカル Microsoft アカウントチームにお問い合わせください。</p>
