### YamlMime:Yaml
ms.openlocfilehash: 6a14cd88330d4511a16d64d3cada7b30ea4768fe
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139904177"
Slug: from-a-pc-on-every-desktop-to-deep-learning-in-every-software
Title: "\"すべてのデスクトップ上の PC\" から \"すべてのソフトウェアの詳細ラーニング\" まで"
Summary: ディープラーニングは、音声認識、言語の理解、コンピュータービジョンなど、人工知能における最近の多くの頼っの背後にあります。 Microsoft では、Cortana、Bing、Office 365、SwiftKey、Skype 翻訳、Dynamics 365、HoloLens など、多くのアプリケーションやサービスでカスタマーエクスペリエンスを変更しています。
Content: >-
  <p>ディープラーニングは、音声認識、言語の理解、コンピュータービジョンなど、人工知能における最近の多くの頼っの背後にあります。 Microsoft では、Cortana、Bing、Office 365、SwiftKey、Skype 翻訳、Dynamics 365、HoloLens など、多くのアプリケーションやサービスでカスタマーエクスペリエンスを変更しています。 Skype で &nbsp; のディープラーニングベースの<a href="https://www.popsci.com/how-microsofts-machine-learning-breaking-language-barrier" target="_blank">言語翻訳</a>は、人気のあるサイエンスによって<a href="https://www.popsci.com/6-greatest-software-innovations-year" target="_blank">その年の7つの最高のソフトウェアイノベーションの1つ</a>と呼ばれていました。このテクノロジは、会話音声認識で人間レベルのパリティを実現するのに役立っています。 ディープラーニングは、Microsoft Cognitive Toolkit、Cortana Intelligence Suite、Microsoft Cognitive Services、Azure Machine Learning、Bot Framework、Azure Bot Service などの開発プラットフォームのコア機能になりました。 このテクノロジ &nbsp; &ldquo; のアプリケーションは、すべてのソフトウェア &rdquo; の深いラーニングがこの10年以内に現実になるということを信じています。</p>


  <p>&rsquo;洗練された製品を作成し、最も困難なコンピューティングタスクのいくつかを解決できるように、開発者が AI やディープラーニングを使用することを非常に困難にしています。 vigorously は、アルゴリズムやインフラストラクチャを改善し、NVIDIA、openai などのパートナーと緊密に連携して、GPU アクセラレータシステム &rsquo; の機能を活用することにより、最も高速で汎用性の高い AI プラットフォーム &ndash; を真のインテリジェントなクラウドとして Microsoft Azure しています。</p>


  <h2>すべてのユーザーに対してディープラーニング Toolkit を Production-Ready</h2>


  <p><a href="https://cntk.ai/" target="_blank"><strong>Microsoft Cognitive Toolkit</strong></a> (旧称<strong>CNTK</strong>) は、ディープニューラルネットワークを学習および評価するためのオープンソースのクロスプラットフォームツールキットです。 Cognitive Toolkit は、単純なビルディングブロックを複雑なコンピューティングネットワークに構成し、関連するすべてのネットワークの種類とアプリケーションをサポートすることで、任意のニューラルネットワークを表します。 最先端の精度と効率性を備え、マルチ GPU/マルチサーバー環境にスケーリングします。 内部ベンチマークと外部ベンチマークの両方において、Cognitive Toolkit は、ほとんどのテストで他の深いラーニングフレームワークの方が大きくなります。また、特に大規模なデータセットや NVIDIA からの Pascal gpu で作業する場合は、最新バージョンが以前のリリースより高速になります。 &rsquo;これは、シングル gpu パフォーマンスに当てはまりますが、非常に重要なのは、Cognitive Toolkit が多数の gpu を使用するようにスケールアップできることです。 最新のリリースでは、C++ に加えて Python をネイティブにサポートするために Cognitive Toolkit を拡張しまし &rsquo; た。 さらに、この Cognitive Toolkit では、開発者が強化学習を使用してモデルをトレーニングできるようになりました。 最後に、どのような方法でもクラウドにバインド Cognitive Toolkit &rsquo; ません。 クラウドでモデルをトレーニングできますが、オンプレミスまたは他のホスト側でモデルを実行できます。 私たちの目標は、誰でもこの強力なテクノロジを活用できるようにすることです。</p>


  <p>Toolkit をすばやく習得するために、多数 &nbsp; のチュートリアルを使用して<strong>Azure Notebooks</strong>を公開し &rsquo; まし &rsquo; た。また、 <a href="https://www.microsoft.com/en-us/research/product/cognitive-toolkit/model-gallery/" target="_blank"><strong>dnn モデルギャラリー</strong></a>も、さまざまなデータセット (画像、数値、音声、テキスト) を使用したシナリオにわたる多数のコードサンプル、レシピ、チュートリアルで構成されています。</p>


  <h2>他のユーザーの意見</h2>


  <p>2016年9月に公開された<a href="https://www.microsoft.com/en-us/research/product/cognitive-toolkit/model-gallery/" target="_blank"><strong>最新の詳細ラーニングソフトウェアツール &rdquo; ペーパーでは &ldquo; </strong></a> 、教育機関の研究者は、Caffe、Cognitive Toolkit (CNTK)、Torch、およびを含む、最新の GPU アクセラレータのディープラーニングソフトウェアツールを比較調査しています。 &rsquo;これらのツールの実行パフォーマンスは、2つの CPU プラットフォームと3つの GPU プラットフォーム上にある3つの一般的なニューラルネットワークを使用してアプリケーションされました。 この Cognitive Toolkit は、ほぼすべてのワークロードで他のディープラーニングツールキットを凌駕しています。</p>


  <p>さらに、Nvidia は最近、広く普及しているすべてのディープラーニングツールキットを最新のハードウェアと比較してベンチマークを実行しています。 結果には、Cognitive Toolkit では、他の使用可能なツールキットよりも高度な学習アルゴリズムがトレーニングおよび評価され、精度を維持しながら、CPU、gpu、複数の &mdash; コンピューター &mdash; に効率的にスケーリングできることが示されています。 具体的には、SuperComputing &rsquo; 16 カンファレンスで示されている &rsquo; ように、以前のリリースよりも<strong>1.7 倍高速</strong>で、Pascal gpu では<strong>3 倍</strong>高速になりました。</p>


  <p>ディープラーニングソフトウェアツールのエンドユーザーは、適切なハードウェアプラットフォームとソフトウェアツールを選択するためのガイドとして、これらのベンチマーク結果を使用できます。 2つ目の方法として、ディープラーニングソフトウェアツールの開発者にとって、詳細な分析では、将来のパフォーマンスをさらに最適化するための将来の方向性について説明します。</p>


  <h2>実際の深いラーニングワークロード</h2>


  <p>Microsoft では、デジタルエージェントから Azure のコアインフラストラクチャまで、さまざまな内部サービスで深いラーニングと Cognitive Toolkit を使用しています。</p>


  <p><strong>1.</strong><strong>エージェント (Cortana):</strong> Cortana は、すべてのデバイスの作業と有効な設定を把握しているデジタルエージェントです。 Cortana には、1億3300万人以上のユーザーがいて、120億を超える質問がインテリジェントに回答されています。 Cortana &ndash; の音声認識からコンピュータービジョンまで、これらすべての機能はディープラーニングと Cognitive Toolkit によって強化されています。 最近、 <a href="https://blogs.microsoft.com/next/2016/10/18/historic-achievement-microsoft-researchers-reach-human-parity-conversational-speech-recognition/#sm.000006gmppudtudy7yojksy7pwee5" target="_blank">音声認識が大幅に画期的</a>になり、会話内の単語を認識するテクノロジが作成され、professional transcriptionists よりもエラーが発生するようになりました。 研究者は、"5.9%" という単語エラー率 (WER) を6.3% から報告しました。これは、業界標準のメニューの音声認識タスクに対して記録された最も低いエラー率です。 Deep ラーニングを使用した人間のパリティへの到達は、本当に歴史的な成果です。</p>


  <p><img alt="DeepLearning" border="0" height="297" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2d83e81d-a588-442a-8e80-f92f842745fc.png" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto" title="DeepLearning" width="610"></p>


  <p><a href="https://arxiv.org/abs/1512.03385" target="_blank">イメージ認識に対するアプローチ</a>は、まず、ImageNet のいくつかの主要なカテゴリと、コンテキストの課題における Microsoft の共通オブジェクトに配置されています。 ツールで構築された DNNs は、分類、ローカライズ、検出という3つのカテゴリに分類されています。 システムは、非常に深いニューラルネットを正確にトレーニングし、過去 &ndash; よりもはるかに多くの152レイヤー &ndash; を使用しており、新しい &ldquo; 残留知識 &rdquo; を使用していたため、強い余白によって勝利しました。 残存学習は、学習手順を再数式化し、詳細なニューラルネットワークの情報フローをリダイレクトします。 これにより、従来は非常に深いニューラルネットワークを構築しようとした dogged の精度の問題を解決できました。</p>


  <p><strong>2.</strong><strong>アプリケーション:</strong>Office 365、Outlook、PowerPoint、Word、Dynamics 365 のアプリケーションは、ディープラーニングを使用して新しいカスタマーエクスペリエンスを提供できます。 <strong>Microsoft カスタマーサポートおよびサービス</strong>によって使用される、ディープラーニングアプリケーションの優れた例の1つです。 ディープニューラルネットと Cognitive Toolkit を使用すると、お客様が求めている問題をインテリジェントに理解し、それらの問題を解決するための最適なソリューションを推奨します。 Bot は、多くの一般的な顧客の問題に対してセルフサービスのセルフサービスエクスペリエンスを提供し、技術的なスタッフがより困難で困難な顧客の問題に集中できるようにします。</p>


  <p>Deep ラーニングを使用するアプリケーションのもう1つの例は、接続されて<a href="https://blogs.technet.microsoft.com/machinelearning/2016/11/02/connected-drones-3-powerful-lessons-we-can-all-take-away/" target="_blank"><strong>いる drone</strong></a>アプリケーションです (接続されている drone が動作していることを確認するために、<a href="https://www.youtube.com/watch?v=nbMt5hHvpnc" target="_blank">このビデオ</a>をご覧ください)。 <strong>Esmart システム</strong> は、ドローンと <a href="https://azure.microsoft.com/en-us/services/machine-learning/" target="_blank">クラウドインテリジェンス</a> を組み合わせることにより、強力な Conviction から、接続された drone を開発し始めました。 接続された Drone の目的は、グラウンドクルーとヘリコプターによって実行される、現在コストがかかり、リスクが高く、非常に時間のかかる検査ではなく、power grid インフラストラクチャの検査と監視をサポートおよび自動化することです。 これを行うには、ドローンからストリーミングされたビデオデータフィードを分析するために<a href="https://blogs.technet.microsoft.com/machinelearning/2016/09/15/building-deep-neural-networks-in-the-cloud-with-azure-gpu-vms-mxnet-and-microsoft-r-server/" target="_blank">ディープラーニング</a>を使用します。 分析ソフトウェアは、insulators などの個々のオブジェクトを認識し、新しい情報をコンポーネントレジストリに直接リンクします。これにより、インスペクターが潜在的な問題をすぐに認識できるようになります。 eSmart は、接続されている Drone からのデータを分析するためのさまざまなディープラーニングテクノロジを適用します。これは、非常に高速な R CNN からワンショットマルチボックス検出などです。</p>


  <p><strong> 3. Cloud Services (Cortana Intelligence Suite):</strong> azure では、 <a href="https://www.microsoft.com/cognitive-services/en-us/apis" target="_blank"><strong>Cognitive Services</strong></a> (ビジョン、音声、言語、ナレッジ、検索など)、Bot Framework、Azure Machine Learning、Azure Data Lake、azure など、Machine Learning および高度な分析のスイートを提供しています。 データウェアハウスと PowerBI。 Cortana Intelligence Suite と呼ばれます。 これらのサービスを、Cognitive Toolkit または任意の他のディープラーニングフレームワークと共に使用して、インテリジェントなアプリケーションをデプロイすることができます。 たとえば、Azure の <strong>HDInsight Apache Spark</strong> クラスターで事前トレーニング済みの dnn 機械学習モデルを使用してスコアリングを非常に並列化できるようになりました。 多数のイメージで事前トレーニング済みの DNNs をスコア付けするシナリオの数が増えています。たとえば、 <a href="https://blogs.technet.microsoft.com/machinelearning/2016/09/02/microsoft-and-liebherr-collaborating-on-new-generation-of-smart-refrigerators/" target="_blank">DNNs を実行して、冷蔵庫内のオブジェクトを視覚的に認識する顧客 Liebherr</a>などです。 開発者は、わずかな手順でこのような処理アーキテクチャを実装できます (こちらの手順を<a href="https://blogs.technet.microsoft.com/machinelearning/2016/10/31/applying-cloud-deep-learning-at-scale-with-microsoft-r-server-azure-data-lake/" target="_blank">参照してください</a>)。</p>


  <p>一般的な大規模なイメージスコアリングシナリオでは、非常に高い i/o スループットや、大容量のファイルストレージ容量が必要になる場合があります。この場合、 <a href="https://azure.microsoft.com/en-us/services/data-lake-store/" target="_blank"><strong>Azure Data Lake Store</strong></a> (adls) は高パフォーマンスでスケーラブルな分析ストレージを提供します。 さらに、ADLS では、データが必要になるまでスキーマについて心配することができないように、読み取り時にデータスキーマを使用します。 ユーザー &rsquo; の観点からは、ADLS は、指定された hdfs コネクタを介して他の hdfs ストレージアカウントと同様に機能します。 トレーニングは、 <strong>Azure N シリーズ NC24 gpu 対応の仮想マシン</strong> 、または <strong>Azure Batch Shipyard</strong>のレシピを使用して行うことができます。これにより、最大4つの NVIDIA tesla K80 gpu を使用して、パブリッククラウドでのベアメタル GPU ハードウェアアクセラレーションで dnns をトレーニングできます。 スコアリングのために、HDInsight Spark クラスターまたは<a href="https://azure.microsoft.com/en-us/services/data-lake-analytics/" target="_blank"><strong>Azure Data Lake Analytics</strong></a>を使用して、ワーカーノード全体にワークロードを分散することによって、 <strong>Microsoft R Server</strong> (mr) の rxExec 関数で大量のイメージコレクションのスコアリングを非常に並列化できます。 スコアリングワークロードは1つのインスタンスによって調整され、各ワーカーノードは個別に ADLS に対してデータの読み取りと書き込みを同時に行うことができます。</p>


  <p><a href="https://www.microsoft.com/en-us/sql-server/" target="_blank"><strong>SQL Server</strong></a>、プレミアデータベースエンジン &ldquo; も深く &rdquo; 普及しています。 これは、R と ML を初めて<a href="https://www.microsoft.com/en-us/sql-server/sql-server-r-services?wt.mc_id=dx_875446&amp;gclid=CMuZo8rnx9ACFUlNfgodz2gFGA" target="_blank">SQL Server に組み込む</a>ことができるようになりました。 SQL Server 内にディープラーニングモデルをプッシュすると、スループット、並列処理、セキュリティ、信頼性、コンプライアンス認定、管理容易性がすべて1つになります。 データ科学者や開発者 &ndash; &rsquo; にとっては、ML モデルを運用環境にデプロイするために管理レイヤーを個別に構築する必要がないという &rsquo; のが大きなメリットです。 さらに、データベース内のデータを複数のアプリケーションで共有できるのと同様に、ディープラーニングモデルを共有できるようになりました。 &nbsp;モデルとインテリジェンスは、SQL Server 2016 によって管理されるもう1つの種類のデータ &rdquo; になり &ldquo; ます。 これらの機能により、開発者は、ディープラーニングを使用して、データベースの最新のトランザクション処理の進歩を結び付ける新しいアプリケーションを構築できるようになりました。</p>


  <p><strong> 4. インフラストラクチャ (Azure):</strong> <a href="https://channel9.msdn.com/Shows/Azure-Friday/Leveraging-NVIDIA-GPUs-in-Azure" target="_blank">ディープラーニング</a>には、ディープラーニングトレーニングの多くのコンピューティング処理を要する性質をサポートできる高パフォーマンスインフラストラクチャの新しい組み合わせが必要です。 Azure では、現在、パブリッククラウドでの単一および倍精度のワークロードに最適な <a href="https://gpu.azure.com/" target="_blank">NVIDIA&#39;s Tesla K80 gpu</a> が搭載されている N シリーズの仮想マシンを使用できるようになりました。 これらの Gpu は、"デバイスの割り当て" と呼ばれるハードウェアパススルーメカニズムを通じて公開されます。これにより、ほぼベアメタルのパフォーマンスを実現できます。 また、これらのワークロードのデータが増加するにつれて、データ科学者は、1台のサーバーの複数の Gpu だけでなく、複数のノードにわたる複数の Gpu にもトレーニングを配布する必要があります。 Azure は、数十または数百の Gpu にわたるこの分散学習のニーズを実現するために、Mellanox&#39;s InfiniBand fabric を使用して N シリーズのハイエンドネットワークインフラストラクチャに投資しています。これにより、2マイクロ秒未満の待機時間を持つ Vm 間での高帯域幅通信が可能になります。 このネットワーク機能を使用すると、Microsoft&#39;Cognitive Toolkit (CNTK) などのライブラリでノード間の通信に MPI を使用したり、より多くの層と優れたパフォーマンスで効率的にトレーニングしたりすることができます。</p>


  <p>また、このロードマップの最初のイテレーションとして現在の N シリーズを使用して、Azure の優れたクラスロードマップで NVIDIA を扱っています。 これらの Virtual Machines は現在プレビュー段階であり、12月1日以降、このオファリングの一般提供が開始されました。</p>


  <p>Azure でのディープラーニングの使用を簡単に始めることができます。 <a href="https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/" target="_blank"><strong>Data Science Virtual Machine (DSVM)</strong></a>は Azure Marketplace で提供されており、Linux および Windows 用のさまざまなディープラーニングフレームワークとツールがあらかじめ読み込まれています。 多数のトレーニングジョブを並行して実行したり、複数のサーバーにわたって分散ジョブを起動したりするには、上位のフレームワークで<a href="https://azure.microsoft.com/en-us/blog/deep-learning-simulation-and-hpc-applications-with-docker-and-azure-batch/" target="_blank"><strong>Azure Batch &ldquo; Shipyard &rdquo; </strong></a>テンプレートを使用できます。 Shipyard は GPU と InfiniBand ドライバーの構成を処理し、Docker コンテナーを使用してソフトウェア環境をセットアップします。</p>


  <p>最後に、エンジニアや研究者のチームが、Bing と Azure を高速化するために、プログラミング可能な<a href="https://www.wired.com/2016/09/microsoft-bets-future-chip-reprogram-fly/" target="_blank"><strong>フィールド</strong></a>と呼ばれるコンピューターチップを使用するシステムを作成しました。 FPGA チップを利用することで、より効率的ではないソフトウェアを中央の man として使用する代わりに、詳細なラーニングアルゴリズムをハードウェアに直接書き込むことができるようになりました。 &rsquo;さらに、現在 &rsquo; の AI/Deep ラーニングでの新しい進歩に対応したり、データセンター内の別の種類の予期しないニーズに応えたりするために、その後に FPGA を再プログラミングできます。 従来、エンジニアは、仕様が異なるハードウェアを設計および展開するために2年以上待つことがあります。 これは、が成功した &rsquo; moonshot プロジェクトであり、お客様にこれをもたらします。</p>


  <h2>AI の未来を整える</h2>


  <p>詳細なラーニングにおけるイノベーションに重点を置いて、インフラストラクチャ、開発ツール、PaaS サービス、エンドユーザーアプリケーションのスタック全体を取り上げています。 製品によってもたらされる利点をいくつか次に示します。</p>


  <ul>
   <li><strong>汎用性の向上:</strong>Cognitive Toolkit では、1つのフレームワークを使用して、nvidia DGX-1 または nvidia GPU ベースのシステムでオンプレミスのモデルをトレーニングし、そのモデルを Azure 上のクラウドで実行できます。 このスケーラブルなハイブリッドアプローチにより、企業はインテリジェントな機能を迅速にプロトタイプおよびデプロイできます。</li>
   <li><strong>より高速なパフォーマンス:</strong>cpu 上での実行と比較すると、GPU アクセラレータ Cognitive Toolkit では、Azure N シリーズサーバーとオンプレミスで使用可能な NVIDIA gpu でディープラーニングのトレーニングと推定がより高速に実行されます。 たとえば、Pascal と NVLink の相互接続テクノロジを使用する NVIDIA DGX-1 は、CPU サーバーの Cognitive Toolkit と比べて170x 高速です。</li>
   <li>より<strong>広い可用性:</strong>NVIDIA Gpu を搭載した azure N シリーズの仮想マシンは現在、Azure のお客様にプレビュー段階にあり、12月に一般公開される予定です。 Azure Gpu を使用すると、トレーニングとモデルの両方の評価を高速化できます。 既にプレビューの一部となっているお客様は、すべての規模の企業が、Azure N シリーズ Vm の Tesla Gpu でワークロードを実行しています。</li>
   <li><strong>データスタック全体とのネイティブ統合:</strong> データが存在する場所の近くにインテリジェンスをプッシュすることを強く信じています。 数年前に、データベースエンジンまたはビッグデータエンジン内で詳細ラーニングを実行すると、科学の架空のように見えますが、これは現実になりました。 大量のデータ (画像、ビデオ、音声、テキストなど) に対してディープラーニングモデルを実行し、一括して実行できます。 これは、Azure Data Lake、HDInsight、SQL Server によってもたらされる機能の一種です。 さらに、他の種類のデータを使用してディープラーニングの結果を結合し、非常に強力な分析やインテリジェンスを行うこともできます (ここでビッグ認識 &rdquo; を呼び出し &ldquo; ます)。 これ &rsquo; は、一度に1つの認知情報を抽出するだけでなく、抽出されたすべての認知データを他の種類のデータに結合して統合するだけではなく、一見魔法 &ldquo; のような認識 &rdquo; アプリケーションを作成することができます。</li>
  </ul>


  <p>すべての開発者に連絡して、このようにして AI アプリケーションに参加するように依頼しましょう。</p>


  <p><a href="https://www.twitter.com/josephsirosh" target="_blank">@josephsirosh</a></p>
