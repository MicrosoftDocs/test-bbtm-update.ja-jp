### YamlMime:Yaml
ms.openlocfilehash: e4f61bb0d7c019bf1596819103886ed51cb21ced
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139889882"
Slug: cognitive-service-2016-09-08
Title: Microsoft Cognitive Services APIs を使用してライブ ビデオをほぼリアルタイムで分析Cognitive Services APIs
Summary: Microsoft Cognitive Services Vision API は、最新のコンピューター ビジョン アルゴリズムを開発者の手の届く先に置き、個々の画像を分析するための API とオフラインのビデオ処理を行います。 これらの API の組み合わせを使用して、ライブ ビデオ ストリームから撮影されたフレームのほぼリアルタイムの分析を実行できるソリューションを作成する方法を紹介したいと考えます。 理論的には、...
Content: >-
  <p><a href="https://www.microsoft.com/cognitive-services/en-us/apis#vision">Microsoft Cognitive Services Vision API</a>&nbsp;では、最新のコンピューター ビジョン アルゴリズムを開発者の指先に置き、個々の画像を分析するための API とオフラインのビデオ処理を行います。 これらの API の組み合わせを使用して、ライブ ビデオ ストリームから撮影されたフレームのほぼリアルタイムの分析を実行できるソリューションを作成する方法を紹介したいと考えます。 理論的には、ライブ テレビ イベント、人のビデオ、人からの反応を分析するアプリを構築したり、人が感じている可能性がある情報をリアルタイムで提供したりすることができます。</p>

  <p><br>このソリューションは、ビデオ ストリームから有用なデータを生成するアプリを作成する開発者に特に役立ちます。 たとえば、開発者は、10a 人のフォーカス グループの反応を読み取り、それらのユーザーが新しい製品を表示したり、Web サイトを参照したりできるアプリを作成できます。 このソリューションは、ほぼリアルタイムでこれを行います。<br>この投稿では、独自のソリューションを簡単に構築するために、API と公開している C# ライブラリを使用して、ほぼリアルタイムのビデオ分析を実現する方法について説明します。</p>

  <p>

  <p>そのようなシステムの基本コンポーネントは、次のとおりです。</p>

  <ul>

  <li>ビデオ ソースからフレームを取得します。</li>

  <li>分析するフレームを選択します。</li>

  <li>これらのフレームを API に送信します。</li>

  <li>API 呼び出しから返される各分析結果を使用します。</li>

  </ul>

  <p>

  <p>サンプル コードが必要なだけの場合は、次のGitHubできます<a href="https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/">https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/</a>。</p>

  <h3><br>単純なアプローチ</h3>

  <p><br>ほぼリアルタイムの分析システムに対応する最も単純な設計は、無限ループであり、ここでは繰り返しごとに、フレームを取り込み、分析し、続いて結果を消費します。</p>

  <p style="padding-left: 30px;"><br>while (true)<br>{</p>

  <p style="padding-left: 60px;">Frame f = GrabFrame();<br> if (ShouldAnalyze(f))<br> {</p>

  <p style="padding-left: 90px;">AnalysisResult r = await Analyze(f);<br> ConsumeResult(r);</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>分析が軽量のクライアント側アルゴリズムで構成されている場合は、このアプローチが適しています。 ただし、クラウドで分析が行われ、待機時間が関係するということは、API 呼び出しに数秒かかる可能性があります。その間、イメージをキャプチャする必要が生じず、スレッドは基本的に何も行いません。 最大フレーム レートは、API 呼び出しの待機時間によって制限されます。 そのため、API を連携して動作するソリューションが必要です。</p>

  <p>

  <h3>APICalls の&nbsp;並列化</h3>

  <p><br>この問題の解決策は、実行時間の長い API 呼び出しを、フレームをつかむプログラム要素と並行して実行を許可する方法です。 C# では、タスクベースの並列処理を使用してこの目標を達成できます。 次に例を示します。</p>

  <p style="padding-left: 30px;"><br>while (true)<br>{</p>

  <p style="padding-left: 60px;">Frame f = GrabFrame();<br>if (ShouldAnalyze(f))<br>{</p>

  <p style="padding-left: 90px;">var t = Task.Run(async () =&gt;</p>

  <p style="padding-left: 90px;">{</p>

  <p style="padding-left: 120px;">AnalysisResult r = await Analyze(f);</p>

  <p style="padding-left: 120px;">ConsumeResult(r);</p>

  <p style="padding-left: 90px;">}</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>これにより、新しいフレームを引き続きつかみながらバックグラウンドで実行できる個別のタスクで各分析が開始されます。 このソリューションでは、API 呼び出しが返されるのを待っている間にメイン スレッドをブロックしないようにします。ただし、単純なバージョン&mdash;の providedmultiple API 呼び出しが並列で発生し、結果が間違った順序で返される可能性があるという保証の一部が失われました。 これにより、複数のスレッドが ConsumeResult() 関数に同時に入る可能性があります。関数がスレッド セーフではない場合は、危険である可能性があります。 最後に、この単純なコードは作成されたタスクを追跡しないので、例外は自動的に消えます。 したがって、追加する最後のコンポーネントは、分析タスクを追跡し、例外を発生し、実行時間の長いタスクを終了し、結果が正しい順序で一度に 1 回使用される "コンシューマー" スレッドです。</p>

  <p>

  <h3>AProducer-Consumer&nbsp; Design</h3>

  <p><br>最後の「プロデューサー/コンシューマー」システムでは、以前の無限ループに非常に類似したプロデューサー スレッドを使用します。 ただし、分析結果を利用できるとすぐに使用する代わりに、プロデューサーはタスクをキューに入れて追跡します。</p>

  <p style="padding-left: 30px;">API 呼び出しタスクを含むキュー。 <br>var taskQueue = new BlockingCollectionTaskResultWrapper&gt;&lt;&lt;&gt;();</p>

  <p style="padding-left: 30px;">プロデューサー スレッド。 <br>while (true)<br>{</p>

  <p style="padding-left: 60px;">フレームをつかむ。 <br>Frame f = GrabFrame();</p>

  <p style="padding-left: 60px;">フレームを分析するかどうかを決定します。 <br>if (ShouldAnalyze(f))<br>{</p>

  <p style="padding-left: 90px;">このスレッドと並行して実行されるタスクを開始します。 <br> var analysisTask = Task.Run(async () =&gt; <br> {</p>

  <p style="padding-left: 120px;">フレームと結果/例外をラッパー オブジェクトに入れる。<br> var output = new ResultWrapper(f);<br>試す<br>{</p>

  <p style="padding-left: 150px;">出力。Analysis = await Analyze(f);</p>

  <p style="padding-left: 120px;">}<br> catch (例外 e)<br>{</p>

  <p style="padding-left: 150px;">戻り値の出力。</p>

  <p style="padding-left: 120px;">}</p>

  <p style="padding-left: 90px;">}</p>

  <p style="padding-left: 90px;">タスクをキューにプッシュします。<br>taskQueue.Add(analysisTask);</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>また、キューからタスクを削除し、タスクが完了するのを待ち、結果を表示するか、スローされた例外を発生するコンシューマー スレッドも用意されています。 キューを使用することで、システムの最大フレーム レートを制限することなく、結果が正しい順序で一度に 1 回使用される保証が可能になります。</p>

  <h3></h3>

  <h3>実装例</h3>

  <p><br>このブログ記事と共に、上で説明したシステムの実装を利用できます。 これは、このような多くのシナリオを実装するのに十分な柔軟性を備え、使いやすいものにすることを目的としています。 ライブラリには、Web カメラからのビデオ フレームを処理するために前に説明したプロデューサー/コンシューマー システムを実装する FrameGrabber クラスが含まれている。 ユーザーは、正確なフォームの API 呼び出しを指定でき、クラスは、新しいフレームが獲得されたとき、または新しい分析結果が利用可能になったときに呼び出しコードに知らせるためにイベントを使用します。</p>

  <p><br>可能性の一部を説明するために、ライブラリを使用する 2 つのサンプル アプリも公開しています。 1 つ目は単純なコンソール アプリであり、このアプリの簡略化されたバージョンを以下に示します。 既定の Web カメラからフレームを取得し、顔検出のために Face API に送信します。</p>

  <p>using System;<br>VideoFrameAnalyzer を使用する。<br>Microsoft.ProjectOxford.Face を使用する。<br>Microsoft.ProjectOxford.Face.Contract を使用する。</p>

  <p>namespace VideoFrameConsoleApplication<br>{</p>

  <p style="padding-left: 30px;">class Program<br> {</p>

  <p style="padding-left: 60px;">static void Main(string[] args)<br> {</p>

  <p style="padding-left: 90px;">分析の種類が Face[] のグラバーを作成します。 <br> FrameGrabberFace&lt;[]&gt; grabber = new FrameGrabberFace&lt;[]&gt;();<br><br> Face API クライアントを作成します。 ここに Face API キーを挿入します。<br> FaceServiceClient faceClient = new FaceServiceClient("&lt;subscription key&gt;");<br><br> Face API 呼び出しを設定します。<br> グラバー。AnalysisFunction = async frame = return&gt; await faceClient.DetectAsync(frame.Image.ToMemoryStream(".jpg"));<br><br> API 呼び出しから新しい結果を受け取った場合の リスナーを設定します。 <br> グラバー。NewResultAvailable += (s, e) =&gt;<br> {</p>

  <p style="padding-left: 120px;">if (例: Analysis != null)<br> Console.WriteLine("新しい結果が で取得されたフレームに対して受信しました {0}。 {1} faces detected" (Frame.Metadata.Timestamp、Analysis.Length など)</p>

  <p style="padding-left: 90px;">};<br><br> Face API を 3 秒ごとに呼び出す方法をグラバーに伝える。<br> グラバー。TriggerAnalysisOnInterval(TimeSpan.FromMilliseconds(3000));<br><br> 実行を開始します。<br> グラバー。StartProcessingCameraAsync()。Wait();<br><br> keypress が停止するまで待ちます<br> Console.WriteLine("Press any key to stop...");<br> Console.ReadKey();<br><br> 停止し、完了するまでブロックします。<br> グラバー。StopProcessingAsync()。Wait();</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p>}</p>

  <p><br>2 番目のサンプル アプリはもう少し興味深く、ビデオ フレームで呼び出す API を選択できます。 左側には、アプリにライブ ビデオのプレビューが表示されます。右側には、対応するフレームにオーバーレイされた最新の API 結果が表示されます。</p>

  <p>ほとんどのモードで、左のライブ ビデオと右に表示された分析との間に視覚的な遅延が生じます。 この遅延は、API 呼び出しにかかった時間です。 この規則の例外は"EmotionsWithClientFaceDetect" モードです。このモードでは、 <a href="https://opencv.org/">OpenCVbe</a>&nbsp; を使用してクライアント コンピューターで顔検出をローカルで実行します。このモードでは、画像を Cognitive Services に送信する前に、クライアント コンピューターで顔検出を実行します。 こうすることで、検出した顔をすぐに表示し、その後 API 呼び出しが戻ったときに後から感情を更新できます。 これは、クライアントで単純な処理を実行できる "ハイブリッド" アプローチの可能性を示しています。その後、Cognitive Services APIs を使用して、必要に応じてより高度な分析でこのアプローチを拡張できます。</p>

  <p><img width="711" height="543" alt="" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/image.png"></p>

  <p>この投稿では、ライブ ビデオ ストリームでほぼリアルタイムの画像分析を実行する可能性と、サンプル コードを使用して作業を開始する方法について説明しました。 以下のコメント、<a href="https://cognitive.uservoice.com/">UserVoicesite</a>&nbsp;、またはサンプル コードの GitHub リポジトリでフィードバック<a href="https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/">や</a>&nbsp;提案をお寄せください。</p>
