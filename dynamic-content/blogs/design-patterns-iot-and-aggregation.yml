### YamlMime:Yaml
ms.openlocfilehash: 78118dc4d31dca0cea263d791a849736ee55b7d2
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896014"
Slug: design-patterns-iot-and-aggregation
Title: 設計パターン – IoT と集計
Summary: この設計パターンでは、スループットが高い IoT データを挿入し、さまざまなフィールドで集計を行う方法について学習します。
Content: "<p>この記事では、高スループットの IoT データを挿入し、レポート用にさまざまなフィールドで集計を使用する方法について学習します。 この設計パターンを理解するには、<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/\">Azure Cosmos DB</a> について既に理解し、変更フィード、要求<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/request-units\">ユニット (RU</a>)、および Azure Functions を<a href=\"https://azure.microsoft.com/en-us/services/functions/\">理解している必要があります</a>。<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed\"></a> これらが新しい概念である場合は、上記のリンクに従ってそれらの詳細を確認してください。</p>\n\n<p>多くのデータベースは、データをパーティション分割するために、非常に高いスループットと低待機時間を実現します。 これは、MongoDB、HBase、Cassandra、Azure Cosmos DB など、すべての NoSQL データベース エンジンに当てはCosmosです。 パーティション分割またはシャーディングのため、これらのデータベースはすべて無制限にスケールアウトできます。</p>\n\n<p>Azure Cosmos DB について詳しく見てみしましょう。 トップ レベルでは、コンテナーが定義されています。 コンテナーはテーブル、コレクション、またはグラフと考できますが、これはすべての情報を保持するメイン エンティティです。 Azure Cosmos DB &ldquo;&rdquo; は、\"コンテナー\" という単語を使用してこの上位エンティティを定義します。また、Azure Cosmos DB はマルチモデル データベースなので、このコンテナーは SQL、MongoDB、および Graph API のコレクション、Cassandra API または Table API のテーブルと同義です。</p>\n\n<p>コレクションには、コレクションのスループット要件に基づいて割り当てられる多数の物理パーティションがあります。 現在、10000 RU では 10 個のパーティションを取得できますが、この数は明日変更される可能性があります。 必要なスループットに常に集中する必要があります。また、割り当てられたパーティションの数を気にしないでください。このパーティションの数は、データ使用量によって変化します。</p>\n\n<p>高スケールのスループットと低待機時間を実現するには、データの挿入中にパーティション キーと行キーを指定し、データの読み取り中に同じパーティション キーと行キーを使用する必要があります。 適切なパーティション キーを選択した場合、データはすべてのパーティションに均等に分散され、読み取り操作と書き込み操作は 1 桁ミリ秒で行えます。</p>\n\n<p>内部的には、Azure Cosmos DB ではハッシュベースのパーティション分割が使用されます。 何か項目を書き込むと、Azure Cosmos DB がパーティション キー値をハッシュし、そのハッシュした結果を基に項目の格納先のパーティションを決定します。 次の図に示すように、優れたパーティション キーを使用すると、使用可能なすべてのパーティション間でデータが均等に分散されます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4085ed78-4f92-4ab6-b760-afb5976e3ed8.png\"><img alt=\"GoodPartition\" border=\"0\" height=\"282\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/83d636ea-ff05-4fdd-bdae-542e720900ee.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"GoodPartition\" width=\"319\"></a></p>\n\n<p align=\"center\"><em>良好なパーティション キー、データが均等に分散される</em></p>\n\n<p>パーティション キーと物理パーティションの間に&rsquo; 1 対 1 のマッピングが存在しません。つまり、1 つの物理パーティションに多数のキーを格納できます。 これは、 が論理概念 (パーティション キー) であり、もう一方が物理的な概念であるためです。 多くの場合、初心者ユーザーは、パーティション キーが物理パーティションと等しいと考える場合があります。 1 つは論理的な概念であり、もう 1 つは物理的な概念であり、1 つは 1 つの概念にマップされません。 各キーはハッシュされた後、剰余演算子を使用してパーティションにマップされます。 各論理パーティションには 10 GB のデータを格納できます。この制限は将来変更される可能性があります。データが 10 GB を超える場合は自動的に分割されます。 パーティションを自分で分割する必要は一度もありませんが、Azure Cosmos DB では背後で行います。 ただし、10 GB を超えるデータを持つ可能性があるパーティション キーを持つ必要があります。&nbsp;</p>\n\n<div style=\"background: rgb(238, 238, 238); padding: 5px 10px; border: 1px solid rgb(204, 204, 204); border-image: none; text-align: center;\"><em>100 万パーティション キーでは、100 万の物理パーティションは作成しません。</em></div>\n\n<p>次に、&rsquo;例を見てみます。 あなたは、温度を維持するために IoT デバイスをビルにインストールし、世界中に数十万人の顧客を持つ IoT 企業で働いている。 各顧客には、毎分温度を更新する何千もの IoT デバイスがあります。 Lets&rsquo; は、データの外観を定義します。</p>\n\n<pre>\n{\n     CustomerId: Microsoft,\n     DeviceId: XYZ-23443,\n     Temperature: 68\n     DateTime: 32423512\n}</pre>\n\n<p>Imagine国にオフィスを持ち、100,000 台の IoT デバイスを分散しているグローバル企業である顧客がいます。 これらのデバイスは、1 日の合計 2 GB に対して 1 分ごとに 2 KB のデータを送信しています。 このレートでは、パーティションを 5 日で埋め込む可能性があります。 Time to Live (TTL)&rsquo; メカニズムを使用してデータを自動的に削除できますが、この例では、このデータを 30 日間保持する必要がある場合を想定します。</p>\n\n<p>パーティション キーとして &ldquo;CustomerId&rdquo; を選択すると、大規模な顧客に対してデータが偏り、パーティションは次のように表示されます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/97f84165-5f51-4c68-bd3a-0526e3611106.png\"><img alt=\"BadPartition\" border=\"0\" height=\"284\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6a8bbc4a-8676-430c-9740-2f6b0bed4ed8.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"BadPartition\" width=\"324\"></a></p>\n\n<p>また、この種のパーティション分割では、数千もの IoT &ldquo;デバイスを持ち、CustomerId&rdquo; でパーティション分割されたコレクションにデータを挿入している大規模な顧客に対して調整が作成されます。 なぜ調整されるのか疑問に思う場合があります。 それを理解するために、コレクションが 5,000 RU/秒と定義され、5 つのパーティションがある場合を想像してください。 つまり、各パーティションのスループットには 1,000 RU を設定できます。</p>\n\n<p>ここでは 5 つのパーティションについて説明しましたが、この数はここでも説明&#39;です。 この数は、スループットに関して将来変更される可能性があります。 ハードウェアの変更により、明日は 3 つのパーティションまたは 5,000 RU 用に 1 つを取得できます。 これらの物理パーティションは一定ではなく、データが拡大し続けるので自動的に分割されます。</p>\n\n<p>ユーザーは多くの場合、この間違いを行い、5000 RU のコレクションをプロビジョニングした場合でも、2000 RU で調整されているという不満を示します。 このシナリオでは、主な問題は、データが適切にパーティション分割されていないと、2000 RU を 1 つのパーティションに挿入しようとしている点です。 これが、すべてのパーティションにデータを均等に分散できる優れたパーティション キーを持つ必要がある理由です。</p>\n\n<p>CustomerId &ldquo;が優&rdquo; れたパーティション キーではない場合は、他にどのようなキーを使用できますか? また、DateTime&rdquo; でデータを&ldquo;パーティション分割する必要はありません。これにより、ホット パーティションが作成されます。 Imagineにパーティション分割した場合、特定の分の間、すべての呼び出しが 1 つのパーティションにヒットします。 顧客のデータを取得する必要がある場合は、データがすべてのパーティションに分散される可能性があるという理由で、ファンアウト クエリになります。</p>\n\n<p>適切なパーティション キーを選択するには、読み取りまたは書き込みのシナリオを考え、最適化する必要があります。 より単純なシナリオでは、読み取りと書き込みの両方のシナリオでパーティション キーを取得できます。 ただし、そうではない場合は、セキュリティを侵害し、シナリオの 1 つを最適化する必要があります。</p>\n\n<p>この記事では、読み取りと書き込みの両方に対して 1 つの適切なパーティション キーがないシナリオについて説明します。 読&rsquo;み取り要件と書き込み要件の両方を満たすために何が可能かを確認します。</p>\n\n<p>このシナリオでは、データを送信するデバイスの数が多いので、書き込み用に最適化する必要があります。 高速インジェストのパーティション キーとして &ldquo;DeviceId&rdquo; を使用してコレクションを定義する方法が最適です。 &ldquo;DeviceId&rdquo; は一意であるだけでなく、CustomerId よりも詳細 &ldquo;です&rdquo;。 データがすべてのパーティションに分散されるので、カーディナリティまたは一意性の高いキーを常に探します。 ただし、レポートの場合、CustomerId に対して集計を行う場合 &ldquo;は、どうしますか&rdquo;?</p>\n\n<p>これは、このブログの crux です。 挿入シナリオのデータをパーティション分割し、レポート シナリオの別のパーティション キーにデータをグループ化する必要があります。 残念ながら、これらは不一致の要件です。</p>\n\n<p>Imagineを使用してデータを挿入しました。&ldquo;パーティション キーとしての DeviceId&rdquo; ですが&ldquo;、温度と CustomerId&rdquo; でグループ化する場合は、クエリはクロスパーティション クエリになります。 クロスパーティション クエリは、しばらくの間は問題はありません。 すべてのデータは Azure Cosmos DB では既定でインデックス付けされます。パーティション間クエリは必ずしも悪いことではありません。ただし、コストがかかる可能性があります。 クロスパーティション クエリでは、ポイント参照よりもはるかに RU/s のコストがかかります。</p>\n\n<p>この問題を解決するには、2 つのオプションがあります。 最初のオプションは、Azure Cosmos DBs&rsquo; 変更フィードと Azure 関数&ldquo;を使用して時間単位でデータを集計し、その集計データを別のコレクションに格納することです。CustomerId&rdquo; はパーティション キーです。</p>\n\n<p align=\"center\"><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/9cc6fc70-8168-48b8-8fcb-15d07f348a0d.png\"><img alt=\"ChangefeedReporting\" border=\"0\" height=\"485\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4f2cbe68-b86c-4f65-9740-3a2a165f4fa5.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"ChangefeedReportingChange\" width=\"533\"></a> <em>フィード</em></p>\n\n<p>1 時間あたりのレポートの変更フィードを再度リッスンして、1 日あたりのデータを集計し、その集計を 1 日あたりの別の Azure Cosmos DB レポートに格納できます。 IoT デバイスは、データを DB に直接Cosmosします。 このパターンは、変更フィードが理由で可能です。 変更フィードでは、DB のログCosmosされます。 変更フィードには、コレクション内のドキュメントに対して行われた挿入操作と更新操作が含まれます。 詳細については、変更フィード <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed\">に関する記事を参照してください</a>。 ただし、変更フィードは、すべてのアカウントとすべてのコレクションに対して既定で有効になっています。</p>\n\n<p>変更フィードと Azure 関数の使い方の詳細については、この画面キャストを <a href=\"https://www.youtube.com/watch?v=iprndNsUeeg&amp;t=459s\">確認してください</a>。</p>\n\n<p>2 つ目のオプションは、Spark を使用して集計を行い、SQL データ ウェアハウスまたはパーティション キーが CustomerId である 2 番目のコレクションに集計値を保持することです。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/89cf5def-0143-49de-910b-1b7201e61e2e.png\"><img alt=\"ChangefeedSpark\" border=\"0\" height=\"291\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f72b720a-08ef-4cb5-8fe7-66b8ba87ae5e.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"ChangefeedSparkThis\" width=\"427\"></a> オプションでも変更フィードが使用されます。 Spark から、直接接続して変更フィードを取得し、Spark のすべての変更をリアルタイムで取得できます。 データが Spark に入った後は、集計を実行し、そのデータを Azure Cosmos DB に書き戻したり、SQL Data Warehouse。</p>\n\n<p>Azure Cosmos DB からデータを読み取り、集計を実行してデータを書き戻す Spark のコード スニペットを次に示します。</p>\n\n<pre>\n# Base Configuration\niotConfig = {\n&quot;Endpoint&quot; : &quot;https://xx.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; : &quot;E0wCMaBIz==&quot;,\n&quot;Database&quot; : &quot;IoT&quot;,\n&quot;preferredRegions&quot; : &quot;Central US;East US2&quot;,\n&quot;Collection&quot; : &quot;IoT&quot;,\n&quot;checkpointLocation&quot; : &quot;dbfs://checkpointPath&quot;\n}\n# Connect via Spark connector to create Spark DataFrame\niot_df = spark.read.format(&quot;com.microsoft.azure.cosmosdb.spark&quot;).options(**iotConfig).load()\niot_df.createOrReplaceTempView(&quot;c&quot;)\npsql = spark.sql (&quot;select DeviceId, CustomerId, Temp from c&quot;)\n \nwriteConfig = {\n&quot;Endpoint&quot; : &quot;https://xx.documents.azure.com:443/&quot;,  \n&quot;Masterkey&quot; : &quot;E0wCMaBKdlALwwMhg==&quot;,\n&quot;Database&quot; : &quot;IoT&quot;,\n&quot;preferredRegions&quot; : &quot;Central US;East US2&quot;,\n&quot;Collection&quot; : &quot;MV&quot;,\n&quot;Upsert&quot; : &quot;true&quot;\n     }\niot_df.createOrReplaceTempView(&quot;c&quot;)\npsql = spark.sql (&quot;select CustomerId, avg(temp) as Temp_Avg from c group by c.CustomerId &quot;)\npsql.write.format(&quot;com.microsoft.azure.cosmosdb.spark&quot;).mode(&#39;append&#39;).options(**writeConfig).save()</pre>\n\n<p>Azure <a href=\"https://www.youtube.com/watch?v=P9Qz4pwKm_0&amp;t=1559s\">Cosmos DB</a> で Spark を使用する方法については、画面キャストを確認してください。</p>\n\n<p>どちらのオプションでも、ライブ変更フィードをリッスンすることで、分単位の集計を行います。 レポートの要件に応じて、異なるコレクションまたは同じコレクション内の異なるレベルで異なる集計を保持できます。 これは、これらの集計値をデータ ウェアハウスに保持するSQLオプションです。</p>"
