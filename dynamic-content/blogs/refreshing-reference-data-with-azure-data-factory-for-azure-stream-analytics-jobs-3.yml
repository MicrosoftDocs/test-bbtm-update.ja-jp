### YamlMime:Yaml
ms.openlocfilehash: f5d7a991da6eebd5d03bfbb532caae0310228fb1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139910476"
Slug: refreshing-reference-data-with-azure-data-factory-for-azure-stream-analytics-jobs-3
Title: Azure Data Factory ジョブの Azure Stream Analytics更新
Summary: このAzure Data Factoryを利用して、さまざまなデータ ストアから参照データをプルし、スケジュールに基いて更新して、ストリーム分析ジョブの入力として提供します。
Content: >-
  <p align="justify">多くの場合<a href="https://azure.microsoft.com/en-us/documentation/articles/stream-analytics-connect-data-event-inputs/#reference-data-inputs"><u>&ldquo;&rdquo;</u></a>&nbsp;、デバイスなどの受信イベント ストリームに参加したい場合は、ストリーム分析ジョブの一部として、クエリのデバイス プロファイルやcustomer <a href="https://azure.microsoft.com/en-us/documentation/services/stream-analytics/"></a>&nbsp;プロファイル情報など、変化の遅い参照データを含むセンサー測定が必要です。 これにより、ストリーム ジョブによって生成された分析情報に関する拡張レポートを作成できます。 この投稿と付随するサンプルでは、Azure Data Factory を利用してさまざまなデータ ストアから参照データをプルし、スケジュールに基づいて更新し、ストリーム分析ジョブへの入力として提供する方法を示します。</p>


  <h2 align="justify">データの参照データのAzure Stream Analytics</h2>


  <p align="justify">Stream Analytics、Azure BLOB ストレージに格納されている参照データをジョブの入力 <a href="https://azure.microsoft.com/en-us/documentation/articles/stream-analytics-connect-data-event-inputs/">&ldquo;の 1 つとして&rdquo;</a> 取得できます。 参照データの更新のサポートを有効にするには、ユーザーは、パスのパターン内で {date} および {time} トークンを使用して、入力構成で BLOB のリストを指定する必要があります。 ジョブは、UTC タイム ゾーンを使用して BLOB 名にエンコードされた日時に基づいて、対応する BLOB を読み込みます。</p>


  <p align="left">たとえば、日付形式が YYYYY/MM/DD&rdquo; &ldquo;で、時刻形式が HH/mm&rdquo; である場合、ジョブにパス パターン (/referencedata/{date}/{time}/customertable.csv など) &ldquo;が構成されている場合、 job は、2015 年 7 月 26 日午前 8 時 30 分 (UTC タイム ゾーン) に/referencedata/2015/07/26/08/30/customertable.csv という名前のファイルを取得します。</p>


  <p align="justify">これには、お客様は次の 2 つの課題&nbsp;に対処する必要があります。</p>


  <ol>
   <li>
   <div align="justify">参照データが Azure BLOB 以外のデータ ストアにある場合は、Azure BLOB に移動する必要があります。</div>
   </li>
   <li>
   <div align="justify">参照データの変更頻度は比較的低い一方で、変更される場合があります。 適切なパスとデータ時間情報&nbsp;を使用して Azure BLOB で参照データを取得および削除するように、定期的な更新スケジュールを設定する必要があります。</div>
   </li>
  </ol>


  <h2 align="justify">さまざまなデータ ストアからの参照データを更新するには、次のAzure Data Factory</h2>


  <p align="justify"><a href="https://azure.microsoft.com/en-us/documentation/services/data-factory/">Azure Data Factory</a> は、上記の課題に最適なソリューションです。 Azure Data Factoryは、データの移動と変換を調整および自動化するクラウドベースのデータ統合サービスです。&nbsp;多数&nbsp;のクラウド ベース<a href="https://azure.microsoft.com/en-us/documentation/articles/data-factory-data-movement-activities/"></a>&nbsp;およびオンプレミスのデータ ストアに接続し、指定した定期的なスケジュールに基づいてデータを簡単に移動できます。</p>


  <p align="justify">例&#39;を見てみしましょう。</p>


  <p align="justify">「&nbsp;<a href="https://azure.microsoft.com/en-us/documentation/articles/stream-analytics-get-started/">Steam Analytics はじめに</a> ガイド」では、通話レコード データがストリーミング形式で大規模に処理され、SIM カードの不正が分析される通信会社のシナリオが示されています (同じ ID から同じ ID から同じ場所で複数回呼び出されるが、地理的に異なる場所で複数回呼び出される)。 このシナリオのストリーム分析ジョブは 1 つの入力を受け取り、ストリーミング呼び出しでは EventHub を介してデータが記録されます。 ここで、別の入力を追加し、顧客 (customerInfo テーブル) に関する情報 (名前、連絡先情報など) を含むデータを参照するとします。 これにより、不正な呼び出しを検出して不正行為の影響を受けている顧客を特定する、ストリーミング クエリで customertInfo テーブルに対する結合を追加できます。 また、customerInfo テーブルが Azure SQL データベースに保持され、新しい顧客が追加された場合、連絡先情報が変更された場合などに、1 日に複数回更新できるとします。</p>


  <p align="justify">次の図は、Azure Data Factory と Stream Analytics を組み合わせて使用して、参照データを使用して上記のクエリを実行し、スケジュールに従って参照データの更新を設定する高レベルのソリューション アーキテクチャを示しています。</p>


  <p align="justify">&nbsp;</p>


  <p align="justify"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cebce617-25a1-46f0-89f0-ead26500d170.png"><img alt="referencedatarefreshdiagram6" border="0" height="709" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0ea18b90-df28-4ae8-a6d4-b1d6bde326d5.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-top-width: 0px" title="referencedatarefreshdiagram6" width="1323"></a></p>


  <p align="justify">&nbsp;</p>


  <p align="justify">&nbsp;上に示したように、コピー アクティビティを含むデータ ファクトリ パイプラインを作成できます。このパイプラインでは、日付と時刻の情報に基づいて、最新バージョンの customertable を Azure SQL&nbsp; から対応するパス内の BLOB にコピーします。 このAzure Stream Analyticsは&nbsp;、参照データ入力として customertable を受け取り、参照データの最新のコピーが使用可能になったら常に取得するように構成されます。</p>


  <p align="justify">&nbsp;上記のサンプルの設定と参照データをコピーするデータ ファクトリのセットアップ方法の詳細については、GitHub の <a href="https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ReferenceDataRefreshForASAJobs">Azure Stream Analytics</a> ジョブ サンプルの参照データ更新に関するページを参照してください。</p>
