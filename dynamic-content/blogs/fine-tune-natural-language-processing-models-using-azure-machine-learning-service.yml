### YamlMime:Yaml
ms.openlocfilehash: ac716b87c61b43b3ec56a6336697d4d0a87ed9ba
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139910791"
Slug: fine-tune-natural-language-processing-models-using-azure-machine-learning-service
Title: サービスを使用して自然言語処理モデルを微調整Azure Machine Learningする
Summary: 自然言語処理 (NLP) ドメインでは、従来、事前トレーニング済みの言語表現は、名前付きエンティティ認識 (Sang と Meulder、2003)、質問の回答 (Rajpurkar et al.、2016)、構文解析 (McClosky et al.、 2010) など、いくつかの重要な使用事例の重要なトピックでした。
Content: >-
  <p><em>このブログ記事は、Li Li、ソフトウェア エンジニア II、Todd Hendry(Microsoft AI Platform のプリンシパル ソフトウェア エンジニア) によって共同執筆されました。</em></p>


  <div style="background:#eee;border:1px solid #ccc;padding:5px 10px;"><strong>更新日: 2019 年 7 月 17 日:</strong>お客様が Azure Machine Learning Service &ldquo; を使用して BERT モデルを事前トレーニングする方法について説明します。ブログ記事「Microsoft では、一般的な言語表現モデル BERT を大規模に簡単に構築できます」を参照<a href="https://azure.microsoft.com/en-us/blog/microsoft-makes-it-easier-to-build-popular-language-representation-model-bert-at-large-scale/" target="_blank">してください</a>。&rdquo;</div>


  <p>自然言語 <a href="https://arxiv.org/pdf/cs/0306050.pdf" target="_blank">処理 (</a> NLP) ドメインでは、従来、事前トレーニング済みの言語表現は、名前付きエンティティ認識 (Sang と Meulder、2003)、質問の <a href="https://arxiv.org/pdf/1606.05250.pdf" target="_blank">回答 (</a> Rajpurkar et al.、2016)、構文 <a href="https://nlp.stanford.edu/~mcclosky/papers/dmcc-naacl-2010.pdf" target="_blank">解析 (</a> McClosky et al.、 2010) など、いくつかの重要な使用事例の重要なトピックでした。</p>


  <p>事前トレーニング済みのモデルを利用する直感は単純です。大規模なコーパス (たとえば、すべての Wikipedia データ) でトレーニングされたディープ ニューラル ネットワークには、異なる単語と文の間の基になる関係に関する十分な知識が必要です。 また、最初からトレーニングするよりもパフォーマンスが優れた、医療分野や財務分野など、別のドメインに簡単に適応できる必要があります。</p>


  <p>&ldquo;最近、<a href="https://arxiv.org/abs/1810.04805" target="_blank">BERT: トランス</a>&rdquo;フォーマーからの双方向エンコーダー表現という論文が Devlin 氏らによって公開されました。これは、前述の事前トレーニング済みのアプローチを使用して、11 の NLP タスクで新しい最先端の結果を達成します。 この技術ブログの投稿では、お客様が Azure Machine Learning Services を使用してカスタム アプリケーションの BERT を効率的かつ簡単に微調整する方法を示したいと考えています。 このコードは、<a href="https://github.com/Microsoft/AzureML-BERT" target="_blank">GitHub。</a></p>


  <h2>BERT の背後にある直感</h2>


  <p>新しい言語モデル BERT の背後にある直感は、シンプルでありながら強力です。 研究者は、十分な大きなトレーニング コーパスを持つ十分な大きなディープ ニューラル ネットワーク モデルによって、コーパスの背後にある関係をキャプチャできると信じています。 NLP ドメインでは、大きな注釈付きコーパスを取得するのは難しいので、研究者は新しい手法を使用して多くのトレーニング データを取得しました。 &ndash;研究者は、人間にコーパスのラベルを付け、ニューラル ネットワークにフィードするのではなく、インターネットで利用できる大規模な<a href="https://arxiv.org/abs/1506.06724" target="_blank">コーパス BookCorpus (Feed</a>、Kiros など) と English Wikipedia (それぞれ 800M と 2,500M の単語) を使用します。 言語モデルのラベルを生成するには、言語タスクごとに 2 つの方法が使用されます。</p>


  <ul>
   <li><strong>マスクされた言語モデル: </strong>単語間の関係を理解する。 重要な考え方は、文内の単語の一部 (約 15%) をマスクし、それらのマスクされた単語をラベルとして使用して、モデルが単語間の関係を強制的に学習する方法です。 たとえば、元の文は次のようになります。</li>
  </ul>


  <pre>

  The man went to the store. He bought a gallon of milk.</pre>


  <p>言語モデルとの入力/ラベルのペアは次の条件を持っています。</p>


  <pre>

  Input: The man went to the [MASK1]. He bought a [MASK2] of milk.

  Labels: [MASK1] = store; [MASK2] = gallon</pre>


  <ul>
   <li><strong>文予測タスク:</strong> 文間の関係を理解する。 このタスクでは、文 B が特定の文 A に続く次の文になる可能性が高いかどうかをモデルに予測します。上記と同じ例を使用して、次のようなトレーニング データを生成できます。</li>
  </ul>


  <pre>

  Sentence A: The man went to the store.

  Sentence B: He bought a gallon of milk.

  Label: IsNextSentence</pre>


  <h2>カスタマイズされたデータセットへの BERT の適用</h2>


  <p>上記の手順を使用して大規模なコーパス (利用可能なすべての英語 Wikipedia など) で BERT をトレーニングした後は、データセットが膨大なので、モデルは英語に関する多くの知識を継承できるという前提があります。 次の手順では、モデルが新しいドメインにすばやく適応することを期待して、さまざまなタスクでモデルを微調整します。 重要なアイデアは、上記でトレーニングした大規模な BERT モデルを使用し、さまざまな種類のタスクに対して異なる入力/出力レイヤーを追加する方法です。 たとえば、カスタマー サポート部門のセンチメント分析を行う場合があります。 これは分類の問題なので、(下の図の左側に示すように) 出力分類レイヤーを追加し、入力を構造化する必要がある場合があります。 別のタスク (質問の回答など) では、入力が質問で対応する段落である別の入力/出力レイヤーを使用する必要がある場合があります。一方、出力は質問の開始/終了の回答範囲です (右側の図を参照)。 それぞれの場合、BERT の設計方法を使用すると、データ サイエンティストはさまざまなレイヤーを簡単に接続して、BERT をさまざまなタスクに適応できます。</p>


  <p align="center"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/39717ecf-8274-46c4-862d-21ca377b1957.png"><img alt="Adapting BERT for different tasks displayed in a diagram" border="0" height="297" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dedc7d55-ee14-40eb-ac37-7eec5fa5a932.png" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="BERT 図" width="701"></a></p>


  <p align="center"><em>図 1。さまざまなタスクに BERT を適用する (</em><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank"><em>ソース</em></a><em>)</em></p>


  <p>次の図は、NLP フィールドで最も一般的なデータセットの 1 つ、1 つの、立ち答えデータセット <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank">(SQuAD)</a> の結果を示しています。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c37ee936-a5d2-4878-b8e2-ffc02a2797f2.png"><img alt="Reported BERT performance on SQuAD 1.1 dataset" border="0" height="413" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cded75a5-7a9a-46c5-a8b7-912c336999a6.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="SQuAD 1.1 データセットで報告された BERT パフォーマンス" width="419"></a></p>


  <p align="center"><em>図 2。SQuAD 1.1</em> データセット (ソース) で BERT パフォーマンスが報告<a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank"><em>されました</em></a><em>。</em></p>


  <p>特定のタスクの種類によっては、非常に異なる入力/出力レイヤーの組み合わせを追加する必要がある場合があります。 GitHub リポジトリでは、General <a href="https://gluebenchmark.com/" target="_blank">Language Understanding Evaluation (GLUE) (</a>2018 年)と<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank">、</a>2018 年 12 月に 2 つのタスクを示しました。</p>


  <h2>Azure Machine Learning サービスの使用</h2>


  <p>さまざまなデータセットに対するさまざまな実験を示します。 さまざまな使用例に合わせてさまざまなハイパーパラメーターを調整できるだけでなく、Azure Machine Learning サービスを使用して、実験のライフサイクル全体を管理できます。 Azure Machine Learningサービスは、エンドツーエンドのクラウドベースの機械学習環境を提供します。そのため、お客様は次に示すように、機械学習モデルの開発、トレーニング、テスト、デプロイ、管理、追跡を行えます。 また、後で使用する PyTorch や TensorFlow などのオープンソース テクノロジも完全にサポートされています。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/63c559d5-e0af-4af2-9fa1-2bdd9487c960.png"><img alt="Azure Machine Learning Service overview diagram" border="0" height="544" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/07ebbbb6-0fd4-40a6-b4e6-c9d0b11cf159.png" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="Azure Machine Learning サービスの概要図" width="1430"></a></p>


  <p align="center"><em>図 3。Azure Machine Learning サービスの概要</em></p>


  <h2>ノートブックの情報</h2>


  <h3>特定のタスクに適切なモデルを定義する</h3>


  <p>BERT モデルを微調整するには、最初の手順として、適切な入力層と出力層を定義します。 GLUE の例では、分類タスクとして定義されています。コード スニペットは、BERT 事前トレーニング済みモデルを使用して言語分類モデルを作成する方法を示しています。</p>


  <pre>

  model = modeling.BertModel(
       config=bert_config,
       is_training=is_training,
       input_ids=input_ids,
       input_mask=input_mask,
       token_type_ids=segment_ids,
       use_one_hot_embeddings=use_one_hot_embeddings)

  logits = tf.matmul(output_layer, output_weights, transpose_b=True)

  logits = tf.nn.bias_add(logits, output_bias)

  probabilities = tf.nn.softmax(logits, axis=-1)

  log_probs = tf.nn.log_softmax(logits, axis=-1)

  one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)

  per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)

  loss = tf.reduce_mean(per_example_loss)</pre>


  <h3>サービスを使用してトレーニング環境Azure Machine Learningする</h3>


  <p>データセットのサイズによっては、実際のデータセットでのモデルのトレーニングに時間がかかる場合があります。 Azure Machine Learningコンピューティングでは、トレーニング プロセスを加速するために、1 つのノードまたは複数のノードの GPU にアクセスできます。 コンピューティングに 1 つ以上のノードを持つクラスター Azure Machine Learning、次のように非常に直感的です。</p>


  <pre>

  compute_config = AmlCompute.provisioning_configuration(vm_size=&#39;STANDARD_NC24s_v3&#39;,
                                                           min_nodes=0,
                                                           max_nodes=8)
  # create the cluster

  gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)

  gpu_compute_target.wait_for_completion(show_output=True)

  estimator = PyTorch(source_directory=project_folder,
                   compute_target=gpu_compute_target,
                   script_params = {...},
                   entry_script=&#39;run_squad.azureml.py&#39;,
                   node_count=node_count,
                   process_count_per_node=process_count_per_node,
                   distributed_backend=&#39;mpi&#39;,
                   use_gpu=True)</pre>

  <p>Azure Machine Learningは、分散トレーニング ジョブの設定と実行に関連する作業を大幅に簡素化します。 ご覧のように、ジョブを複数のワーカーにスケーリングするには、構成内のノードの数を変更し、分散バックエンドを提供します。 分散バックエンドの場合、Azure Machine Learning は TensorFlow パラメーター サーバーや Horovod を使用した MPI などの一般的なフレームワークをサポートし、InfiniBand などの Azure ハードウェアと連携して、さまざまなワーカー ノードを接続して最適なパフォーマンスを実現します。 NLP モデルを微調整するために、Azure Machine Learning サービスで分散トレーニング機能を使用する方法に関するブログ投稿をフォローアップします。</p>


  <p>モデル トレーニング用のコンピューティング先を作成および設定する方法の詳細については、ドキュメントを参照 <a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets" target="_blank">してください</a>。</p>


  <h3>Hyper パラメーターのチューニング</h3>


  <p>特定の顧客固有の&rsquo;使用例では、モデルのパフォーマンスは、選択したハイパーパラメーター値に大きく依存します。 ハイパーパラメーターは大きな検索空間を持つ可能性があります。また、各オプションを探索すると非常にコストがかかる可能性があります。 Azure Machine Learning サービスは、ハイパーパラメーター調整機能を提供し、さまざまなハイパーパラメーター構成を検索して、最適なパフォーマンスを実現する構成を見つける自動機械学習サービスを提供します。</p>


  <p>指定された例では、ランダム サンプリングが使用されます。この場合、ハイパーパラメーター値は、定義された検索空間からランダムに選択されます。 次の例では、1e-4 から 1e-6 の学習速度空間をログの一様な方法で探索しました。そのため、学習率は 1e-4 を中心に 2 つの値、1e-5 を中心に 2 つの値、1e-6 を中心に 2 つの値になる可能性があります。</p>


  <p>また、最適化するメトリックを選択できます。 検証の損失、精度スコア、F1 スコアは、最適化のために選択できる一般的なメトリックです。</p>


  <pre>

  from azureml.train.hyperdrive import *

  import math


  param_sampling = RandomParameterSampling( {
           &#39;learning_rate&#39;: loguniform(math.log(1e-4), math.log(1e-6)),
  })


  hyperdrive_run_config = HyperDriveRunConfig(
       estimator=estimator,
       hyperparameter_sampling=param_sampling,
       primary_metric_name=&#39;f1&#39;,
       primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,
       max_total_runs=16,
       max_concurrent_runs=4)</pre>

  <p>実験ごとに、さまざまなハイパーパラメーターの組み合わせの進行状況を確認できます。 たとえば、次の図は、さまざまなハイパーパラメーターの組み合わせを使用した時間の平均損失を示しています。 トレーニング損失が予想を&rsquo;満たしない場合 (上の赤い曲線など)、実験の一部は早期に終了できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c7ba77d9-afa5-4d07-8a22-778cd793c1b6.png"><img alt="HyperDrive Run Primary Metric line graph" border="0" height="465" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bdbe13c8-0011-49de-a019-4731cd3951cb.png" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="HyperDrive 実行プライマリ メトリックの線グラフ" width="994"></a></p>


  <p align="center"><em>図 4。さまざまな実行のトレーニング データの平均損失と早期終了</em></p>


  <p>Azure ML&rsquo; 自動ハイパーパラメーター 調整機能の使用方法の詳細については、ハイパーパラメーターのチューニングに関するドキュメント<a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters" target="_blank">を参照してください</a>。 また、すべての実験を追跡する方法については、実験とメトリックを追跡 <a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-track-experiments" target="_blank">する方法に関するドキュメントを参照してください</a>。</p>


  <h2>結果の視覚化</h2>


  <p>Azure Machine Learning サービスを使用すると、お客様は GLUE データセットで MRPC を微調整するときに 85% の評価精度を達成できます (BERT 基本モデルでは 3 エポックが必要です)。これは最先端の結果に近いです。 複数の GPU を使用すると、トレーニング時間を短縮できます。また、より強力な GPU (V100 など) を使用すると、トレーニング時間を短縮できます。 特定の実験の 1 つについて、詳細は次のとおりです。</p>


  <p>&nbsp;</p>


  <table border="1" cellpadding="2">
   <tbody>
    <tr>
     <td valign="top"><strong>GPU#</strong></td>
     <td valign="top"><strong>1</strong></td>
     <td valign="top"><strong>2</strong></td>
     <td valign="top"><strong>4</strong></td>
    </tr>
    <tr>
     <td valign="top"><strong>K80 (NC ファミリ)</strong></td>
     <td valign="top">191 s/epoch</td>
     <td valign="top">105 s/エポック</td>
     <td valign="top">60 s/エポック</td>
    </tr>
    <tr>
     <td valign="top"><strong>V100 (NCv3 ファミリ)</strong></td>
     <td valign="top">36 s/エポック</td>
     <td valign="top">22 s/epoch</td>
     <td valign="top">13 s/エポック</td>
    </tr>
   </tbody>
  </table>


  <p style="text-align: center;"><em>表 1。GLUE データセット内の MRPC のエポックあたりのトレーニング時間</em></p>


  <p>SQuAD 1.1 の場合、お客様は約 88.3 F1 スコアと 81.2 完全一致 (EM) スコアを達成できます。 BERT 基本モデルを使用して 2 つのエポックが必要であり、各エポックの時間を次に示します。</p>


  <p>&nbsp;</p>


  <table border="1" cellpadding="2">
   <tbody>
    <tr>
     <td valign="top"><strong>GPU#</strong></td>
     <td valign="top"><strong>1</strong></td>
     <td valign="top"><strong>2</strong></td>
     <td valign="top"><strong>4</strong></td>
    </tr>
    <tr>
     <td valign="top"><strong>K80 (NC ファミリ)</strong></td>
     <td valign="top">16,020 s/エポック</td>
     <td valign="top">8,820 s/エポック</td>
     <td valign="top">4,020 s/エポック</td>
    </tr>
    <tr>
     <td valign="top"><strong>V100 (NCv3 ファミリ)</strong></td>
     <td valign="top">2940 s/エポック</td>
     <td valign="top">1393 s/エポック</td>
     <td valign="top">735 s/エポック</td>
    </tr>
   </tbody>
  </table>


  <p style="text-align: center;"><em>表 2.電話データセットのエポックあたりのトレーニング時間</em></p>


  <p>すべての実験が完了すると、Azure Machine Learning service SDK では、選択したメトリックおよび対応するハイパーパラメーターの概要が表示されます。 学習率が検証の損失に与える影響の例を以下に示します。 実験全体を通して、学習率は約 7e-6 (左端) から約 1e-3 (右端) に変更されており、検証の損失が最も少ないのは、3.1 e-4 です。 このグラフを利用して、顧客が最適化する他のメトリックを評価することもできます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a73a079a-14f6-421a-8d6e-c4dda311c710.png"><img alt="Learning rate versus validation loss scatter chart" border="0" height="483" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/189651c7-05e1-4381-81b7-32d871b360b7.png" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="ラーニング率と検証損失の散布図" width="1030"></a></p>


  <p align="center"><em>図 5.ラーニング率と検証の損失</em></p>


  <h2>まとめ</h2>


  <p>このブログ投稿では、Azure Machine Learning サービスを使用して BERT を簡単に調整する方法、および対応するデータセットの分散設定の使用やハイパーパラメーターのチューニングなどのトピックについて説明しました。 また、Azure Machine Learning サービスを使用して NLP モデルを微調整する方法を示すいくつかの暫定的な結果も示しました。 すべてのコードは、 <a href="https://github.com/Microsoft/AzureML-BERT" target="_blank">GitHub リポジトリで入手でき</a>ます。 GitHub リポジトリで問題を発生させて、ご質問やご意見がある場合はお知らせください。</p>


  <h3>リファレンス</h3>


  <p>BERT: Language Understanding とその<a href="https://github.com/google-research/bert" target="_blank">GitHub サイト</a><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">の詳細な双方向トランスフォーマーの事前トレーニング。</a></p>


  <ul>
   <li>無料試用版の使用を開始するには、今日の<a href="https://azure.microsoft.com/en-us/free/services/machine-learning/" target="_blank">Azure Machine Learning サービス</a>のホームページにアクセスしてください。</li>
   <li><a href="https://azure.microsoft.com/en-us/services/machine-learning-service/" target="_blank">Azure Machine Learning サービス</a>の詳細については、こちらをご覧ください。</li>
  </ul>
