### YamlMime:Yaml
ms.openlocfilehash: 925b8ff6fd3c1af5f966d171fb18451fefaa59f7
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139904557"
Slug: processing-trillions-of-events-per-day-with-apache-kafka-on-azure
Title: Azure で Apache Kafka を使用して 1 日あたり数十億個のイベントを処理する
Summary: 'n 現在の時代では、企業は 1 秒ごとに膨大な量のデータを生成します。 ビジネス インテリジェンス、ユーザー分析、または運用インテリジェンスの場合。ストリーミング データのインジェストと分析では、このデータをソースから関心のある複数のコンシューマーに移動する必要があります。 '
Content: >-
  <p><em>このブログは、ソフトウェア エンジニアの Noor Abani と Negin Raoof が共同執筆しています。ソフトウェア エンジニアは、Nitin Kumar、Siphon チーム、AI Platform の監督下でベンチマーク、最適化、パフォーマンス チューニングの実験を共同で実行しました。 </em></p>


  <p><em>HDInsight チームの Dhruv Goel と Uma Maheswari Anbazhagan のコラボレーションに感謝します。</em></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1266d43c-ccdb-43d9-a747-d3fe550d3d2e.png"><img alt="image" border="0" height="420" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d63561bf-7dc7-4317-bc17-c7f0c310e8bc.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="746"></a></p>


  <p>&nbsp;</p>


  <p align="center"><em>図 1: さまざまなシナリオのプロデューサー スループット。2 GBps は、10 ブローカー Kafka クラスターで実現されます。 </em></p>


  <p>現在の時代には、企業は 1 秒ごとに膨大な量のデータを生成します。 ビジネス インテリジェンス、ユーザー分析、または運用インテリジェンスの場合。ストリーミング データのインジェストと分析では、このデータをソースから関心のある複数のコンシューマーに移動する必要があります。 <a href="https://kafka.apache.org/" target="_blank">Apache Kafka</a> は、スケーラブルで信頼性が高く、高速なデータ インジェストおよびストリーミング ツールとして機能する、分散型のレプリケートされたメッセージング サービス プラットフォームです。 Microsoft では、1 秒あたり最大 3,000 万件のイベントを処理するために、ほぼリアルタイムのデータ転送サービスの主要なコンポーネントとして Apache Kafka を使用しています。</p>


  <p>この投稿では、世界で&rsquo;最も大規模な Kafka デプロイの 1 つを実行した経験と学習を共有します。 基になるインフラストラクチャに関する考慮事項に加え、メッセージのスループット、待機時間、および耐久性に影響を与える、いくつかの Tunable Kafka ブローカーとクライアント構成について説明します。 何百もの実験を実行した後、さまざまな実稼働の使用事例で最大限の使用率を実現するために必要な Kafka 構成を標準化しました。 可能な限り最高のパフォーマンスを実現するために Kafka クラスターをチューニングする方法を示します。</p>


  <p>パフォーマンスには、スループットと待機時間の 2 &ndash; つの正次元があります。 この経験から、顧客のパフォーマンス要件は、次の図の A、B、C の 3 つのカテゴリに分類されます。 カテゴリ お客様は高スループット (最大 1.5 GBps) を必要とし、待機時間が長くなる (&lt; 250 ミリ秒) に耐えています。 そのようなシナリオの 1 つは、セキュリティや侵入検出アプリケーションなどのほぼリアルタイムのプロセスに対するテレメトリ データ の取り込みです。 カテゴリ B のお客様は、オンラインのスペルチェックや文法チェックなど、リアルタイム処理に非常に厳しい待機時間要件 (&lt; 10 ミリ秒) があります。 最後に、カテゴリ C のお客様は、高スループットと低待機時間 (約 100 ミリ秒) の両方を必要としますが、サービス可用性監視アプリケーションなどの低いデータ信頼性を許容できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8a78560f-ab71-4108-ad05-93cddbddc2e0.png"><img alt="This graph shows the maximum throughput we achieved in each case" border="0" height="554" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3522f0f9-3763-40c9-ab9f-71d7bc042d73.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="このグラフは、各ケースで達成した最大スループットを示しています" width="731"></a></p>


  <p>上のグラフは、それぞれのケースで達成した最大スループットを示しています。 信頼性は、パフォーマンスに対するトレードオフを持つもう 1 つの要件です。 Kafka は、データをレプリケートし、構成可能な受信確認設定を提供することで、信頼性を提供します。 これらの保証に付属するパフォーマンスへの影響を定量化します。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>


  <p>この目標は、実稼働 Kafka クラスターの実行を計画しているすべてのユーザーが、各構成の影響を理解し、関係するトレードオフを評価し、その使用事例に合って適切に調整し、可能な限り最高のパフォーマンスを得やすくすることです。</p>


  <h2>サイフォンとAzure HDInsight</h2>


  <p>O365、Bing、Skype、SharePoint などの企業からオンラインで 1 日あたり 3 兆件のイベントを取り込んで処理できる、準拠したコスト効率の高いほぼリアルタイムの発行/サブスクライブ システムを構築するために、<a href="https://azure.microsoft.com/en-us/blog/siphon-streaming-data-ingestion-with-apache-kafka/">Siphon</a> というストリーミング プラットフォームを作成しました。 Siphon は、Azure クラウド上の内部 Microsoft のお客様向けに構築され、 <a href="https://azure.microsoft.com/en-us/services/hdinsight/">HDInsight</a> Apache Kafkaコア コンポーネントとして機能します。 ハードウェアを購入して Kafka クラスターを設定および運用し、ビットをインストールしてチューニングし、監視を行うのは非常に困難です。 Azure HDInsightは、コスト効率の高い VM ベースの価格モデルを持つ<a href="https://azure.microsoft.com/en-us/pricing/details/hdinsight/"></a>マネージド サービスであり、Azure Apache Kafkaクラスターをプロビジョニングしてデプロイします。 HDInsight では、Kafka アップタイムで 99.9% の SLA を使用して定期的なメンテナンスと修正プログラムの適用を実行しながら、ブローカーが正常な状態を維持します。 また、ロールベースのアクセス制御や <a href="https://docs.microsoft.com/en-us/azure/hdinsight/domain-joined/apache-domain-joined-run-kafka"></a> Bring <a href="https://azure.microsoft.com/en-us/blog/bring-your-own-keys-for-apache-kafka-on-hdinsight/">Your Own Key (BYOK</a>) 暗号化などのエンタープライズ セキュリティ機能も備わっています。</p>


  <h2>ベンチマークの設定</h2>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0cab15e4-bc37-4b20-8811-ad8d1d206298.png"><img alt="Benchmark setup" border="0" height="282" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b956ef49-d4ec-43bf-be1d-227bf0fc3148.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="ベンチマークの設定" width="1006"></a></p>


  <h2>トラフィック ジェネレーター</h2>


  <p>システム全般と Kafka&rsquo; クラスターを特にストレステストするために、クラスターフロントエンドにランダム バイトのメッセージ バッチを常に生成するアプリケーションを開発しました。 このアプリケーションでは、100 スレッドをスピンして、1 KB のランダム データの 1,000 メッセージを各トピックに 5 ミリ秒間隔で送信します。 特に明示的に言及されていない限り、これは標準的なアプリケーション構成です。</p>


  <h2>イベント サーバーのセットアップ</h2>


  <p>Event Server は、Kafka プロデューサーおよびコンシューマー API を実装するフロントエンド Web サーバーとして使用されます。 負荷のバランスを取り、何千ものクライアント マシンから Kafka ブローカーに送信される要求の生成を管理するために、クラスター内に複数のイベント サーバーをプロビジョニングします。 パーティション アフィニティを実装することで、ブローカーへの TCP 接続の数を最小限に抑えるためにイベント サーバーを最適化しました。これにより、各イベント&rsquo; サーバー マシンはランダムに選択されたパーティション リーダーに接続し、一定の時間間隔の後にリセットされます。 各 Event Server アプリケーションは <a href="https://azure.microsoft.com/en-us/blog/f-series-vm-size/">、Azure Standard F8s Linux</a> VM のスケール セット上の Docker コンテナーで実行され、最大 Java ヒープ サイズが 9 GB に設定された 7 つの CPU と 12 GB のメモリが割り当てられます。 ストレス ツールによって生成された大量のトラフィックを処理するために、これらのイベント サーバーの 20 インスタンスを実行します。</p>


  <p>また、イベント サーバーは、複数のスライディング キューを使用して、クライアントからの未処理の要求の数を制御します。 新しい要求は、イベント サーバー インスタンス内の複数のキューの 1 つにキューに入れられます。このキューは、複数の並列 Kafka プロデューサー スレッドによって処理されます。 各スレッドは、1 つのプロデューサーをインスタンス化します。 スライディング キューの数は、スレッド プールのサイズによって制御されます。 さまざまなスレッド プール サイズについてプロデューサーのパフォーマンスをテストするときに、スレッドを追加しすぎると処理オーバーヘッドが発生し、 <a href="https://kafka.apache.org/documentation/#monitoring">Kafka</a> 要求キューの時間とローカル処理時間が長引く可能性があるという問題が見つかりました。 Kafka の送信待機時間が 2 倍になっているにもかかわらず、5 つ以上のスレッドを追加した場合でも、イングレス スループットが大幅に増加する必要はありません。 そのため、イベント サーバー インスタンスごとに 5 つの Kafka プロデューサー スレッドを選択しました。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ececd185-beac-4b1f-928d-b2ae9030abb5.png"><img alt="Kafka producer threads" border="0" height="674" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a93596ae-e3b7-489a-9472-03ed3aeff0ba.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Kafka プロデューサー スレッド" width="1001"></a></p>


  <h2>Kafka Broker ハードウェア</h2>


  <p>実験には <a href="https://kafka.apache.org/11/documentation.html">Kafka バージョン 1.1</a> を使用しました。 テストで使用される Kafka ブローカーは <a href="https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/">、Azure Standard D4 V2 Linux VM です</a>。 8 コアと 28 GB の RAM を備える 10 台のブローカーを使用しました。 このセットアップで CPU 使用率が高くなったことは一度も発生してこない。 一方、ディスクの数はスループットに直接影響しました。 最初に、各 Kafka ブローカーに 10 <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/windows/managed-disks-overview">の Azure Managed Disks</a> をアタッチします。 既定では、Managed Disksローカル冗長 <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-lrs">ストレージ (</a> LRS) がサポートされます。この場合、3 つのデータ コピーが 1 つのリージョン内に保持されます。 LRS ストレージ アカウントに対する書き込み要求は、データがすべてのコピーに書き込まれた後にのみ正常に返されるので、これにより、もう 1 つのレベルの耐久性が生まれます。 各コピーは、ストレージ スケール <a href="https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-high-availability">ユニット内の個別</a> の障害ドメインと更新ドメインに存在します。 つまり、3 倍のレプリケーション係数 Kafka 構成と共に、本質的に 9 倍のレプリケーションを確保しています。</p>


  <h2>コンシューマーと Kafka Connectセットアップ</h2>


  <p>このベンチマークでは、<a href="https://kafka.apache.org/documentation/#connect">Kafka</a> のデータConnect使用するために、コネクタ サービスとして Kafka を使用しました。 Kafka Connectは、信頼できるスケーラブルな方法で Kafka メッセージを生成および使用するための組み込みツールです。 実験では、Kafka からのメッセージを使用する Null シンク コネクタを実行し、それらを破棄してからオフセットをコミットしました。 これにより、プロデューサーとコンシューマーの両方のスループットを測定しながら、特定の宛先にデータを送信することで発生する潜在的なボトルネックを排除できます。 このセットアップでは、<a href="https://azure.microsoft.com/en-us/blog/f-series-vm-size/">Azure Standard F8s Linux VM</a> ノードの 20 インスタンスConnect Docker コンテナーに対して Kafka を実行しました。 各コンテナーには、最大 Java ヒープ サイズが 7 GB の 8 CPU と 10 GB メモリが割り当てられます。</p>


  <h2>結果</h2>


  <h3>プロデューサーの構成</h3>


  <p>パフォーマンスと <a href="https://kafka.apache.org/documentation/#producerconfigs" target="_blank">耐久性に</a> 最も影響を与える主なプロデューサー構成は次のとおりです。</p>


  <ul>
   <li>Batch.size</li>
   <li>Ack</li>
   <li>Compression.type</li>
   <li>Max.request.size</li>
   <li>Linger.ms</li>
   <li>Buffer.memory</li>
  </ul>


  <h3>バッチ サイズ</h3>


  <p>各 Kafka プロデューサーは、1 つのパーティションのレコードをバッチ処理し、パーティション リーダーに発行されたネットワーク要求と IO 要求を最適化します。 そのため、バッチ サイズを大きくすると、スループットが高くなる可能性があります。 負荷が軽い場合、プロデューサーはバッチの準備が整うのを待つので、Kafka の送信待機時間が長くなる可能性があります。 これらの実験では&rsquo;、プロデューサーに要求の負荷が大きかったため、最大 512 KB のバッチ サイズまでの待機時間の増加は観察されません。 その後、スループットが低下し、待機時間が増加し始めました。 これは、512 KB のプロデューサー バッチを十分に迅速に埋めるのに十分な負荷を意味します。 しかし、プロデューサーは、より大きなバッチを埋めるのに時間がかかっています。 <strong>そのため、負荷が高い場合は、スループットと待機時間を向上させるためにバッチ サイズを増やしてください。</strong></p>


  <p><strong><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7c21e04c-15eb-41cf-b6ec-630a5cd50401.png"><img alt="Kafka batch size" border="0" height="584" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1cbae8d7-4b6f-4d82-bc42-ce56fa6abcee.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Kafka バッチ サイズ" width="889"></a></strong></p>


  <p>バッチ <em>処理 Linger.ms</em> 設定によっても制御されます。 バッチが満たされていない場合でも、プロデューサーがバッチを送信するまでに待機する時間が長くなっています。 低負荷のシナリオでは、待機時間を犠牲にしてスループットが向上します。 継続的な高スループットで Kafka をテストしたので&rsquo;、この設定の利点は得ていました。</p>


  <p>より大きなバッチ処理をサポートするために調整したもう 1 つの構成は <em>buffer.memory</em> で、プロデューサーがバッファー処理に使用できるメモリの量を制御します。 この設定を 1 GB に増やしました。</p>


  <h2>プロデューサーが必要な確認</h2>


  <p>プロデューサーが必要な確認構成では、書き込み要求が完了したと見なされる前に、パーティション リーダーが必要な受信確認の数を決定します。 この設定はデータの信頼性に影響を与え、値 0、1、または -1 (つまり、すべて) を受 &ldquo;け取ります&rdquo;。</p>


  <p>最高の信頼性を実現するために、acks = all を設定すると、リーダーがすべての同期中レプリカ (ISR) がメッセージを確認するのを待機します。 この場合、同期内レプリカの数が構成されている min.insync.replicas より少ない場合、要求は失敗します。 たとえば、min.insync.replicas が 1 に設定されている場合、そのパーティションで使用可能な ISR が少なくとも 1 <strong></strong> つ存在する場合、リーダーは要求を正常に確認します。 範囲のもう一方の端では、acks = 0 を設定すると、プロデューサーによって送信された要求がすぐに完了したと見なされます。 acks = 1 を設定すると、リーダーがメッセージを受信したと保証されます。</p>


  <p>このテストでは、これらの 3 つの値の間で構成を変更しました。 結果は、信頼性の保証と待機時間の間に発生する直感的なトレードオフを確認します。 <strong>ack = -1 はデータ損失に対してより強力な保証を提供しますが、待機時間が長くスループットが低下します。</strong></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/42388b7b-c1d4-43ed-9064-4be2d924ab2b.png"><img alt="While ack provides stronger guarantees against data loss, it results in higher latency and lower throughput." border="0" height="640" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5aae2be0-22db-4543-a7c5-55f14258d757.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="ACK はデータ損失に対してより強力な保証を提供しますが、待機時間が長くスループットが低下します。" width="954"></a></p>


  <h2>[圧縮]</h2>


  <p>Kafka プロデューサーは、メッセージをブローカーに送信する前に圧縮するように構成できます。 <em>Compression.type 設定</em>では、使用する圧縮コーデックを指定します。 サポートされている圧縮コーデックは&ldquo;、gzip、&rdquo;&ldquo;snappy、&rdquo;&ldquo;lz4 です。&rdquo;圧縮は有益であり、ディスク容量に制限がある場合は考慮する必要があります。</p>


  <p>&ldquo;gzip &ldquo;&rdquo; と snappy <strong>&ldquo;という 2 つの一般的に使用される圧縮コーデックの中で、gzip&rdquo; の圧縮率が高くなると、CPU &ldquo;負荷が高くなる代わり、ディスク使用量が少なくなります。一方、snappy&rdquo; </strong> では、CPU オーバーヘッドが少なく圧縮が少なくなります。&rdquo;ブローカー ディスクまたはプロデューサーの CPU &ldquo;の制限に基づいて使用するコーデックを決定できます。gzip&rdquo; は、データをスナップよりも 5 倍圧縮&ldquo;できます。&rdquo;</p>


  <p>古い Kafka プロデューサー (Scala クライアント) を使用して新しい Kafka バージョンに送信すると、メッセージ型構造 (<a href="https://kafka.apache.org/documentation/#messageset" target="_blank">マジック</a> バイト) に非互換性が作成され、ブローカーは強制的に書き込み前に強制的に圧縮解除および再圧縮されます。 これにより、この追加の操作により、メッセージ配信と CPU オーバーヘッド (この場合は約 10%) に待機時間が追加されます。 新しいバージョンの Kafka を使用する場合は、Java プロデューサー クライアントを使用するようにお勧めします。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/590c32f7-6a45-4187-90b0-1f7d8350dc25.png"><img alt="Throughput versus latency" border="0" height="657" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/68fabc5a-70f5-41e2-8500-1f7024e235f5.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="スループットと待機時間" width="970"></a></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b6d9bbd7-d11a-4875-a3d5-08f784cab09e.png"><img alt="CPU Utilization" border="0" height="626" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/df7f408a-9c6b-49f8-806a-15e809c2766f.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="CPU 使用率" width="906"></a></p>


  <h2>ブローカーの構成</h2>


  <h3>ディスクの数</h3>


  <p>ストレージ ディスクの IOPS (1 秒あたりの入出力操作) および 1 秒あたりの読み取り/書き込みバイト数が限られています。 新しいパーティションを作成する際に、Kafka は、使用可能なディスク間で負荷を分散するために、既存のパーティションが最も少ないディスクに新しい各パーティションを格納します。 それでも、各ディスク上で数百のパーティション レプリカを処理する場合、Kafka は使用可能なディスク スループットを簡単に飽和状態にできます。</p>


  <p>クラスターで <a href="https://azure.microsoft.com/en-us/pricing/details/managed-disks/" target="_blank">Azure Standard S30 HDD ディスク</a> を使用しました。 実験では、Kafka がディスクごとに複数の同時 I/O 操作を実行して、ディスクあたり平均 38.5 MBps のスループットを確認しました。 全体的な書き込みスループットには、Kafka のインジェスト要求とレプリケーション要求の両方が含まれます。</p>


  <p>ブローカーごとに 10、12、および 16 の接続ディスクを使用してテストし、プロデューサーのスループットへの影響を調査しました。 <strong>結果は、接続されているディスクの数が増えるスループットの増加の相関関係を示しています。</strong> 1 つの VM に接続できるディスクの数 (最大 16 ディスク) によって制限されました。 そのため、ディスクを追加するには VM を追加する必要があるため、コストが増加します。 次の実験では、ブローカーごとに 16 の標準の HDD を引き続き使用することを決定しました。 この実験は、特にディスクの数の影響を観察するためのものであり、スループットを最適化するために行われる他の構成チューニングは含んでいなかった点に注意してください。 そのため、このセクションで説明するスループットは、この投稿の他の場所に示されている値よりも低くなります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/54e21a17-aad9-4559-804f-98620557fe9c.png"><img alt="Number of throughput" border="0" height="646" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4e7eb7e1-db87-4f80-b2e7-2422820674d9.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="スループットの数" width="948"></a></p>


  <h3>トピックとパーティションの数。</h3>


  <p>Kafka の各パーティションはシステム上のログ ファイルであり、プロデューサー スレッドは同時に複数のログに書き込むことができます。</p>


  <p>同様に、各コンシューマー スレッドはメッセージを 1 つのパーティションから読み取るので、複数のパーティションからの使用が並列で処理されます。 この実験では、パーティション密度 (つまり、レプリカを含めないブローカーあたりのパーティション数) がパフォーマンスに与える影響を定量化します。 パーティション密度を高くすると、メタデータ操作と、パーティション リーダーとそのフォロワー間のパーティションごとの要求/応答に関連するオーバーヘッドが増加します。 まだ流れるデータがない場合であっても、パーティションのレプリカは引き続きリーダーからデータをフェッチします。これによりネットワーク経由での要求の送受信のための追加の処理が発生します。 そのため、CPU を効率的に利用するために、I/O、ネットワーク、およびレプリカのフェッチスレッドの数を増やしました。 CPU が完全に使用された後は、スレッド プールのサイズを増やすとスループットが向上しない可能性があります。 Kafka メトリックを使用して、ネットワークと I/O プロセッサのアイドル <a href="https://kafka.apache.org/documentation/#monitoring">時間を監視できます</a>。</p>


  <p>さらに、要求キューと応答 <a href="https://kafka.apache.org/documentation/#monitoring">キューの時間について Kafka</a> メトリックを監視すると、Kafka スレッド プールのサイズを調整できます。 I/O スレッドとネットワーク スレッドを割り当てると、要求キューと応答キューの両方の待機時間が短縮されます。 要求のローカル待機時間が長いほど、&rsquo;ディスクで I/O 要求を十分に高速に処理できなかったと示されました。 Kafka の主要な構成を次の一覧にまとめるとします。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/59e2fb4a-d251-407d-a205-68918cbf3979.png"><img alt="10" border="0" height="324" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/359191c7-edeb-4cd1-8ec0-5a56cc729b11.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="10" width="727"></a></p>


  <p><strong>Kafka では、ブローカーごとに数千のパーティションを処理できます</strong>。 トピックあたり 100 のパーティション (つまり、ブローカーあたり合計 200 のパーティション) で最高のスループットを達成しました (20 のトピックと 10 のブローカーがあります)。 パーティション密度が高いスループット低下は、待機時間の長い時間に対応します。これは、ディスクが処理する必要がある追加の I/O 要求のオーバーヘッドが原因で発生しました。</p>


  <p>また、パーティション密度を高くすると、トピックが使用できなくなる可能性があります。 このような場合、Kafka では、各ブローカーが格納され、より多くのパーティションのリーダーになる必要があります。 このようなブローカーのクリーンなシャットダウンが発生した場合、新しいリーダーの選択には数秒かかる可能性があります。この場合、パフォーマンスに大きな影響を与える可能性があります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/36441b94-9d55-4880-8c6e-c9a0677aa9cc.png"><img alt="Partition density" border="0" height="621" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ee6e9b6a-c7f6-4a27-a4d1-b2a805cd2c42.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="パーティション密度" width="941"></a></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5c6748de-cf43-4ebc-8b05-8397833b6e94.png"><img alt="CPU Utilization versus Partition density" border="0" height="615" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/07305da0-7f1c-4a0c-a7a7-f3fcef9a5754.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="CPU 使用率とパーティション密度" width="947"></a></p>


  <h3>レプリカの数</h3>


  <p>レプリケーションは、サービスの信頼性を提供するトピック レベルの構成です。 Siphon では、一般に、最大 2 つのブローカーが同時に使用できない状況でデータを保護するために、実稼働環境で 3 倍のレプリケーションを使用します。 ただし、スループットの向上と低待機時間の実現が可用性よりも重要な状況では、レプリケーション係数を低い値に設定できます。</p>


  <p>高いレプリケーション係数により、パーティションのリーダーとフォロワーの間で追加の要求が発生します。 その結果、レプリケーション係数 <strong>が高</strong> いほど、追加の要求を処理するために使用されるディスクと CPU が増え、書き込み待機時間が長く<strong> 、スループットが低下します。</strong></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/61013bbe-2905-4965-ab07-c7c838d44717.png"><img alt="Producer throughput and replication" border="0" height="597" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/97b4747e-188d-47cd-adc5-2623f24ad841.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="プロデューサーのスループットとレプリケーション" width="967"></a></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bc081b88-2ce0-472b-8c52-cd782ccc1de6.png"><img alt="Kafka send latency versus replication" border="0" height="616" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/977a09e1-3b1a-432c-a94c-96e5166b1478.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Kafka 送信待機時間とレプリケーション" width="939"></a></p>


  <h3>メッセージ サイズ</h3>


  <p>Kafka では、大量のデータを非常に効率的に移動できます。 ただし、Kafka 送信の待機時間は、1 秒あたりのクエリ数 (QPS) とメッセージ サイズの観点から、イングレス ボリュームに基づいて変化する可能性があります。 メッセージ サイズの影響を調査するために、1 KB から 1.5 MB のメッセージ サイズをテストしました。 この実験中、負荷は一定に保たれ続けた点に注意してください。 メッセージ サイズに関係なく、最大 1.5 GBps の一定のスループットと最大 150 ミリ秒の待機時間を確認しました。 1.5 MB を超えるメッセージの場合、この動作が変更される可能性があります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2868b75e-b085-4090-9341-50fa20dead53.png"><img alt="image" border="0" height="197" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8236366d-e137-485c-86f2-a0bfca1753d6.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="770"></a></p>


  <h2>まとめ</h2>


  <p>プロデューサー、ブローカー、コンシューマーを構成するために調整できる <a href="https://kafka.apache.org/documentation/">Kafka</a> 構成は何百もいます。 このブログでは、パフォーマンスに影響を与える可能性がある主な構成を特定しました。 これらのパラメーターをチューニングすると、スループット、待機時間、CPU 使用率などのパフォーマンス メトリックに及ぼす影響を示しました。 パーティション密度、バッファー サイズ、ネットワーク、IO スレッドなどの適切な構成を使用することで、ブローカーあたり 10 台のブローカーと 16 台のディスクを含む約 2 GBps を達成したと示しました。 また、信頼性とスループットの間で生じるトレードオフを、レプリケーション係数やレプリカの確認のような構成で定量化しました。</p>
