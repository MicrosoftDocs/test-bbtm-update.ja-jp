### YamlMime:Yaml
ms.openlocfilehash: 7edd0a3c82e80fcb2a9ade51acf319ecab2ff693
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139889664"
Slug: preview-the-new-azure-storage-sdk-for-go-storage-sdks-roadmap
Title: 新しい Azure Storage sdk for to & Storage sdk ロードマップをプレビューする
Summary: Blob Storage をサポートする次世代 Azure Storage SDK for ゴーを紹介します。
Content: "<p>現在利用可能な<a href=\"https://godoc.org/github.com/Azure/azure-storage-blob-go/2016-05-31/azblob\" target=\"_blank\">ドキュメントと例</a>を使用して、新規および再設計された<a href=\"https://github.com/azure/azure-storage-blob-go\">Azure Storage SDK for to</a>を発表します。 この新しい SDK は、Azure Storage sdk の次世代設計理念に従うように再設計されました。これは、openapi 仕様のオープンソースコードジェネレーターである<a href=\"https://github.com/Azure/autorest\">AutoRest</a>によって生成されるコードの上に構築されています。</p>\n\n<p>Azure Storage クライアントライブラリは過去数年にわたって大幅に進化しており、C++ から JavaScript まで多くの開発言語をサポートしています。 すべてのプラットフォームとプログラミング言語をサポートするために、AutoRest を使用して、より多くの言語で新機能の提供を促進することにしました。 Storage SDK for ゴーでは、AutoRest によってプロトコルレイヤーと呼ばれるものが生成されます。 新しい SDK はこれを内部的に使用して、Storage サービスと通信します。</p>\n\n<p>現時点では、新しい Azure Storage SDK for to は Blob ストレージのみをサポートしていますが、今後、ファイルとキューのサポートがリリースされる予定です。 これらのサービスはすべて個別にパッケージ化されることに注意してください。最近、 <a href=\"https://github.com/Azure/azure-storage-python\">Azure Storage SDK for Python</a>を使って作業を開始しました。 今後、すべての Storage クライアントライブラリの分割されたパッケージが表示されることが予想されます。 これにより、Storage サービスの1つのみを使用すると、ライブラリのフットプリントが大幅に削減されます。</p>\n\n<h2>新機能</h2>\n\n<ul>\n <li>多層 SDK アーキテクチャ: 低レベルの Api と高レベルの Api</li>\n <li>柔軟性を高めるために、サービスごとに1つの SDK <a href=\"https://github.com/Azure/azure-storage-blob-go/tree/master/2016-05-31/\">パッケージ</a> (REST API) バージョンがあります。 古い REST API バージョンを使用するように選択して、アプリケーションを中断しないようにすることができます。 さらに、複数のパッケージをサイドバイサイドで読み込むことができます。</li>\n <li>AutoRest によって生成されたコードに基づいて構築</li>\n <li>Blob、ファイル、キューサービスのパッケージを分割してフットプリントを削減</li>\n <li>HTTP 要求と応答を処理するための拡張可能な新しいミドルウェア<a href=\"https://github.com/azure/azure-pipeline-go\">パイプライン</a></li>\n <li>アップロードおよびダウンロード操作の進行状況に関する通知</li>\n</ul>\n\n<h2>多層 SDK アーキテクチャ</h2>\n\n<p>新しい Storage SDK for new は、3つのレイヤーで構成されています。これにより、プログラミングエクスペリエンスが簡略化され、debuggability が向上します。 最初のレイヤーは、プライベートクラスと関数で構成される自動生成されたレイヤーです。 将来、 <a href=\"https://github.com/Azure/autorest\">AutoRest</a> を使用してこのレイヤーを生成することができます。 ご期待ください。</p>\n\n<p>2番目のレイヤーは、1対1の Azure Storage REST API 操作にマッピングするステートレスなシンラッパーです。 例として、BlobURL オブジェクトには、 <a href=\"https://docs.microsoft.com/en-us/rest/api/storageservices/put-blob\">Putblob</a>、 <a href=\"https://docs.microsoft.com/en-us/rest/api/storageservices/put-block\">Putblob</a>、 <a href=\"https://docs.microsoft.com/en-us/rest/api/storageservices/put-block-list\">PutBlockList</a>などのメソッドが用意されています。 これらの Api のいずれかを呼び出すと、1つの REST API 要求だけでなく、最初の REST 呼び出しが失敗した場合の再試行回数が発生します。</p>\n\n<p>3番目のレイヤーは、便宜上、高レベルの抽象化で構成されています。 たとえば、UploadBlockBlobFromStream は、アップロードされるストリームのサイズに応じて、いくつかの PutBlock 操作を呼び出します。</p>\n\n<p><img alt=\"\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/74d05caf-0e82-471d-a7b6-685b84435076.png\" style=\"margin-right: auto; margin-left: auto; float: none; display: block;\"></p>\n\n<h2>Hello World</h2>\n\n<p>新しい Storage SDK for new を使用した Hello World の例を次に示します。 GitHub の<a href=\"https://github.com/Azure/azure-storage-blob-go/blob/master/2016-05-31/azblob/zt_examples_test.go\">完全な例</a>を確認してください。</p>\n\n<pre class=\"prettyprint\">\n// From the Azure portal, get your Storage account&#39;s name and key and set environment variables.\naccountName, accountKey := os.Getenv(&quot;ACCOUNT_NAME&quot;), os.Getenv(&quot;ACCOUNT_KEY&quot;)\n\n// Use your Storage account&#39;s name and key to create a credential object.\n credential := azblob.NewSharedKeyCredential(accountName, accountKey)\n\n// Create a request pipeline that is used to process HTTP(S) requests and responses.\np := azblob.NewPipeline(credential, azblob.PipelineOptions{})\n\n // Create an ServiceURL object that wraps the service URL and a request pipeline.\n u, _ := url.Parse(fmt.Sprintf(&quot;https://%s.blob.core.windows.net&quot;, accountName))\nserviceURL := azblob.NewServiceURL(*u, p)\n\n // All HTTP operations allow you to specify a Go context.Context object to\n// control cancellation/timeout.\nctx := context.Background() // This example uses a never-expiring context.\n\n// Let&#39;s create a container\nfmt.Println(&quot;Creating a container named &#39;mycontainer&#39;&quot;)\n containerURL := serviceURL.NewContainerURL(&quot;mycontainer&quot;) \n _, err := containerURL.Create(ctx, azblob.Metadata{}, azblob.PublicAccessNone)\nif err != nil { // An error occurred\n   if serr, ok := err.(azblob.StorageError); ok { // This error is a Service-specific\n      switch serr.ServiceCode() { // Compare serviceCode to ServiceCodeXxx constants\n         case azblob.ServiceCodeContainerAlreadyExists:\n            fmt.Println(&quot;Received 409. Container already exists&quot;)\n            break\n         default:\n            // Handle other errors ...\n            log.Fatal(err)\n      }\n   }\n}\n\n// Create a URL that references a to-be-created blob in your \n// Azure Storage account&#39;s container.\nblobURL := containerURL.NewBlockBlobURL(&quot;HelloWorld.txt&quot;)\n\n// Create the blob with string (plain text) content.\ndata := &quot;Hello World!&quot;\nputResponse, err := blobURL.PutBlob(ctx, strings.NewReader(data), \n   azblob.BlobHTTPHeaders{ContentType: &quot;text/plain&quot;}, azblob.Metadata{}, \n   azblob.BlobAccessConditions{})\nif err != nil {\n   log.Fatal(err)\n}\nfmt.Println(&quot;Etag is &quot; + putResponse.ETag())\n\n</pre>\n\n<h2>新しいパイプラインパッケージを使用した進行状況レポート</h2>\n\n<p>すべての Storage クライアントライブラリに関してよく寄せられる機能の1つに、転送の進行状況をバイト単位で追跡する機能がありました。 これは、Storage SDK for ゴーで使用できるようになりました。 次に例を示します。</p>\n\n<pre class=\"prettyprint\">\n// From the Azure portal, get your Storage account&#39;s name and key and set environment variables.\naccountName, accountKey := os.Getenv(&quot;ACCOUNT_NAME&quot;), os.Getenv(&quot;ACCOUNT_KEY&quot;)\n\n// Create a request pipeline using your Storage account&#39;s name and account key.\ncredential := azblob.NewSharedKeyCredential(accountName, accountKey)\np := azblob.NewPipeline(credential, azblob.PipelineOptions{})\n\n// From the Azure portal, get your Storage account blob service URL endpoint.\ncURL, _ := url.Parse(\n   fmt.Sprintf(&quot;https://%s.blob.core.windows.net/mycontainer&quot;, accountName))\n\n// Create a ContainerURL object that wraps the container URL and a request \n// pipeline to make requests.\ncontainerURL := azblob.NewContainerURL(*cURL, p)\n\nctx := context.Background() // This example uses a never-expiring context\n// Here&#39;s how to create a blob with HTTP headers and metadata (I&#39;m using \n// the same metadata that was put on the container):\nblobURL := containerURL.NewBlockBlobURL(&quot;Data.bin&quot;)\n\n// requestBody is the stream of data to write\nrequestBody := strings.NewReader(&quot;Some text to write&quot;)\n\n// Wrap the request body in a RequestBodyProgress and pass a callback function \n// for progress reporting.\n_, err := blobURL.PutBlob(ctx,\n   pipeline.NewRequestBodyProgress(requestBody,\n      func(bytesTransferred int64) {\n         fmt.Printf(&quot;Wrote %d of %d bytes.\\n&quot;, bytesTransferred, requestBody.Len())\n      }),\n   azblob.BlobHTTPHeaders{\n      ContentType: &quot;text/html; charset=utf-8&quot;,\n             ContentDisposition: &quot;attachment&quot;,\n   }, azblob.Metadata{}, azblob.BlobAccessConditions{})\nif err != nil {\n    log.Fatal(err)\n}\n\n// Here&#39;s how to read the blob&#39;s data with progress reporting:\nget, err := blobURL.GetBlob(ctx, azblob.BlobRange{}, azblob.BlobAccessConditions{}, false)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Wrap the response body in a ResponseBodyProgress and pass a callback function \n// for progress reporting.\nresponseBody := pipeline.NewResponseBodyProgress(get.Body(), \n   func(bytesTransferred int64) {\n      fmt.Printf(&quot;Read %d of %d bytes\\n.&quot;, bytesTransferred, get.ContentLength())\n   })\ndownloadedData := &amp;bytes.Buffer{}\ndownloadedData.ReadFrom(responseBody)\n// The downloaded blob data is in downloadData&#39;s buffer\n</pre>\n\n<h2>次の&#39;は何ですか?</h2>\n\n<h3>Storage SDK for ゴーロードマップ:</h3>\n\n<ul>\n <li>一般公開</li>\n <li>ファイルとキューパッケージ</li>\n <li>アーカイブと blob 階層などの新しい Storage 機能が近日公開予定</li>\n <li>スループットの高い並列ファイル転送などの便利な機能</li>\n</ul>\n\n<h3>Storage sdk の残りの部分のロードマップ:</h3>\n\n<ul>\n <li>.net と Java の場合は近日公開予定の Blob、ファイル、キューサービスのパッケージを分割し、その後に他のすべての Storage クライアントライブラリを使用する</li>\n <li>AutoRest の OpenAPI (a. k. a Swagger) 仕様</li>\n <li>リアクティブプログラミングモデルを使用した完全に新しい非同期 Java クライアントライブラリ</li>\n</ul>\n\n<h2>開発者による調査 &amp; に関するフィードバック</h2>\n\n<p>&rsquo; <a href=\"https://aka.ms/AzureStorageDevSurvey\">5 つの質問</a>による調査を行ってください。 お客様が要求した機能 &rsquo; に積極的に取り組んでいます。年次調査は、ロードマップに影響を与える最も簡単な方法の1つです。</p>\n\n<p>Sercan と Jeffrey Richter</p>"
