### YamlMime:Yaml
ms.openlocfilehash: 70c70f618ac4da0cc6fe65fe744669fadab7365f
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139910783"
Slug: hive-memory-settings-resolve-out-of-memory-errors-using-azure-hdinsight
Title: Azure HDInsight を使用してメモリ不足エラーを解決するための Hive 設定
Summary: ユーザーがよく経験する問題として、Hive を使用するときに発生するメモリ不足 (OOM) エラーがあります。 このブログ投稿では、問題についてお客様がマイクロソフトに連絡した場合のシナリオと、問題を解決するために推奨する設定について説明します。
Content: "<p>ユーザーがよく経験する問題として、Hive を使用するときに発生するメモリ不足 (OOM) エラーがあります。 このブログ投稿では、問題についてお客様がマイクロソフトに連絡した場合のシナリオと、問題を解決するために推奨する設定について説明します。</p>\n\n<h1>シナリオ</h1>\n\n<p>次の問題により、お客様の1人にお問い合わせください。 次のクエリを Hive を使用して実行しました。</p>\n\n<pre class=\"prettyprint\">\nSELECT\n COUNT (T1.COLUMN1) as DisplayColumn1,\n &hellip;\n &hellip; \n &hellip;.\nFROM\n TABLE1 T1,\n TABLE2 T2,\n TABLE3 T3,\n TABLE5 T4,\n TABLE6 T5,\n TABLE7 T6\nwhere (T1.KEY1 = T2.KEY1&hellip;.\n &hellip;\n &hellip;\n</pre>\n\n<p>このクエリの特徴:</p>\n\n<ul>\n <li>T1 は、STRING 型の列が多数ある大きなテーブル TABLE1 のエイリアスです。</li>\n <li>他のテーブルはそれほど大きくありませんが、多数の列があります。</li>\n <li>すべてのテーブルは相互に結合されています。場合によっては、TABLE1 などのテーブルにある複数の列によって結合されています。</li>\n</ul>\n\n<p>次のクエリを実行したときに、MapReduce の Hive を使用して24ノード A3 クラスターで実行した場合、クエリは約26分で実行されました。 ユーザーは、MapReduce に Hive を使用してクエリを実行すると、次の警告メッセージが表示されることに気づきました。</p>\n\n<pre class=\"prettyprint\">\nWarning: Map Join MAPJOIN[428][bigTable=?] in task &#39;Stage-21:MAPRED&#39; is a cross product\nWarning: Shuffle Join JOIN[8][tables = [t1933775, t1932766]] in Stage &#39;Stage-4:MAPRED&#39; is a cross product\n</pre>\n\n<p>クエリの実行は約26分で終了したため、この警告は無視され、代わりにこのクエリ &rsquo; のパフォーマンスを向上させる方法に焦点を当てました。</p>\n\n<p>パフォーマンスの向上に関する <a href=\"https://azure.microsoft.com/en-us/documentation/articles/hdinsight-hadoop-optimize-hive-query/\">ドキュメント</a> に基づいて、お客様は tez 実行エンジンを使用することにしました。 Tez 設定を有効にして同じクエリを実行すると、クエリは15分間実行された後、次のエラーがスローされます。</p>\n\n<pre class=\"prettyprint\">\nStatus: Failed\nVertex failed, vertexName=Map 5, vertexId=vertex_1443634917922_0008_1_05, diagnostics=[Task failed, taskId=task_1443634917922_0008_1_05_000006, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure\nwhile running task:java.lang.RuntimeException: java.lang.OutOfMemoryError: Java heap space\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:172)\n        at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:138)\n        at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:324)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:176)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:168)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:168)\n        at org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:163)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n</pre>\n\n<p>その後、より大きな VM を使用することにしました。つまり、より大きな VM にはヒープ領域が D12 ます。 それでも同じエラーが発生します。 この問題のデバッグについては、お客様がマイクロソフトに連絡しました。</p>\n\n<h1>メモリ不足エラーのデバッグ中</h1>\n\n<p>CSS チームとエンジニアリングチームが、メモリ不足 (OOM) エラーの原因となった問題の1つが、 <a href=\"https://issues.apache.org/jira/browse/HIVE-8306\">ここで</a>説明されている既知の問題に起因していました。 JIRA の説明から:</p>\n\n<pre class=\"prettyprint\">\nWhen hive.auto.convert.join.noconditionaltask = true we check noconditionaltask.size and if the sum of tables sizes in the map join is less than noconditionaltask.size the plan would generate a Map join, the issue with this is that the calculation doesnt take into account the overhead introduced by different HashTable implementation as results if the sum of input sizes is smaller than the noconditionaltask size by a small margin queries will hit OOM.\n</pre>\n\n<p>次のように hive-site.xml ファイルを確認することによって、実際には hive... join. noconditionaltask が true に設定されていること &nbsp; を確認しています。</p>\n\n<pre class=\"prettyprint\">\n&lt;property&gt;\n    &lt;name&gt;hive.auto.convert.join.noconditionaltask&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;\n      Whether Hive enables the optimization about converting common join into mapjoin based on the input file size. \n      If this parameter is on, and the sum of size for n-1 of the tables/partitions for a n-way join is smaller than the\n      specified size, the join is directly converted to a mapjoin (there is no conditional task).\n    &lt;/description&gt;\n  &lt;/property&gt;\n</pre>\n\n<p>警告と JIRA に基づいて、Map Join は Java ヒープ領域 &rdquo; OOM エラーの &ldquo; 原因であるという仮説でした。 この問題について詳しく説明しました。</p>\n\n<p><a href=\"https://blogs.msdn.com/b/shanyu/archive/2014/07/31/hadoop-yarn-memory-settings-in-hdinsigh.aspx\">このブログの投稿</a>で説明されているように、tez 実行エンジンを使用すると、実際に使用されるヒープ領域は tez コンテナーに属します。 Tez コンテナー メモリについて説明した次の図を参照してください。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/63b25367-49ea-457c-869d-43f2f62da566.png\"><img alt=\"Tez_Memory\" border=\"0\" height=\"384\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a023b0c3-60dd-4bb3-bc49-ff0364825e9c.png\" style=\"border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"Tez_Memory\" width=\"688\"></a></p>\n\n<p>ブログの <a href=\"https://blogs.msdn.com/b/shanyu/archive/2014/07/31/hadoop-yarn-memory-settings-in-hdinsigh.aspx\">投稿 </a>に示すように、次の2つのメモリ設定は、ヒープのコンテナーメモリを定義します。これは、\"hive. tez........................... 経験から判断すると、OOM 例外の原因は、コンテナー サイズが小さすぎることではありません。 Java ヒープ サイズ (hive.tez.java.opts) が小さすぎることが原因です。 OOM が表示されている場合は常に、それを増やす &ldquo; &rdquo; ことができます。必要に応じて、hive のサイズ &rdquo; を増やす &ldquo; ことが必要になる場合があります。Java &rdquo; の場合は、 &ldquo; コンテナーのサイズの &ldquo; 約80% にする必要があります。&rdquo;</p>\n\n<p>ただし、この設定は、常に hive. tez. container. container. のサイズより小さくする必要があることに注意してください。</p>\n\n<p>D12 コンピューターには 28 GB のメモリがあるので、10 GB (10,240 MB) のコンテナー サイズを使用し、80% を java.opts に割り当てることにしました。 そのために、Hive コンソールで次の設定を使用しました。</p>\n\n<pre class=\"prettyprint\">\nSET hive.tez.container.size=10240\nSET hive.tez.java.opts=-Xmx8192m</pre>\n\n<p>これらの設定に基づいて、クエリは 10 分間未満で正常に実行されました。</p>\n\n<h1>まとめ</h1>\n\n<p>OOM エラーの取得は、コンテナーのサイズが小さすぎることを意味するわけではありません。 代わりに、ヒープサイズが増加し、コンテナーメモリサイズの80% 以上になるように、メモリ設定 &nbsp; を構成する必要があります。</p>"
