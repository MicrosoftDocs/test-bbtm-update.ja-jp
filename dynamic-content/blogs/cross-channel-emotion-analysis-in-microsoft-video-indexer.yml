### YamlMime:Yaml
ms.openlocfilehash: 79362782a90e3596b40e147764fa112857e4389e
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139910835"
Slug: cross-channel-emotion-analysis-in-microsoft-video-indexer
Title: Microsoft Video Indexer でのクロスチャネル感情分析
Summary: 業界をまたがって多くの異なる顧客は、メディア コンテンツの異なる部分に表示される感情の瞬間に関する洞察を得る必要があります。 ブロードキャスト担当者の場合、これはより多くのを作成するのに役立ちます。
Content: >-
  <p>業界をまたがって多くの異なる顧客は、メディア コンテンツの異なる部分に表示される感情の瞬間に関する洞察を得る必要があります。 ブロードキャスト担当者の場合は、より影響の大きなプロモーション クリップを作成し、閲覧者をコンテンツに取り込むのに役立ちます。販売業界では、売上の呼び出しを分析し、収束を改善するために非常に役立ちます。広告では、広告をポップアップ表示するのに最適な瞬間を特定するのに役立ちます。一覧は続きます。 その結果、私たちは、人間の行動&rsquo;を模倣する Video Indexer s (VI) <a href="https://en.wikipedia.org/wiki/Paul_Ekman#Emotions_as_universal_categories" target="_blank"></a>&rsquo; の新しい機械学習モデルを共有して、4 つの異文化感情状態を動画で検出します。"アンジェール"、"恐れ"、"喜び"、"悲しみ" です。</p>


  <p>人間の感情を認識して解釈する認知能力を備えるマシンは、複雑さのために困難な作業です。 人間として、複数のメディアを使用して感情を分析します。 これには、顔の表現、音声の色、音声コンテンツが含まれます。 最終的には、特定の感情の決定は、これらの 3 つのモダリティをさまざまな程度に組み合わせて行った結果です。</p>


  <p>従来の感情分析モデルは&ndash;&ndash;コンテンツの極度を検出しますが、新しいモデルでは、より細かい粒度分析を提供する目的で、肯定的または否定的です。 たとえば、否定的な感情を持つ瞬間を考えると、新しいモデルは、基になる感情が恐れ、悲しみ、または感情であるかどうかを判断します。 次の図は、教育の重要性に関する Microsoft CEO Satya Nadellas&rsquo; の音声の VIS&rsquo; 感情分析を示しています。 彼の話の冒頭で、残念な瞬間が検出されました。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/82dbc171-dee3-45ac-9a5f-2e2393ee5472.png"><img alt="Microsoft CEO Satya Nadella's speech on the importance of education" border="0" height="343" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/422fa6c3-955e-45b2-ba60-def29ebfb716.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Microsoft CEO Satya Nadella" width="1232"></a></p>


  <p>検出された感情とビデオに沿った特定の外観はすべて、次のようにビデオ インデックス JSON に列挙されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5682dd63-ccd2-405e-8260-30bb5289b89c.png"><img alt="video index JSON" border="0" height="289" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b57dfad0-1f50-4cc6-9b68-75cde4529140.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="JSON" width="301"></a></p>


  <h2>VI でのチャネル間感情検出</h2>


  <p>この新しい機能では、ディープ ラーニングを利用して、音声コンテンツと音声の色に基づいてメディア資産内の感情の瞬間を検出します。 VI は、音声コンテンツのセマンティック プロパティをキャプチャすることで感情を検出します。 ただし、単一の単語のセマンティック プロパティでは十分ではないので、基になる構文も分析されます。これは、同じ単語が異なる順序で異なる感情を誘発する可能性があるためです。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/45b0374b-9cb2-4e07-a8b3-5e903fb5a580.png"><img alt="Syntax" border="0" height="275" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4544a4f5-5949-422b-903a-4cfeb3dda934.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="構文" width="1388"></a></p>


  <p>VI では、音声コンテンツのコンテキストを利用して、主要な感情を考え出します。 たとえば、車<em>&ldquo;&hellip;&hellip;&rdquo;</em>が私に向かっていた文で、非常に速い速度で加速する文には否定的な言葉は含みませんが、VI は依然として、基になる感情として恐れを検出できます。</p>


  <p>VI では、話者の声の音色も分析します。 音声アクティビティを含むセグメントが自動的に検出され、内に含まれる影響を受ける情報が音声コンテンツ コンポーネントと融合されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bdb65fc5-3787-4baf-a798-443e60314b62.png"><img alt="Video Indexer" border="0" height="277" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/771d1f7d-835e-4265-9251-68526ec39786.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Video Indexer" width="1101"></a></p>


  <p>VI の新しい感情検出機能では、音声コンテンツと音声の音声に依存する機能により、マーケティング、カスタマー ケア、販売の目的でビデオを活用することで、ビデオのコンテンツに関する洞察を深めすることができます。</p>


  <p>詳細については、<a href="https://www.videoindexer.ai/" target="_blank">VIs ポータルまたは VI&rsquo;</a> 開発者ポータル<a href="https://api-portal.videoindexer.ai/" target="_blank"></a>を参照し、この新機能を無料で試してください。 感情コンテンツとしてインデックス付けされたビデオ (サンプル <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/e09e3055ae/" target="_blank">1</a>、サンプル <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/afdbe9521b/" target="_blank">2</a>、サンプル <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/c324f4d698/" target="_blank">3) を参照できます</a>。&nbsp;&nbsp;</p>


  <h3>質問やフィードバックがある場合や 皆様のご意見をお待ちしております。</h3>


  <p><a href="https://cognitive.uservoice.com/forums/598144-video-indexer" target="_blank">UserVoice を使用して</a>、機能に優先順位を付けるか、質問がある場合は電子<a href="mailto:VISupport@Microsoft.com" target="_blank">VISupport@Microsoft.com</a>メールでお問い合わせください。</p>
