### YamlMime:Yaml
ms.openlocfilehash: 364e3920bb04257ff71dd147c14f5ca96c36f7ce
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139908990"
Slug: hangman
Title: Dictionary を使用せずに Hangman を再生するようにニューラルネットワークをトレーニングする
Summary: Hangman のゲームで、補強学習と CNTK を使用して、ニューラルネットワークをトレーニングし、非表示の単語を推測しています。 トレーニング済みのモデルでは、参照辞書に依存していません。入力としては、可変長の部分的に隠された単語 (空白と正確に推測された文字で構成される) と、既に推測されている文字を示すバイナリベクターを入力として受け取ります。 この投稿に関連付けられている git リポジトリでは、ニューラルネットワークをトレーニングし、ゲームプレイ用の Azure Web アプリにデプロイするためのサンプルコードを提供します。
Content: >-
  <p>執筆者: Mary Wahl、Shaheen Gauher、Fidan Boylu Uz、Sandeep Zhao</p>


  <p><strong>まとめ</strong></p>


  <p>Hangman のゲームで、補強学習と CNTK を使用して、ニューラルネットワークをトレーニングし、非表示の単語を推測しています。 トレーニング済みのモデルは参照辞書に依存していません。入力としては、可変長の、部分的に隠された単語 (空白と正確に推測された文字で構成)、および既に推測されている文字を示すバイナリベクトルを入力として受け取ります。 <a href="https://github.com/Azure/Hangman">この投稿に関連付けられている git リポジトリ</a>では、ニューラルネットワークをトレーニングし、ゲームプレイ用の Azure Web アプリにデプロイするためのサンプルコードを提供します。</p>


  <p><strong>動機</strong></p>


  <p>Hangman の従来の子供&#39;s ゲームでは、&#39;プレーヤーは、文字数だけが最初にわかっている非表示の単語を特定することを目的としています。 各ラウンドでは、プレーヤーはアルファベットの文字を推測します。単語に文字が含まれている場合、その文字のすべてのインスタンスが表示されます。それ以外の場合は、hangman&#39;s のボディ部の1つが gibbet 上に描画されます。 ゲームは、単語が完全に推測されている場合は win で終了し、hangman&#39;s 本体が完全に公開されている場合は失われます。 プレーヤーを支援するために、これまでに推測されたすべての文字を表示する記録が通常は保持されています。</p>


  <p>一般的な Hangman 戦略では、部分的に明らかになった単語を、プレイヤー &rsquo; の語彙内のすべての単語と比較します。 一意の一致が見つかった場合、プレーヤーは単に残りの文字を推測します。複数の一致がある場合、プレーヤーは、予想される間違った推定数を最小限に抑えるために、考えられる単語を区別する文字を推測できます。 このような戦略は、事前にコンパイルされた参照辞書をボキャブラリとして使用して、(machine learning を使用せずに) アルゴリズムに実装できます。 残念ながら、この方法では、非表示の単語がプレーヤー &rsquo; の語彙に含まれていない場合に、最適な推測が得られたり、完全に失敗したりする可能性があります。 通常、この問題は実際に発生します。子供が非表示の単語を選択すると、多くの場合、適切な名詞を選択したり、参照辞書に存在しないスペルミスをコミットしたりするからです。</p>


  <p>このような問題に対する別の方法として、対象言語での文字と文字の組み合わせの頻度に基づいて推測を行うことができます。 英語版のゲームの場合、このような戦略では、母音の推測から始まり、Q が既に現れたときに文字 U を推測し、一部の文字または n グラムが他よりも一般的であることを認識します。Learnable パターンの幅が広く、独自の <em>priori</em> の不確定性が実際に最も役に立つという理由から、ニューラルネットワークをトレーニングして、参照辞書に依存せずに非表示の単語を推測するための適切なルールを学習することにしました。</p>


  <p><strong>モデルの設計とトレーニング</strong></p>


  <p>このモデルには、部分的に隠された非表示の単語と、既に推測されている文字を示すバイナリベクターという2つの主要な入力があります。 Hangman の非表示単語の可変長を格納するために、部分的に見えない単語 ( &ldquo; まだ推測されていない単語内の文字を表す空白 &rdquo; ) は、最後の出力のみが保持される長期間の短期メモリ (lstm) 繰り返しネットワークに取り込まれます。 LSTM &rsquo; s の出力は、前の推定値を示すバイナリベクトルと共にスプライスされ、結合された入力は、ネットワーク &rsquo; の推定可能な推定値 (a ~ Z) を表す26個の出力ノードを持つ1つの高密度レイヤーに取り込まれます。 モデル &rsquo; の出力 &ldquo; 推測 &rdquo; は、指定された入力の最大値がノードに含まれている文字です。</p>


  <p>HangmanPlayer というラッパークラスを作成し、補強学習を使用してこのモデルをトレーニングしました。 非表示の単語とモデルは、HangmanPlayer のインスタンスが作成されるときに提供されます。 最初のラウンドでは、HangmanPlayer は、適切なサイズの空白 (非表示の単語にまだ文字が表示されていないため) を使用してモデルを照会します。 HangmanPlayer は、モデルに &rsquo; 対して指定された入力、および推定 &rsquo; 品質に関するフィードバックとフィードバックを格納します。 推測に基づいて、HangmanPlayer は入力を更新し (正しく推測された文字を明らかにし、どの文字が推測されたかを示します)、Hangman のゲームが終了するまでモデルに対してクエリを繰り返し実行 &hellip; します。 最後に、HangmanPlayer は、保存した入力、出力、およびフィードバックを使用して、モデルをトレーニングします。 トレーニングは、トレーニングセット内の次の非表示の単語 (Princeton &rsquo; s <a href="https://wordnet.princeton.edu/">wordnet</a>から描画) を使用して Hangman の新しいゲームが作成されたときに続行されます。</p>


  <p><strong>運用化</strong></p>


  <p><a href="https://github.com/Azure/Hangman">Git リポジトリ</a>の手順とサンプルファイルでは、Azure Web アプリを作成して、トレーニングされた CNTK モデルをプレイゲーム用に運用化する方法を示します。 この flask web アプリは<a href="https://github.com/ilkarman/Azure-WebApp-w-CNTK">、Python 3 を使用して CNTK モデルをデプロイするための</a>Ilia Karmanov &rsquo; s テンプレートに大きく基づいています。 Web アプリにアクセスするユーザーは、自分の非表示の単語を選択します。これらの単語 &ndash; は直接 &ndash; 表示されることはありません。また、試合が勝利または損失のいずれかで終了するまで、各推測後にモデルにフィードバックを提供します。</p>


  <p>このプロジェクトの詳細については、「サンプルコード」と「作業を再現するための手順」を参照してください。 <a href="https://github.com/Azure/Hangman">Azure Hangman git リポジトリ</a>を参照してください。</p>
