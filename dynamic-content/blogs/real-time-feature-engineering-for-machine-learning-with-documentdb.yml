### YamlMime:Yaml
ms.openlocfilehash: eeec37f1e5029e7d49a3211cb89c933d22d96bbf
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139889010"
Slug: real-time-feature-engineering-for-machine-learning-with-documentdb
Title: DocumentDB を使用した Machine Learning の特徴エンジニアリングの Real-Time
Summary: 機械学習ソリューション用に DocumentDB に格納されているデータを活用する必要がありましたか。 このブログ記事では、Azure DocumentDB での機械学習アプリケーションのイベントモデリング、featurize、および機能データの保守を開始する方法について説明します。
Content: "<blockquote>\n<p>機械学習ソリューション用に DocumentDB に格納されているデータを活用する必要がありましたか。 このブログ記事では、Azure DocumentDB での機械学習アプリケーションのイベントモデリング、featurize、および機能データの保守を開始する方法について説明します。</p>\n</blockquote>\n\n<h2>Machine Learning と RFM</h2>\n\n<p>機械学習の分野は広く &ndash; 利用されています。機械学習が日常生活に与える影響をすべて特定するのは困難です。 再生を予測するモデルに対して音楽サービスの電源をストリーミングする推奨エンジンから、機械学習を使用して予測を行います。 機械学習は、データのパターンを検討して認識する方法をコンピューターに教える方法の1つであり、colossal データセット &ndash; からの洞察を収集ために使用されるようになっています。 feats 人間には、実行するメモリ容量と計算能力がありません。</p>\n\n<p>イベントモデリングと機械学習の世界では、RFM は奇妙な概念ではありません。 RFM は、3つの次元 (<strong>R</strong>Ecency、 <strong>F</strong>requency、 <strong>M</strong>onetary) に基づいています。は、機械学習モデルでよく使用される顧客をセグメント化するためのシンプルで強力な方法です。 RFM の背後にある考え方は、ほとんどのシナリオで直感的かつ一貫しています。昨日を購入した顧客は、1年に何も購入していない顧客に対して別の購入を行う可能性が高くなります。 さらに、購入を頻繁に行う spendy のお客様は、RFM 手法を使用して価値あるものとしても分類されています。</p>\n\n<p>RFM 機能のプロパティ:</p>\n\n<ul>\n <li>RFM 機能の値は、<strong>基本的なデータベース操作</strong>を使用して計算できます。</li>\n <li>生の値は、新しいイベントが到着したときに <strong>オンラインで更新</strong> できます。</li>\n <li>RFM 機能は、 <strong>機械学習モデルに役立ちます。</strong></li>\n</ul>\n\n<p>生データから得られた洞察は時間の経過と共にあまり役に立たないため、意思決定を支援するために RFM 機能をほぼリアルタイムで計算できることが重要 [1] です。 したがって、一般的な解決策として、イベントログを送信し、ほぼリアルタイムで自動的に特徴を RFM することができます。これは、さまざまな問題で機能を使用できるようにするためです。</p>\n\n<h2>DocumentDB はどこに配置されるのですか。</h2>\n\n<p><a href=\"https://azure.microsoft.com/services/documentdb/\">Azure DocumentDB</a> は、低待機時間と高いスループットを保証しながらシームレスに拡張できる、世界規模で分散した高可用性アプリを対象とした、非常に高速な世界規模の NoSQL データベースサービスです。 JavaScript の言語統合されたトランザクション実行により、開発者はストアドプロシージャ、トリガー、およびユーザー定義関数 (Udf) を JavaScript でネイティブに記述できます。</p>\n\n<p>これらの機能により、DocumentDB は、前述の時間制約を満たすことができます。また、イベントログを収集し、不足しているデータセットに格納して、顧客を正確にセグメント化する機械学習モデルのトレーニングに適した形式の RFM 機能で構成されるデータセットに到達することができます。 JavaScript ストアドプロシージャを使用した RFM 機能の計算を支援するために使用される特性付け logic および確率論的データ構造を実装したため、このロジックはデータベースストレージパーティションに直接格納され、実行されます。 この記事の残りの部分では、チャーン予測シナリオのために、DocumentDB でイベントモデリングを開始する方法と特徴データを維持する方法について説明します。</p>\n\n<p>ドキュメントの一覧を DocumentDB にアップロードして、RFM 機能のメタデータを更新する方法のエンドツーエンドのコードサンプルは、 <a href=\"https://github.com/Azure-Samples/documentdb-dotnet-rfm\">GitHub</a>でホストされています。</p>\n\n<h2>シナリオ</h2>\n\n<p>機械学習とイベントのモデリング領域の調査を開始するために選択した最初のシナリオは、2015 KDD カップ、年間データマイニング、およびナレッジ検出コンテストの問題です。 コンペティションの目標は、中国の最大規模の open course (MOOC) プラットフォームの1つである XuetangX で、前のアクティビティに基づいて学生がコースを削除するかどうかを予測することでした。</p>\n\n<p>データセットは次のように構成されています。</p>\n\n<p><img alt=\"Real-Time Feature Engineering for Machine Learning with DocumentDB\" border=\"0\" height=\"160\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5ba050d2-0974-4feb-8c26-0c90b723ae9f.jpg\" style=\"border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"DocumentDB を使用した Machine Learning の特徴エンジニアリングの Real-Time\" width=\"480\"></p>\n\n<p align=\"center\">図 1. データセットを使用できるようにするために、KDD カップ2015と XuetangX の開催者にも同意することを gratefully します。</p>\n\n<p>各イベントには、学生が完了したアクションの詳細が表示できます。 たとえば、ビデオを視聴したり、特定の質問に回答したりすることができます。 すべてのイベントは、各講座と学生のペアに固有のタイムスタンプ、コース ID (cid)、学生 ID (uid)、および登録 ID (eid) で構成されます。</p>\n\n<h2>アプローチ</h2>\n\n<h3>イベントログのモデリング</h3>\n\n<p>最初の手順では、DocumentDB でイベントログをドキュメントとしてモデル化する方法を決定しました。 私たちは2つの主なアプローチを検討しています。 最初の方法では、各ドキュメントの主キーとして、エンティティ名、エンティティ値、機能名 &gt; の &lt; 組み合わせを使用しています。 この方法の主キーの例は &lt; &rdquo; 、eid &rdquo; 、1、 &ldquo; cat &rdquo; &gt; です。 これは、学生登録 id が1である場合に追跡する機能ごとに個別のドキュメントを作成したことを意味します。 多数の機能がある場合は、多数のドキュメントが挿入される可能性があります。 主キーとしてではなく、エンティティ名とエンティティ値 &gt; を使用して &lt; 、2番目のイテレーションで一括アプローチを採用しました。 この方法の主キーの例としては、eid &rdquo; 、1 &gt; が &lt; &rdquo; あります。 この方法では、学生登録 id が1の場合に、すべての特徴データを追跡するために1つのドキュメントを使用しました。</p>\n\n<p>最初の方法では、追加のフィーチャー名属性があるため、挿入時の競合の数を最小限に抑えることができます。これにより、主キーがより一意になります。 ただし、多数の機能がある場合は、各機能に対して追加のドキュメントを挿入する必要があるため、結果として得られるスループットは最適ではありません。 2番目のアプローチでは、featurize によってスループットを最大化し、イベントログを一括で挿入することで、競合の可能性を高めます。 このブログ投稿では、より単純なコードを提供し、conflits 減らすことができる最初のアプローチについて説明しました。</p>\n\n<h3>手順 1</h3>\n\n<p>RFM 機能メタデータの更新を担当するストアドプロシージャを作成します。</p>\n\n<pre class=\"prettyprint\">\nprivate static async Task CreateSproc()\n{\n    string scriptFileName = @&quot;updateFeature.js&quot;;\n    string scriptName = &quot;updateFeature&quot;;\n    string scriptId = Path.GetFileNameWithoutExtension(scriptFileName);\n\n    var client = new DocumentClient(new Uri(Endpoint), AuthKey);\n    Uri collectionLink = UriFactory.CreateDocumentCollectionUri(DbName, CollectionName);\n\n    var sproc = new StoredProcedure\n    {\n        Id = scriptId,\n        Body = File.ReadAllText(scriptFileName)\n    };\n    Uri sprocUri = UriFactory.CreateStoredProcedureUri(DbName, CollectionName, scriptName);\n\n    bool needToCreate = false;\n\n    try\n    {\n        await client.ReadStoredProcedureAsync(sprocUri);\n    }\n    catch (DocumentClientException de)\n    {\n        if (de.StatusCode != HttpStatusCode.NotFound)\n        {\n            throw;\n        }\n        else\n        {\n            needToCreate = true;\n        }\n    }\n\n    if (needToCreate)\n    {\n        await client.CreateStoredProcedureAsync(collectionLink, sproc);\n    }\n}</pre>\n\n<h3>ステップ 2</h3>\n\n<p>各イベントを特徴としています。 この例では、各 student アクションは、前に作成されたストアドプロシージャを使用して DocumentDB コレクションに挿入する必要がある <strong>{entity: {name: &ldquo; &ldquo; , value: &hellip; }、feature: {name &ldquo; &ldquo; &hellip; </strong>:、value:}} の形式で、12行に展開されます。 このプロセスをバッチ処理し、そのサイズを構成できます。</p>\n\n<pre class=\"prettyprint\">\nprivate static string[] Featurize(RfmDoc doc)\n{\n    List&lt;string&gt; result = new List&lt;string&gt;();\n\n    var entities = new Tuple&lt;string, object&gt;[] { new Tuple&lt;string, object&gt;(&quot;eid&quot;, doc.Eid), new Tuple&lt;string, object&gt;(&quot;cid&quot;, doc.Cid), \n        new Tuple&lt;string, object&gt;(&quot;uid&quot;, doc.Uid) };\n    var features = new Tuple&lt;string, object&gt;[] { new Tuple&lt;string, object&gt;(&quot;time&quot;, doc.Time), new Tuple&lt;string, object&gt;(&quot;src_evt&quot;, doc.SourceEvent), \n        new Tuple&lt;string, object&gt;(&quot;cat&quot;, doc.Cat), new Tuple&lt;string, object&gt;(&quot;obj&quot;, doc.Obj) };\n\n    foreach (var entity in entities)\n    {\n        foreach (var feature in features)\n        {\n            StringBuilder eb = new StringBuilder();\n            StringBuilder fb = new StringBuilder();\n            StringWriter eWriter = new StringWriter(eb);\n            StringWriter fWriter = new StringWriter(fb);\n\n            JsonSerializer s = new JsonSerializer();\n            s.Serialize(eWriter, entity.Item2);\n            string eValue = eb.ToString();\n\n            s.Serialize(fWriter, feature.Item2);\n            string fValue = fb.ToString();\n\n            var value = string.Format(CultureInfo.InvariantCulture, &quot;{{\\&quot;entity\\&quot;:{{\\&quot;name\\&quot;:\\&quot;{0}\\&quot;,\\&quot;value\\&quot;:{1}}},\\&quot;feature\\&quot;:{{\\&quot;name\\&quot;:\\&quot;{2}\\&quot;,\\&quot;value\\&quot;:{3}}}}}&quot;,\n                entity.Item1, eValue, feature.Item1, fValue);\n            result.Add(value);\n        }\n    }\n\n    return result.ToArray();\n}</pre>\n\n<h3>手順 3.</h3>\n\n<p>手順 1. で作成したストアドプロシージャを実行します。</p>\n\n<pre class=\"prettyprint\">\nprivate static async Task&lt;StoredProcedureResponse&lt;string&gt;&gt; UpdateRFMMetadata(DocumentClient client, string metaDoc)\n{\n    object metaDocObj = JsonConvert.DeserializeObject(metaDoc);\n\n    int retryCount = 100;\n    while (retryCount &gt; 0)\n    {\n        try\n        {\n            Uri sprocUri = UriFactory.CreateStoredProcedureUri(DbName, CollectionName, &quot;updateFeature&quot;);\n            var task = client.ExecuteStoredProcedureAsync&lt;string&gt;(\n                sprocUri,\n                metaDocObj);\n            return await task;\n        }\n        catch (DocumentClientException ex)</pre>\n\n<p>このストアドプロシージャは、{entity: という形式の行を入力として受け取り<b>ます。 {name: &ldquo; &rdquo; , value: &hellip; }, 機能: {name: &rdquo; &ldquo; , &hellip; value:}}</b>という形式のドキュメントを生成するために、関連する特徴メタデータを更新して、 <b>{entity: {name: &quot; &quot; , value &quot; &quot; :}, feature: {name: &quot; &quot; , value:...}, ismetadata: true, 集計: { &quot; count &quot; :.. &quot; &quot; .}}}</b> DocumentDB に挿入されるドキュメント内の機能の名前によっては、定義済みの集計のサブセットが更新されます。 たとえば、ドキュメントの機能名が &ldquo; cat &rdquo; (category) の場合、count_unique_hll 集計を使用して、カテゴリの一意の数を追跡します。 また、ドキュメントの機能名が &ldquo; time &rdquo; の場合は、最小値と最大値の集計が使用されます。 次のコードスニペットは、個別のカウントと最小の集計を更新する方法を示しています。 これらの集計を維持するために使用しているデータ構造の詳細については、次のセクションを参照してください。</p>\n\n<pre class=\"prettyprint\">\ncase AGGREGATE.count_unique_hll:\n    if (aggData === undefined) aggData = metaDoc.aggregates[agg] = new CountUniqueHLLData();\n    aggData.hll = new HyperLogLog(aggData.hll.std_error, murmurhash3_32_gc, aggData.hll.M);\n\n    let oldValue = aggData.value = aggData.hll.count();\n    aggData.hll.count(doc.feature.value); // add entity to hll\n    aggData.value = aggData.hll.count();\n\n    if (aggData.value !== oldValue &amp;&amp; !isUpdated) isUpdated = true;\n    break;\ncase AGGREGATE.min:\n    if (aggData === undefined) aggData = metaDoc.aggregates[agg] = new AggregateData();\n    if (aggData.value === undefined) aggData.value = doc.feature.value;\n    else if (doc.feature.value &lt; aggData.value) {\n        aggData.value = doc.feature.value;\n        if (!isUpdated) isUpdated = true;\n    }\n    break;</pre>\n\n<h2>確率論的データ構造体</h2>\n\n<p>JavaScript では、次の3つの確率論的データ構造が実装されています。これらはそれぞれ、前のセクションで作成したストアドプロシージャの一部として条件付きで更新できます。</p>\n\n<h3>HyperLogLog</h3>\n\n<p>マルチセット内の各要素にハッシュ関数を適用することにより、マルチセット内の一意の要素の数を概算します (元のセットと同じカーディナリティを持つ一様に分布した乱数の新しいマルチセットを取得し、新しいセット <em>n</em>の各数値の先頭の0の最大数を計算します)。 推定カーディナリティは 2 ^<em>n</em> [2] です。</p>\n\n<h3>BloomFilter</h3>\n\n<p>要素がセットのメンバーであるかどうかをテストします。 誤検知は可能ですが、偽陽性は使用できません。 代わりに、ブルームフィルターは、要素がセットのメンバーであるかどうかを確認<em>するときに</em>、セット内にあるかどうか<em>を返します</em>。 ブルームフィルターに要素を追加するために、要素は <em>k ハッシュ関数</em> に渡され、 <em>k</em> 配列位置に到達します。 これらの各位置のビットは1に設定されます。 要素がセット内に存在するかどうかをテストするために、 <em>k 配列位置</em>に到達するために、各<em>k</em>ハッシュ関数に再び要素が取り込まれます。 いずれかのビットが0の場合、要素は明示的に set [3] に含まれていません。</p>\n\n<h3>Count-Min スケッチ</h3>\n\n<p>イベントのストリームを取り込みし、セット内の個別のメンバーの頻度をカウントします。 このスケッチは、特定のイベントの種類の頻度に対してクエリを実行できます。 ブルームフィルターと同様に、このデータ構造はいくつかのハッシュ関数を使用してイベントを値 &ndash; にマップしますが、これらのハッシュ関数は、イベントがデータセット [4] に存在するかどうかにかかわらず、イベントの頻度を追跡します。</p>\n\n<p>上記の各データ構造体は、特定の確率を使用して、true 値の特定の範囲内の推定値を返します。 これらの確率は、どの程度のメモリを犠牲にするかに応じて調整可能です。 次のスニペットは、eid = 1 を持つ student の一意のオブジェクトの数について、HyperLogLog 近似値を取得する方法を示しています。</p>\n\n<pre class=\"prettyprint\">\nprivate static void OutputResults()\n{\n    var client = new DocumentClient(new Uri(Endpoint), AuthKey);\n    Uri collectionLink = UriFactory.CreateDocumentCollectionUri(DbName, CollectionName);\n\n    string queryText = &quot;select c.aggregates.count_unique_hll[\\&quot;value\\&quot;] from c where c.id = \\&quot;_en=eid.ev=1.fn=obj\\&quot;&quot;;\n    var query = client.CreateDocumentQuery(collectionLink, queryText);\n\n    Console.WriteLine(&quot;Result: {0}&quot;, query.ToList()[0]);\n}</pre>\n\n<h2>まとめ</h2>\n\n<p>RFM の特徴が正の影響を与える可能性のあるシナリオの範囲は、チャーン予測を超えています。 この後も、さまざまな機械学習のコンテストやお客様のシナリオで、RFM の機能をいくつか使用して成功したことが証明されています。</p>\n\n<p>RFM の力と DocumentDB &rsquo; のサーバー側プログラミング機能を組み合わせることにより、synergistic 効果が得られます。 この記事では、DocumentDB ストアドプロシージャを使用してイベントモデリングを開始し、機能データを維持する方法について説明します。 開発者は、 <a href=\"https://github.com/Azure-Samples/documentdb-dotnet-rfm\">GitHub</a> &nbsp; でホストされているサンプルに機能を追加して、ケースごとに追加の機能メタデータを維持するためのツールを備えていることを願っています。 この種類のソリューションを Azure Machine Learning と統合する方法の詳細については、今後の投稿をご覧ください。 DocumentDB によってデータ特徴付け上のさまざまな機械学習モデルを試してみることができます。</p>\n\n<p>DocumentDB のデータベースストレージパーティションに直接発送して実行できるデータベースプログラムアプリケーションロジックを記述する方法の詳細については、「 <a href=\"https://azure.microsoft.com/documentation/articles/documentdb-programming/\">documentdb のサーバー側プログラミング: ストアドプロシージャ、データベーストリガー、udf</a>」を参照してください。 最新の DocumentDB のニュースと機能については、twitter <a href=\"https://twitter.com/DocumentDB\">@DocumentDB</a> でフォローして最新情報を入手してください。</p>\n\n<p>最後に、にご連絡いただく <a href=\"mailto:askdocdb@microsoft.com\">askdocdb@microsoft.com</a> か、以下のコメントをお寄せください。追加の ML サポートに関する問い合わせや、DocumentDB を使用して machine learning を再利用する &rsquo; 方法をご紹介します。</p>\n\n<h2>リファレンス</h2>\n\n<p>[1] Oshri、Gal。 &ldquo;RFM: イベントモデリングに対するシンプルで強力なアプローチです。 &rdquo;<i>Cortana Intelligence と Machine Learning のブログ</i>(2016)。 <a href=\"https://blogs.technet.microsoft.com/machinelearning/2016/05/31/rfm-a-simple-and-powerful-approach-to-event-modeling/\">https://blogs.technet.microsoft.com/machinelearning/2016/05/31/rfm-a-simple-and-powerful-approach-to-event-modeling/</a></p>\n\n<p>[2] <a href=\"https://gist.github.com/terrancesnyder/3398489\">https://gist.github.com/terrancesnyder/3398489</a> 、 <a href=\"https://stackoverflow.com/questions/5990713/loglog-and-hyperloglog-algorithms-for-counting-of-large-cardinalities\">https://stackoverflow.com/questions/5990713/loglog-and-hyperloglog-algorithms-for-counting-of-large-cardinalities</a></p>\n\n<p>[3] <a href=\"https://github.com/jasondavies/bloomfilter.js\">https://github.com/jasondavies/bloomfilter.js</a> 、Copyright &copy; 2011、Jason Davies</p>\n\n<p>[4] <a href=\"https://github.com/mikolalysenko/count-min-sketch\">https://github.com/mikolalysenko/count-min-sketch</a>、MIT ライセンス (MIT)、Copyright &copy; 2013 Mikola Lysenko</p>"
