### YamlMime:Yaml
ms.openlocfilehash: 5fb412d376b94799ba067b9ebcbfe669d6b6c71b
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896045"
Slug: cloudera-adls
Title: Cloudera がサポートされるようになりました Azure Data Lake Store
Summary: Cloudera Enterprise Data Hub 5.12 のリリースにより、Azure Data Lake Store (adls) の Cloudera クラスターで、Spark、Hive、HBase、Impala、MapReduce の各ワークロードを実行できるようになりました。
Content: "<p><a href=\"https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_rn_new_in_cdh_512.html#cdh_rn_new_in_cdh_512\" target=\"_blank\">Cloudera Enterprise Data Hub 5.12</a>のリリースにより、Azure Data Lake Store (adls) の Cloudera クラスターで、Spark、Hive、HBase、Impala、MapReduce の各ワークロードを実行できるようになりました。 ADLS での実行には、次の利点があります。</p>\n\n<ul>\n <li>データのサイズに関係なく、クラスターを拡大または縮小します。</li>\n <li>クラスターをスピンアップまたは破棄すると、データは独立して保持されます。 Azure Data Lake Analytics や Azure SQL Data Warehouse などの他のクラスターやコンピューティングエンジンは、同じデータに対してワークロードを実行できます。</li>\n <li>Azure Active Directory に統合されたロールベースのアクセス制御を有効にし、粒度の細かい POSIX ベースの acl を使用してユーザーとグループを承認します。</li>\n <li>分析ワークロード用に最適化されたパフォーマンスを備えたクラウド HDFS。数百テラバイトのデータの読み取りと書き込みを同時にサポートします。</li>\n <li>アカウントサイズや個々のファイルサイズに制限はありません。</li>\n <li>データは、既定では Azure Key Vault のサービス管理キーまたはユーザーが管理するキーを使用して暗号化され、転送中は SSL で暗号化されます。</li>\n <li>データレプリケーションが Data Lake Store によって管理され、hdfs とクラウドストレージインフラストラクチャレベルの両方でデータをレプリケートするのではなく、HDFS 互換インターフェイスから公開されるため、データの持続性は低コストです。</li>\n</ul>\n\n<p>開始するには、Azure Marketplace で<a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.clouderaedh\" target=\"_blank\">Cloudera Enterprise データハブテンプレート</a>または<a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.director-on-azure\" target=\"_blank\">Cloudera Director テンプレート</a>を使用して、Cloudera クラスターを作成します。 クラスターが稼働したら、次のいずれかまたは両方の方法を使用して、ADLS を有効にします。</p>\n\n<h3>クラスター全体にアクセスするための Data Lake Store を追加する</h3>\n\n<p><strong>手順 1</strong>: adls では、id 管理と認証に Azure Active Directory を使用します。 Cloudera クラスターから ADLS にアクセスするには、まず<a href=\"https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal\" target=\"_blank\">Azure AD でサービスプリンシパルを作成</a>します。 サービスプリンシパルの <em>アプリケーション id</em>、 <em>認証キー</em>、 <em>テナント id</em> が必要になります。</p>\n\n<p><strong>手順 2</strong>: adls にアクセスするには、前の手順で作成したサービスプリンシパルのアクセス許可を割り当てます。 これを行うには、Azure portal に移動し、Data Lake Store に移動して、[データエクスプローラー] を選択します。 次に、ターゲットパスに移動し、[アクセス] を選択して、適切なアクセス権を持つサービスプリンシパルを追加します。 ADLS でのアクセス制御の詳細については、こちらの <a href=\"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-access-control\" target=\"_blank\">ドキュメント</a> を参照してください。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cff17378-2988-4540-ac41-f71c58cfddd0.png\"><img alt=\"adls2_acl\" border=\"0\" height=\"357\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5ce750a1-4741-480c-9388-ef8ea49eb51b.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"adls2_acl\" width=\"858\"></a></p>\n\n<p><strong>手順 3:</strong> Cloudera Manager &gt; &gt; にアクセスします。 core-site.xml に次の構成を追加します。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0c71da7d-e625-42e7-a4bc-d5b901a4cb2d.png\"><img alt=\"adls1_hdfscfg\" border=\"0\" height=\"413\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0dda749c-1f25-44d1-918e-8f4f3cc8f5b5.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"adls1_hdfscfg\" width=\"851\"></a></p>\n\n<p><strong>手順 1</strong> . で取得したサービスプリンシパルのプロパティ値を使用して、これらのパラメーターを設定します。</p>\n\n<pre class=\"prettyprint\">\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.client.id&lt;/name&gt;\n    &lt;value&gt;<em>Application ID</em>&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.credential&lt;/name&gt;\n    &lt;value&gt;<em>Authentication Key</em>&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.refresh.url&lt;/name&gt;\n    &lt;value&gt;https://login.microsoftonline.com/&lt;<em>Tenant ID</em>&gt;/oauth2/token&lt;/value&gt;\n&lt;/property&gt; \n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.access.token.provider.type&lt;/name&gt;\n    &lt;value&gt;ClientCredential&lt;/value&gt;\n&lt;/property&gt;\n</pre>\n\n<p><strong>手順 4: </strong>Hadoop コマンドを実行して ADLS にアクセスできることを確認します。次に例を示します。</p>\n\n<pre class=\"prettyprint\">\nhdfs dfs -ls adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;/</pre>\n\n<h3>Hadoop コマンドラインでの Data Lake Store の指定</h3>\n\n<p>クラスター全体にアクセスするために Data Lake Store を構成するのではなく、MapReduce または Spark ジョブのコマンドラインで adls アクセス情報を提供することもできます。 このメソッドでは、サービスプリンシパルの代わりに Azure AD 更新トークンを使用し、で資格情報を暗号化します。ユーザー &rsquo; のホームディレクトリにある JCEKS ファイルには、次のような利点があります。</p>\n\n<ul>\n <li>各ユーザーは、クラスター全体の資格情報ではなく、独自の資格情報を使用できます。</li>\n <li>で暗号化されているため、 &rsquo; 他のユーザー &rsquo; の資格情報を見ることはできません。ユーザー &rsquo; のホームディレクトリの JCEKS</li>\n <li>資格情報をクリアテキストで構成ファイルに保存する必要はありません</li>\n <li>Azure AD でサービスプリンシパルを作成する権限を持つユーザーを待つ必要はありません</li>\n</ul>\n\n<p>次の手順では、Azure クロスプラットフォームクライアントツールにサインインして取得した更新トークンを使用してこれを設定する方法の例を示します。</p>\n\n<p><strong>手順 1</strong>: azure のログイン &rdquo; コマンド &ldquo; を実行して azure cli にサインインし、 <em>refreshtoken</em>を取得して、ユーザー &rsquo; のホームディレクトリの下にある azure/accessTokens から<em>_clientId</em>します。</p>\n\n<p><strong>手順 2</strong>: adls にアクセスするための資格情報を設定するには、次のコマンドを実行します。</p>\n\n<pre class=\"prettyprint\">\nexport HADOOP_CREDSTORE_PASSWORD=&lt;your encryption password&gt; \nhadoop credential create dfs.adls.oauth2.client.id -value &lt;_clientId from Step 1&gt; -provider jceks://hdfs/user/&lt;username&gt;/cred.jceks \nhadoop credential create dfs.adls.oauth2.refresh.token -value &lsquo;&lt;refreshToken from Step 1&gt;&rsquo; -provider jceks://hdfs/user/&lt;username&gt;/cred.jceks </pre>\n\n<p><strong>手順 3</strong>: Hadoop コマンドを実行して adls にアクセスできることを確認します。次に例を示します。</p>\n\n<pre class=\"prettyprint\">\nhdfs dfs -Ddfs.adls.oauth2.access.token.provider.type=RefreshToken -Dhadoop.security.credential.provider.path=jceks://hdfs/user/&lt;username&gt;/cred.jceks -ls adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;\nhadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teragen -Dmapred.child.env=&quot;HADOOP_CREDSTORE_PASSWORD=$HADOOP_CREDSTORE_PASSWORD&quot; -Dyarn.app.mapreduce.am.env=&quot;HADOOP_CREDSTORE_PASSWORD=$HADOOP_CREDSTORE_PASSWORD&quot; -Ddfs.adls.oauth2.access.token.provider.type=RefreshToken -Dhadoop.security.credential.provider.path=jceks://hdfs/user/&lt;username&gt;/cred.jceks 1000 adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;\n</pre>\n\n<h3>EDH 5.12 での ADLS のサポートに関する制限事項</h3>\n\n<ul>\n <li>ADLS は、セカンダリストレージとしてサポートされています。 ADLS にアクセスするには、完全修飾 Url を adl:// &lt; your ADLS account &gt; . azuredatalakestore.net/ &lt; path to file &gt; という形式で使用します。</li>\n</ul>\n\n<h3>その他の技術情報</h3>\n\n<ul>\n <li><a href=\"https://www.cloudera.com/documentation/enterprise/latest/topics/admin_adls_config.html\" target=\"_blank\">ADLS のサポートに関する Cloudera のドキュメント</a></li>\n</ul>"
