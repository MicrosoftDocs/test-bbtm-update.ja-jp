### YamlMime:Yaml
ms.openlocfilehash: bc1a7da28d1bf4fb074b1754fdae6283ccc9eaa1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139892354"
Slug: spark-connector-for-cosmosdb-seamless-interaction-with-globally-distributed-multi-model-data
Title: 'Spark Connector for #CosmosDB - グローバルに分散されたマルチモデル データとのシームレスな対話'
Summary: '本日、Azure Cosmos DB 用の Spark コネクタが真にマルチモデル化されました。 最近の発表「Azure Cosmos DB: 業界初のグローバル分散型マルチモデル データベース サービス」で説明した通り、私たちの目標は、既に使い慣れたツールと API を使用して、グローバルに分散されたアプリを簡単に作成できるよう支援します。'
Content: "<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dca42937-94b4-4152-9b82-54b590901fe5.png\"><img alt=\"image\" border=\"0\" height=\"288\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dd8fa093-06c9-4ba5-9cb6-29725da4c678.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"920\"></a></p>\n\n<p>本日は、&rsquo;Azure Cosmos DB 用の Spark コネクタが真にマルチモデル化されました。 最近の発表<a href=\"https://azure.microsoft.com/blog/azure-cosmos-db-microsofts-globally-distributed-multi-model-database-service/\">「Azure Cosmos DB:&rsquo;</a> 業界で初めてグローバルに分散されたマルチモデル データベース サービス」で説明した通り、私たちの目標は、既に使い慣れたツールと API を使用して、グローバルに分散されたアプリを簡単に作成できるよう支援します。 Azure Cosmos DBS&rsquo; データベース エンジンは、<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/documentdb-introduction\">SQL (DocumentDB) API</a>、<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/mongodb-introduction\">MongoDB API</a>、<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/graph-introduction\">Gremlin (グラフ) API</a>、<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/table-introduction\">Azure Table Storage API</a> をネイティブにサポートしています。 Azure Cosmos DB 用の更新された Spark コネクタを使用すると、Apache Spark は、すべての Azure Cosmos DB データ モデル (ドキュメント、テーブル、グラフ) と対話できます。</p>\n\n<h2>Azure Cosmos DB とは</h2>\n\n<p>Azure Cosmos DB は、ミッション クリティカル<a href=\"https://aka.ms/acdbglobaldist\">&#39;アプリケーション向</a>け、グローバルに分散されたマルチモデル データベース サービスを提供する Microsoft のサービスです。 Azure Cosmos DB は、ターンキー<a href=\"https://docs.microsoft.com/azure/cosmos-db/tutorial-global-distribution-documentdb\"></a>グローバル分散、スループットとストレージの世界規模でのエラスティック スケールアウト、99 番目のセンタイルでの 1 桁ミリ秒の待機時間、5 <a href=\"https://docs.microsoft.com/azure/cosmos-db/consistency-levels\"></a>つの定義済みの整合性レベル、および保証された高可用性を提供します。すべては、業界をリードする包括的な <a href=\"https://azure.microsoft.com/support/legal/sla/cosmos-db/\">SLA</a> によってサポートされます。 <a href=\"https://docs.microsoft.com/azure/cosmos-db/partition-data\"></a> Azure Cosmos DB では<a href=\"https://www.vldb.org/pvldb/vol8/p1668-shukla.pdf\">、スキーマとインデックスの管理に</a>対処する必要なく、すべてのデータのインデックスが自動的に作成されます。 Azure Cosmos DB はマルチモデルであり、ドキュメント、キーと値、グラフ、列指向の各データ モデルをサポートします。 Azure Cosmos DB は、クラウド生まれのサービスとして、最初からマルチテナントとグローバル分散を念頭に置いて入念に置いて設計されています。</p>\n\n<h2>Globally-Distributed および Azure Apache Spark DB を使用Machine Learningデータに対してリアルタイムCosmos実行する</h2>\n\n<p>Azure Cosmos DB 用の Spark コネクタを使用すると、Azure Cosmos DB のグローバルに分散されたデータに対するリアルタイムのデータ サイエンス、機械学習、高度な分析、探索が可能です。 Azure Apache Spark DB&rsquo; Cosmos に接続すると、お客様は、Azure Cosmos DB を使用してデータをすばやく永続化して照会できる、移動の速いデータ サイエンスの問題を解決する能力が向上します。 これは、ネイティブの Azure Cosmos DB マネージド インデックスを効率的に利用し、分析を実行するときに更新可能な列を有効にします。&nbsp;また、さまざまな IoT、データ サイエンス、分析のシナリオに対応する、急速に変化するグローバル分散データに対するプッシュダウン述語フィルター処理も<a href=\"https://github.com/Azure/azure-cosmosdb-spark/wiki\">利用します</a>。</p>\n\n<p>Azure Cosmos DB + Spark のその他の使用例を次に示します。</p>\n\n<ul>\n <li>データのストリーミング抽出、変換、読み込み (ETL)</li>\n <li>データ エンリッチメント</li>\n <li>トリガー イベント検出</li>\n <li>複雑なセッション分析とパーソナル化</li>\n <li>ビジュアル データの探索と対話型分析</li>\n <li>データ探索、情報共有、コラボレーションのためのノートブック エクスペリエンス</li>\n</ul>\n\n<p>Spark Connector for Azure Cosmos DB では<a href=\"https://github.com/Azure/azure-documentdb-java\">、Azure DocumentDB Java SDK が使用されます</a>。 今すぐ<a href=\"https://aka.ms/spark-documentdb\">始めて</a>、Spark コネクタをダウンロード<a href=\"https://github.com/Azure/azure-cosmosdb-spark\">GitHub。</a></p>\n\n<h2>Azure Cosmos DB テーブルの操作</h2>\n\n<p>Azure Cosmos DB は、予測可能なパフォーマンス<a href=\"https://docs.microsoft.com/azure/cosmos-db/table-introduction\">Table API</a>グローバル分散を備え、柔軟なスキーマを持つキー値ストアを必要とするアプリケーションに対して新しい機能を提供します。 Azure Cosmos DB で <a href=\"https://docs.microsoft.com/azure/storage/storage-introduction\">Azure Table Storage</a> SDK および REST API を使用できます。 Azure Cosmos DB では、現在パブリック プレビュー中のスループット最適化テーブル (&quot;非公式に Premium&quot; テーブルと呼ばれる) がサポートされています。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a6a0e709-d9aa-4ae0-9aca-d86d1f691299.png\"><img alt=\"image\" border=\"0\" height=\"314\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/01802a5a-3937-44cb-b21f-171c7a4e22d0.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"920\"></a></p>\n\n<p>Azure Apache Spark DB Cosmos Table APIに接続するには、次のように Azure Cosmos DB 用 Spark コネクタを使用できます。</p>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\nval readConfig = Config(Map(&quot;Endpoint&quot; -&gt; &quot;https://$tableContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterkey$&quot;,\n&quot;Database&quot; -&gt; &quot;$tableDatabase$&quot;,\n&quot;Collection&quot; -&gt; &quot;$tableCollection$&quot;,\n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;))\n\n \n// Create collection connection \nval tblCntr = spark.sqlContext.read.cosmosDB(readConfig)\ntblCntr.createOrReplaceTempView(&quot;tableContainer&quot;)</pre>\n\n<p>テーブルに接続したら、Spark DataFrame を作成できます (前の例では、tblCntr になります)。</p>\n\n<pre class=\"prettyprint\">\n// Print tblCntr DataFrame Schema\nscala&gt; tblCntr.printSchema()\nroot\n |-- _etag: string (nullable = true)\n |-- $id: string (nullable = true)\n |-- _rid: string (nullable = true)\n |-- _attachments: string (nullable = true)\n |-- City: struct (nullable = true)\n |    |-- $t: integer (nullable = true)\n |    |-- $v: string (nullable = true)\n |-- State: struct (nullable = true)\n |    |-- $t: integer (nullable = true)\n |    |-- $v: string (nullable = true)\n |-- $pk: string (nullable = true)\n |-- id: string (nullable = true)\n |-- _self: string (nullable = true)\n |-- _ts: integer (nullable = true)\n\n\n\n// Run Spark SQL query against your Azure Cosmos DB table\nscala &gt; spark.sql(&quot;select `$id`, `$pk`, City.`$v` as City, State.`$v` as State from tableContainer where City.`$v` = &#39;Seattle&#39;&quot;).show()\n+----+-----+-------+-----+\n| $id|  $pk|   City|State|\n+----+-----+-------+-----+\n|John|Smith|Seattle|   WA|\n+----+-----+-------+-----+\n</pre>\n\n<p>スキーマをすばやく簡単に操作し、基になる Azure SQL DB テーブルに対して Spark Cosmosクエリを実行できます。</p>\n\n<h2>Azure Cosmos DB グラフの操作</h2>\n\n<p>Azure Cosmos <a href=\"https://docs.microsoft.com/azure/cosmos-db/graph-introduction\"></a> DB&nbsp;&lt; には、グラフ モデリングとトラバーサル API と共に、ターンキー グローバル分散、ストレージとスループットのエラスティック スケールアウト、99 パーセンタイルでの 10 ミリ&lt;秒の読み取り待機時間と 15 ミリ秒、自動インデックス作成とクエリ、調整可能な整合性レベル、99.99% の可用性を含む包括的な SLA が提供されます。 Azure Cosmos DB は、<a href=\"https://tinkerpop.apache.org/\">Apache TinkerPop&#39;</a> のグラフ トラバーサル言語 <a href=\"https://tinkerpop.apache.org/docs/current/reference/#graph-traversal-steps\">Gremlin</a> を使用してクエリを実行できます。また、Apache Spark <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/spark-connector-graph\">GraphX</a> などの他の TinkerPop 互換グラフ システムとシームレスに統合できます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dd59c5ac-aff0-4bfb-b9cf-4970ca3b3908.png\"><img alt=\"image\" border=\"0\" height=\"197\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3af75d53-9ca6-4efa-8ca3-e80081a5117d.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"640\"></a></p>\n\n<p class=\"prettyprint\">Azure Apache Spark DB Cosmos Graphに接続するには、次のように Azure Cosmos DB 用 Spark コネクタを使用します。</p>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\n\n// Maps\nval baseConfigMap = Map(\n&quot;Endpoint&quot; -&gt; &quot;https://$graphContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterKey$&quot;\n&quot;Database&quot; -&gt; &quot;$database$&quot;,\n&quot;Collection&quot; -&gt; &quot;$collection$&quot;, \n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;,\n&quot;schema_samplesize&quot; -&gt; &quot;1000&quot;\n)\n\nval airportConfigMap = baseConfigMap ++ Map(&quot;query_custom&quot; -&gt; &quot;select * from c where c.label=&#39;airport&#39;&quot;) \nval delayConfigMap = baseConfigMap ++ Map(&quot;query_custom&quot; -&gt; &quot;select * from c where c.label=&#39;flight&#39;&quot;) \n\n\n// Configs\n// get airport data (vertices)\nval airportConfig = Config(airportConfigMap)\nval airportColl = spark.sqlContext.read.cosmosDB(airportConfig)\nairportColl.createOrReplaceTempView(&quot;airportColl&quot;) \n\n// get flight delay data (edges)\nval delayConfig = Config(delayConfigMap)\nval delayColl = spark.sqlContext.read.cosmosDB(delayConfig)\ndelayColl.createOrReplaceTempView(&quot;delayColl&quot;) </pre>\n\n<p>ここでは、空港データ (頂点) 用に Spark DataFrames &ndash; を作成し、もう 1 つはフライト遅延データ (エッジ) 用に作成しました。 Azure Cosmos DB&nbsp; に格納したグラフは、次の図のように視覚的に示されます。頂点は空港を表す青い円で、端はそれらの都市間のフライトを表す黒い線です。この例では、これらのフライト (エッジ) の出発都市はシアトル (すべてのエッジの発信元であるマップの左上の青い円) です。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5408d9ab-53b1-4d5f-8b6e-bfa06a96bc7d.png\"><img alt=\"image\" border=\"0\" height=\"575\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5a4233c7-c18e-46ee-9e7c-210b791b3354.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"920\"></a></p>\n\n<p align=\"center\"><em>図: 空港D3.js都市間のフライトである空港 (青い円) と端 (黒い線) を視覚化します。</em></p>\n\n<h2 align=\"left\">Db グラフと Spark Cosmos統合&nbsp;する利点</h2>\n\n<p align=\"left\">Azure Cosmos DB グラフと Spark コネクタを使用する主な利点の 1 つは、Gremlin クエリと Spark DataFrame (および他の Spark クエリ) を同じデータ コンテナー (&nbsp;グラフ、テーブル、ドキュメントのコレクションなど) に対して実行できる点です。たとえば、Azure Cosmos DB グラフに格納されているこのフライト グラフに対する簡単な Gremlin Groovy クエリを次に示します。</p>\n\n<pre class=\"prettyprint\">\n         \\,,,/\n         (o o)\n-----oOOo-(3)-oOOo-----\nplugin activated: tinkerpop.server\nplugin activated: tinkerpop.utilities\nplugin activated: tinkerpop.tinkergraph\ngremlin&gt; :remote connect tinkerpop.server conf/remote-secure.yaml\n==&gt;Configured tychostation.graphs.azure.com/52.173.137.146:443\n\ngremlin&gt; // How many flights into each city leaving SEA\n==&gt;true\ngremlin&gt; :&gt; g.V().has(&#39;iata&#39;, &#39;SEA&#39;).outE(&#39;flight&#39;).inV().values(&#39;city&#39;).groupCount()\n==&gt;[Chicago:1088,New York:432,Dallas:800,Miami:90,Washington DC:383,Newark:345,Boston:315,Orlando:116,Philadelphia:193,Fort Lauderdale:90,Minneapolis:601,Juneau:180,Ketchikan:270,Anchorage:1097,Fairbanks:260,San Jose:611,San Francisco:1698,San Diego:617,Oakland:798,Sacramento:629,Los Angeles:1804,Orange County:569,Burbank:266,Ontario:201,Palm Springs:236,Las Vegas:1204,Phoenix:1228,Tucson:90,Austin:90,Denver:1231,Spokane:269,San Antonio:90,Salt Lake City:860,Houston:568,Atlanta:521,St. Louis:90,Kansas City:95,Honolulu, Oahu:415,Kahului, Maui:270,Lihue, Kauai:128,Long Beach:345,Detroit:244,Cincinnati:4,Omaha:90,Santa Barbara:90,Fresno:142,Colorado Springs:90,Portland:602,Jackson Hole:13,Cleveland:6,Charlotte:169,Albuquerque:105,Reno:90,Milwaukee:82]\n\n\ngremlin&gt; // SEA -&gt; Reno flight delays\n==&gt;true\ngremlin&gt; :&gt; g.V().has(&#39;iata&#39;, &#39;SEA&#39;).outE(&#39;flight&#39;).as(&#39;e&#39;).inV().has(&#39;iata&#39;, &#39;RNO&#39;).select(&#39;e&#39;).values(&#39;delay&#39;).sum()\n==&gt;963</pre>\n\n<p>上のコードは、 <strong>tychostation </strong>グラフ (tychostation.graphs.azure.com) に接続して、次の Gremlin Groovy クエリを実行します。</p>\n\n<ul>\n <li>グラフトラバーサルと groupCount() を使用して、シアトルから一覧表示された目的地の都市に出発するフライトの数を決定します (このデータセットには、シアトルからシカゴへのフライトが 1088 便あるなど)。</li>\n <li>グラフを使用して、シアトルから Reno への 90 フライトの合計遅延 (分) を決定します (つまり、963 分の遅延)。</li>\n</ul>\n\n<p>同じ変更グラフを使用する Spark コネクタを使用して、独自の Spark DataFrame クエリを実行することもできます。 前の Spark&rsquo; コネクタ のコード スニペットに従って、この場合は HDInsight Jupyter Notebook サービスを使用して Spark SQL &ndash;&rsquo;クエリを実行します。</p>\n\n<h3>シアトルから出発する上位 5 つの目的地</h3>\n\n<pre class=\"prettyprint\">\n%%sql\nselect a.city, sum(f.delay) as TotalDelay \nfrom delays f \njoin airports a \n  on a.iata = f.dst \nwhere f.src = &#39;SEA&#39; and f.delay &lt; 0 \ngroup by a.city \norder by sum(f.delay) limit 5\n</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/596d31e9-6b5a-4a98-a0d5-ccbbaeefd47e.png\"><img alt=\"image\" border=\"0\" height=\"261\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c68f83f3-90c6-45d6-a42f-e9c16a4b26af.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"640\"></a></p>\n\n<h3>シアトル発のフライトの目的地 (都市) 別に遅延の中央値を計算する</h3>\n\n<pre class=\"prettyprint\">\n%%sql\nselect a.city, percentile_approx(f.delay, 0.5) as median_delay \nfrom delays f \njoin airports a \n  on a.iata = f.dst \nwhere f.src = &#39;SEA&#39; and f.delay &lt; 0 \ngroup by a.city \norder by median_delay\n</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7bc67496-97fa-4471-b83e-a5f41d542d6d.png\"><img alt=\"image\" border=\"0\" height=\"259\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ad11342c-9068-4ab6-be3f-3e02a27f75f5.png\" style=\"border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"640\"></a></p>\n\n<p>Azure Cosmos DB では、Apache Tinkerpop Gremlin クエリと、同じグラフを対象とする Apache Spark DataFrame クエリの両方<em><u>を使用</u></em>できます。</p>\n\n<h2>Azure Cosmos DB ドキュメント データ モデルの操作</h2>\n\n<p>Azure Cosmos DB のグラフ、テーブル、またはドキュメントを使用している場合でも、Azure Cosmos DB 用 Spark コネクタの観点から見ると、コードは同じです。&nbsp;最終的には、これらのデータ モデルに接続するためのテンプレートを次に示します。</p>\n\n<ol>\n <li>接続を構成します。</li>\n <li>構成と DataFrame をビルドします。</li>\n <li>また、Apache Spark&ndash;は Azure Cosmos DB と連携して動作しています。</li>\n</ol>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\n\n// Configure your connection\nval baseConfigMap = Map(\n&quot;Endpoint&quot; -&gt; &quot;https://$documentContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterKey$&quot;\n&quot;Database&quot; -&gt; &quot;$database$&quot;,\n&quot;Collection&quot; -&gt; &quot;$collection$&quot;, \n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;,\n&quot;schema_samplesize&quot; -&gt; &quot;1000&quot;\n)\n\n// Build config and DataFrame\nval baseConfig = Config(baseConfigMap)\nval baseColl = spark.sqlContext.read.cosmosDB(baseConfig)\n</pre>\n\n<p>また、Azure Cosmos DB 用 Spark コネクタを使用すると、Spark ワーカー ノードと Azure Cosmos DB データ パーティションの間でデータが並列化されます。&nbsp;そのため、データがテーブル、Graph、またはドキュメントに格納されている場合でも、Machine Learning と Apache Spark に関するデータ サイエンスの問題を解決するときに、Azure Cosmos DB によってサポートされるパフォーマンス、スケーラビリティ、スループット、整合性が得されます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b57acb00-bbd4-4580-82e0-312f69853eec.png\"><img alt=\"image\" border=\"0\" height=\"332\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8c63299d-8122-4ca2-97f7-aa18c59408a6.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"イメージ\" width=\"920\"></a></p>\n\n<h2>次の手順</h2>\n\n<p>このブログ記事&rsquo;では、Spark Connector for Azure Cosmos DB が Azure Cosmos DB でサポートされている複数のデータ モデルとシームレスに対話する方法について説明しました。 Apache Spark Azure Cosmos DB を使用すると、ビッグ データに対するアドホックな対話型クエリと、高度な分析、データ サイエンス、機械学習、人工知能の両方が可能です。 Azure Cosmos DB は、世界中のさまざまなソースから増分収集されるデータをキャプチャするために使用できます。 これには、ソーシャル分析、時系列、ゲームまたはアプリケーションのテレメトリ、小売カタログ、最新の傾向とカウンター、監査ログ システムが含まれます。 その後、Spark を使用して、高度な分析と AI&nbsp;&nbsp; アルゴリズムを大規模に実行し、Azure Cosmos DB のデータを基にグローバルに実行できます。&nbsp;Azure Cosmos DB <a href=\"https://azure.microsoft.com/blog/azure-cosmos-db-microsofts-globally-distributed-multi-model-database-service/\">&rsquo;</a>は業界で初めてグローバルに分散されたマルチモデル データベース サービスです。Azure Cosmos DB &ndash; 用の Spark コネクタは、テーブル、グラフ、ドキュメント データ モデルを使用できます。</p>\n\n<p>クエリの実行を開始するには、Azure portal から新しい <a href=\"https://portal.azure.com/#create/Microsoft.DocumentDB\">Azure Cosmos DB</a> アカウントを作成し、<a href=\"https://github.com/Azure/azure-cosmosdb-spark\">Azure-CosmosDB-Spark</a> GitHub レポポでプロジェクトを使用します。</p>\n\n<p>Twitter <a href=\"https://twitter.com/AzureCosmosDB\">@AzureCosmosDB</a> <a href=\"https://twitter.com/search?q=%23cosmosdb&amp;lang=en\">#と CosmosDB</a> でフォローして最新の Azure Cosmos DB のニュースと機能を最新の情報に残し、Stack Overflow の開発者フォーラムでお問い<a href=\"https://stackoverflow.com/questions/tagged/azure-cosmosdb\">合わせください</a>。</p>"
