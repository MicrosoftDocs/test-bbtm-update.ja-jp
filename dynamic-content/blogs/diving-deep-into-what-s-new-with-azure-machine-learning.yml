### YamlMime:Yaml
ms.openlocfilehash: 8ffac1887cc2eef30f7e98b5fc248f2885402c65
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139904186"
Slug: diving-deep-into-what-s-new-with-azure-machine-learning
Title: 新しい機能について深く掘り下Azure Machine Learning
Summary: 今日の前に、データ サイエンティストが任意の規模でモデルを構築、デプロイ、管理、監視するように設計された Azure Machine Learning に対する一連の主要な更新プログラムを公開しました。 これはプライベート プレビューで行いました。..
Content: >-
  <p>今日の早い時点で、データ サイエンティストが任意<a href="https://aka.ms/aml-preview-page" target="_blank">の</a>規模でモデルを構築、デプロイ、管理、監視するために設計された Azure Machine Learning に対する一連の主要な更新プログラムを公開しました。 これは過去 6 か月間のプライベート プレビューであり、100&rsquo; 社を超える企業がいます。現在、これらの更新プログラムをお客様と共有して非常に楽しみに思っています。 &rsquo;この&rsquo;&rsquo;投稿では、これまでに Azure Machine Learning で行った学習、現在お客様から見た傾向、これらの新機能の構築で検討した主要な設計ポイント、新機能について説明します。</p>


  <h2>ここまでの学習</h2>


  <p>3 年前に Azure Machine Learning Studio を立ち上げ、確立されたデータ サイエンティストや、新しいデータ サイエンティストがモデルを簡単に作成してデプロイMLしました。 この用語が使用される前は、豊富なモジュールセットからグラフィカルに構成し、ボタンを押して Web サービスとしてデプロイすることで構築された実験のサーバーレス トレーニングを有効にしました。 このサービスは、データ サイエンティストによって構築された数十万ものモデルの上に数十億のスコアリング要求を提供します。 次を含め、お客様がサービスがどのように使用されているのか、非常に高い報酬を得ていました。</p>


  <ul>
   <li><a href="https://www.youtube.com/watch?v=QRylfZVpar0" target="_blank">オーストラリアン・スクール・for・100000000001</a>&nbsp;</li>
   <li><a href="https://azure.microsoft.com/en-us/resources/videos/rolls-royce-and-microsoft-collaborate-to-create-new-digital-capabilities/" target="_blank">Rolls-Rolls-Rollsce での予測メンテナンス</a></li>
   <li><a href="https://blogs.technet.microsoft.com/machinelearning/2017/06/27/saving-snow-leopards-with-deep-learning-and-computer-vision-on-spark/" target="_blank">Snow Snow Snow Trust を使用したリモート カメラ ステーションからのスノウの認識</a></li>
  </ul>


  <p>今後は、&rsquo;次のレベルのパワーと制御を求める多くのお客様と、今日発表した機能がこれらのニーズに対応していきました。 データ サイエンス ワークフローを見て、お客様は次のステージを歩いているのを見て取ります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7333f6ee-de92-4a9d-ab5e-44af1adf1507.png"><img alt="Business goals" border="0" height="827" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/35c66879-a6b2-4fb8-8777-b7b5691ee24a.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="ビジネス目標" width="2447"></a></p>


  <h2>主要な傾向</h2>


  <p>過去数年間&rsquo;、私たちはあらゆる業界のお客様と対話し、ML に関するさまざまな経験を持ち、すべてのドメインの問題を解決してきました。 これらのエンゲージメントを反映すると、次の傾向が見て取り上がっています。</p>


  <p><strong>開発者による ML と AI &ndash;</strong> の導入を加速する 開発者と話をする場合、開発者は、顧客向けのイマーシブでパーソナライズされた生産的なエクスペリエンスを作成したいと考えています。 アプリの記述方法の一部ML AI の機能がますます増えつながっています。 Microsoft では、会社&rsquo;全体の開発者が、私たちが構築しているアプリケーションで AI を使用している方法を見て、うれしい思いを&rsquo;しました。 お気に入りの例の 2 つは、PowerPointです。 Microsoft Cognitive Services <a href="https://microsoft.com/cognitive" target="_blank">を利用して、</a> リアルタイムの翻訳とキャプション機能と言語理解ツールを構築し、箇条書きリストを <a href="https://www.pcmag.com/article/355434/microsoft-office-users-are-getting-ai-but-may-not-know-it" target="_blank">タイムラインに変換しました</a>。 すぐに使用できる 30 個の AI API セットである Microsoft Cognitive Services は、アプリケーションの強化を探している何十万もの開発者によって使用されています。 開発者による AI に対するこの需要は増加するだけで、ソフトウェアの記述方法がこれらの新機能を中心に進化するにつれて、組織はデータ上に構築された簡単に使用できる AI を提供します。</p>


  <p><strong>ハイブリッド トレーニングとスコアリング &ndash;</strong> すべての顧客は、データに固有の要件セットを持っています。 コンプライアンス、コスト、規制、物理、および既存のプロセスとアプリケーションはすべて、データと意思決定が行える場所の要因です。 これにより、データ管理と移動の課題が生じ、すべてのデータにわたって操作できるツール、サービス、フレームワークが必要になります。 さらに、多くの場所にモデルをデプロイする機能が必要です。 お客様は大量のデータをデータ レイクに統合し、Spark のようなツールを使用してデータを準備および分析しているのを確認しますが、生成されるモデルはさまざまなフォーム ファクターにデプロイする必要があります。 2&rsquo; つの一般的なハイブリッド パターンを見ていました。 1 つ目は、クラウドまたはアプリケーションにデプロイされるモデルのトレーニングに使用されるオンプレミス システムに存在する機密データです。 2 つ目は、クラウドに取り込まれた膨大な量のデータ (IOT アプリケーションなど) に対してモデルをトレーニングし、そのモデルをオンプレミスまたは切断された環境にデプロイすることです。</p>


  <p><strong>可能な限りイベントに近いスコアリング &ndash;</strong> 上記の点に従って、開発者があらゆる場所でモデルを使用することがより重要になり、エッジベースとデバイスベースのスコアリングが増加しています。 最近、Custom Vision サービスでは、トレーニング済みの認識モデルを CoreML に出力して、iOS 内で直接使用 <a href="https://azure.microsoft.com/en-us/blog/custom-vision-service-introduces-classifier-export-starting-with-coreml-for-ios-11/" target="_blank">する機能を有効にしました</a>。 IOT 空間のお客様は、モデルをデバイスに直接、または個別に動作できるゲートウェイ デバイスに置く必要があります。 待機時間に対処する場合でも、切断中でもスコアリングをサポートする機能を探している場合でも、顧客は、可能な限りイベントの近くにスコアリングを配置するためにデプロイを制御しながら、モデルを任意の場所で柔軟にトレーニングしたいと考えています。</p>


  <p><strong>ハードウェア、フレームワーク、ツールの統一を加速する &ndash;</strong> この領域で作業する最&rsquo;も楽しい側面の 1 つは、スタックのすべての層で目にしたイノベーションのペースです。 選択できるツールには目まごたえの配列があります。それぞれがすばらしい方法で使用されています。 ハードウェア 層では、CPU、GPU、FPGA など、処理機能が指数関数的に増加しています。 時間がたつ間にこのイノベーションにより、成熟したツールチェーンが、特定のワークロード用に最適化されたハードウェア レベルにまで及び、顧客がコスト、待機時間、制御を調整およびトレードオフできます。 短期的には、お客様が自分の使用事例に最適なツール セットを見つけ実験しているのを見るのです。</p>


  <h2>デザイン ポイント</h2>


  <p>学習を考えると、&rsquo;&rsquo;これらの新機能を形成するために、次の 4 つの点に設計を固定しました</p>


  <h3>Machine Learning大規模なデータ</h3>


  <p>構築するサービスとツールは大規模に動作する必要があります。また、お客様は少なくとも 5 つの異なる規模の規模で課題に直面 &ldquo;しています。&rdquo;</p>


  <p><strong>すべてのデータを操作する &ndash;</strong> 大規模なモデルの構築を使用するには、すべてのデータにアクセスできる必要があります。 多くの場合、これは Spark のようなツールを使用して、データ レイク内のデータ量を増やす可能性を意味しますが、これは課題の一部にしか含め "ない" という意味です。 顧客はデータを見つけて取得できる必要があります。その後、データを理解して整形できる必要があります。 これらのステージはいずれも、データ サイズの増加に応じてボトルネックになる可能性はないので、ツールはローカル CSV ファイルからクラウド内のペタバイト規模のデータ レイクにスケーリングする必要があります。</p>


  <p><strong>コンピューティング ニーズの増加 (アップ/アウト) &ndash;での運用</strong>データの拡張を超えて、使用する手法&rsquo;では、処理力をスケーリングする必要があります。 お客様は、大規模なデータセットをメモリ内に直接収め、またはディープ ラーニング用の最新の GPU を搭載したマシンにスケールアップする必要があります。 お客様は、Spark などの分散データ インフラストラクチャ上の問題セット、または Azure Batch サービス上のハイパーパラメーター スイープとモデル評価での超並列処理に対してスケールアウトします。 これら 2 つの力は、大規模なディープ ラーニングを行う場合に組み合わせて、多くのスケールアップされたマシンを必要とします。</p>


  <p><strong>使用しているモデルと実験の数をスケーリングする &ndash;</strong> チームが実験の速度を上げ、実行される実験の数と生成されるモデルの数が増える。 これらのモデルを管理、監視、保守できる必要があります。 Teams、モデルの任意のバージョンを特定して再作成する機能と、組織が AI を使用してより多くの意思決定を行う上でスケールを追跡する必要があるアーティファクトの数が必要です。</p>


  <p><strong>モデルの使用量のスケーリング &ndash;</strong> 任意のツールとフレームワークを使用して生成されたモデルは、任意の数の要求に対応する簡単なスケーリングを可能にする方法でデプロイする必要があります。 つまり、コンテナー ベースのモデルのデプロイを受け入れ、顧客をきめ細かく制御できるだけでなく、Azure Container Service などのサービスを使用して Azure でスケーラブルなホスティング レイヤーを提供することができます。</p>


  <p><strong>チームのスケーリング &ndash;</strong> データ サイエンス チームは、1 つのチームではありません。 ツールとサービスは、データ サイエンス ライフサイクルのすべての段階で、安全な方法でコラボレーションと共有を可能にする必要があります。 さまざまなチームやプロセスを柔軟にサポートするためにソフトウェア開発用のソース管理システムが進化したのと同様に、チームが成長し続けるにつれて、システムは AI 開発ライフサイクルをサポートする必要があります。</p>


  <h3>現在使用しているツールを使用&rsquo;した構築</h3>


  <p>それらをすべて規則するフレームワークやツールチェーンはありません。 エコシステムの急速な分散を考えると、お客様は自分に最適なツールを実験して選択できます。 エコシステムのイノベーションの加速は、現在のツールとフレームワークと手法が 6 か月の時間とは異なっているという意味&rsquo; です。 構築するサービスとツールでは、データ サイエンティストがエコシステムから選択して選択し、それらのツールを使用できる必要があります。また、これらの進化に伴い、トレーニング、デプロイ、管理に一貫したエクスペリエンスを提供する方法で構築する必要があります。</p>


  <p>ツール空間でのこの拡張の副作用の 1 つは、再現性を持つ課題です。 ツールが変更された&rsquo; 場合、12 か月後に実験を再作成するにはどうすれば良いでしょうか。 検証済みの一連の依存関係をチェックポイント処理する必要があるソフトウェア開発者と同様に、フレームワークが行き来するに応じて、確実に結果を再現できるシステムが必要です。</p>


  <h3>実験の速度を上げ</h3>


  <p>データ サイエンス チームの摩擦の主な領域を見て、次の課題について常に耳を通します。</p>


  <ul>
   <li>データの取得、準備、および理解</li>
   <li>迅速なローカル プロトタイプ作成とスケーリングから大規模なデータ セットまで、トレーニングを確実にスケーリングする</li>
   <li>さまざまなツールと手法でトレーニングされたモデルの比較と選択</li>
   <li>実稼働環境へのモデルのデプロイ</li>
   <li>デプロイされたモデルからテレメトリを取得し、モデルを学習して改善する</li>
  </ul>


  <p>これらの各手順とこれらの手順の間の摩擦を排除することで、チームは実験の速度を向上できると信じています。 これにより、より優れたモデルをより迅速に作成し、最終的には顧客により多くの価値を提供し、チームの効率を高めることができます。 サービスとツールでは、必要な柔軟性と制御を維持しながら、これらの主要な摩擦点を減らす必要があります。</p>


  <h3>あらゆる場所のモデル</h3>


  <p>最後に、構築するサービス&rsquo;では、モデルのデプロイ、管理、監視をあらゆる場所で有効にする必要があります。 お&rsquo;客様がデプロイ フォーム ファクターに柔軟性を持て、次の要素を含めて実現できる必要があります。</p>


  <ul>
   <li>何百万ものデバイスまたはアプリによって使用されるスケーラブルな Web サービスのためにクラウドにデプロイする</li>
   <li>バッチ、対話型、リアルタイムのストリーミング パイプラインで大規模なデータを処理するために、データ レイクにデプロイする</li>
   <li>トランザクション処理とデータ ウェアハウス用にインラインでデータをスコア付けするために、SQL Server 2017 など、データ エンジンにデプロイする</li>
   <li>エッジへのデプロイ。スコアリングを可能な限りイベントの近くに移動し、切断されたシナリオをサポートします</li>
  </ul>


  <h2>新しい機能について説明します</h2>


  <p>これらの設計ポイントを考えると、次&rsquo;の新しい機能がリリースAzure Machine Learning</p>


  <h3>実験</h3>


  <p>Azure Machine Learning実験サービスを使用すると、開発者とデータ サイエンティストは実験の速度を上げできます。 Git リポジトリによってサポートされるすべてのプロジェクトと、実験とトレーニングの実行を管理するための簡単なコマンド ライン ツールを使用すると、すべての実行で、実行に使用されるコード、構成&rsquo;、データを追跡できます。 さらに重要なのは、モデル ファイル、ログ出力、主要メトリックからの実験の出力が追跡され、時間の経過と共にモデルがどのように進化するのかという履歴を持つ強力なリポジトリが提供される点です。</p>


  <p>実験サービスは、使用する任意の Python ツールとフレームワークを利用できるよう構築されています。 実験は、ローカルまたはリモートで Docker コンテナー内でローカルに実行したり、Spark 上でスケールアウトしたりできます。 HDInsight Apache Spark機能により、大量のデータに対するデータの準備と変換、トレーニングが可能です。 ディープ ラーニング ベースの実験は、Microsoft Cognitive Toolkit、<a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a>、<a href="https://caffe2.ai/" target="_blank">Caffe</a>、<a href="https://pytorch.org/" target="_blank">PyTorch</a> などの任意の<a href="https://www.microsoft.com/en-us/cognitive-toolkit/" target="_blank">フレームワーク</a>を使用して GPU アクセラレータ仮想マシンで行われます。 今後 <a href="https://batchaitraining.azure.com/" target="_blank">、Azure Batch AI サービス</a> を使用して大規模なスケールアウト トレーニングを提供し、その後、サービスを通じて運用モデル管理できます。</p>


  <p>Azure Machine Learning で使用できる Machine Learning Server (<a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/python/what-is-revoscalepy" target="_blank">revoscalepy</a> および <a href="https://docs.microsoft.com/en-us/r-server/python-reference/microsoftml/microsoftml-package" target="_blank">microsoftml</a>) の Python ライブラリには、Microsofts&rsquo; 並列外部メモリ アルゴリズム (線形回帰とロジスティック回帰、デシジョン ツリー、ブースト ツリー、ランダム フォレスト) の Python バージョンと、テストされたML アルゴリズムと変換 (ディープ ニューラル ネット、1 つのクラス SVM、高速ツリー、フォレスト、線形回帰、ロジスティック回帰)。 さらに、これらのライブラリには、リモート データ ソースとデプロイ ターゲットを使用して接続するための豊富な API セットが含まれている。 これらのライブラリを使用すると、実験サービスを使用してモデルをトレーニングし、Machine Learning Server が SQL Server &ndash; 、HD Insight、Windows Server、Linux、Spark の 3 つのディストリビューションすべてで実行されている場所で、これらのモデルを運用化できます。このトレーニングと運用化の機能は、事実上すべての Python ツールキットで使用できます。 これにより、お気に入りのデータ サイエンス環境から、モデルを構築し、運用データ プラットフォームで運用化するすばらしい力が得されます。</p>


  <p>データ サイエンスは線形&rsquo;プロセスではないとわかっています。実験サービスを使用すると、時間を振り返って、適切な結果を生成した実験を比較できます。 適切なバージョンを&rsquo;見つけると、使用された正確なコード、構成、データにプロジェクトを簡単に設定して、履歴内の任意の時点から開発を開始できます。 最後に、環境構成を追跡することで、実験サービスを使用すると、まったく同じ構成で新しい環境をすばやく設定して構成できます。 実験サービスは、ローカル コンピューター、ローカルまたはクラウドで実行されている Docker コンテナー、または HDInsight 上の Spark のような Azure のスケールアウト エンジンでのトレーニングを管理します。 コマンド ライン パラメーターを変更することで、ジョブをローカル実行からクラウドに簡単に移動できます。</p>


  <h3>モデル管理</h3>


  <p>このモデル管理サービスは、Azure、オンプレミス、および IOT Edge デバイスのモデルのデプロイ、ホスティング、バージョン管理、管理、監視を提供します。 モデル&rsquo;をホストするためのメカニズムとして、コンテナーの制御、柔軟性、利便性を顧客に提供するために、Docker に対する重要な賭けを車両として採用しました。 コンテナーを使用すると、モデルをホストするために反復可能で一貫性のある環境を取得できます。 モデルは Python で記述された Web サービスを介して公開され、より高度なロジック、カスタム ログ、状態管理、または他のコードを Web サービス実行パイプラインに追加できます。 このロジックは、コンテナーを構築するためにパッケージ化され、Azure Container Registry に登録し、任意の標準の Docker ツールチェーンを使用してデプロイできます。&nbsp; Azure Container Service&rsquo; クラスターに大規模にモデルをデプロイするときに、コンテナーの自動スケーリングを処理し、使用可能なコンテナーに要求を効率的にルーティングする、モデル サービス用に最適化されたホスティング インフラストラクチャを構築しました。</p>


  <p>デプロイされたモデルとサービスは Application インサイト を通じて監視できます。特定のモデル メトリックを含むモデルの実行に関する詳細が決定レベルで提供されます。 デプロイされたモデルでは、バージョンが追跡され、モデルの作成に使用される特定のコード、構成、およびデータへのリンクが有効になります。 モデルアップグレードのデプロイを管理し、新しいバージョンを確実にデプロイしながらダウンタイムを回避し、必要に応じて以前のバージョンにロールバックできるようにサポートが提供されます。 デプロイされたモデルが監視され、新しいデータでトレーニングされた後に更新される再トレーニング シナリオが可能であり、新しいデータに基づいてモデルを継続的に改善できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2002c8b0-b82e-4c8d-8e57-fe815fc91678.png"><img alt="Screenshot_1" border="0" height="1119" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/9950fb99-1a0c-43a5-b68a-c6b2acd2fd60.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Screenshot_1" width="1634"></a></p>


  <p>このモデルの主な利点の 1 つは、デプロイ プロファイルを完全に制御できるという利点です。 すべてのモデルのホストである 1 つのクラスターを作成しますか? 部門または顧客ごとにクラスターをデプロイしますか? 日中に高い通話量をサポートし、夜間にスケールダウンする必要がある単一のモデルはありますか? 私たちの目標は、ユーザーが求めたことを聞いたコントロールとカスタマイズを行う目的で、コンテナー ホスティング インフラストラクチャを制御提供します。 VM&rsquo; の種類とデプロイ プロファイルを柔軟に選択できます。クラスターにデプロイする前に、開発とテストのための単一のインスタンスとして Data Science Virtual Machine の使用を簡単に開始できます。</p>


  <p>また、モデル管理 サービスを通じてデプロイされたモデルは、コードからサービスを使用する簡単なメカニズムとして swagger を提供します。 この機能をExcelパートナーは、この機能を使用して、この機能を使用して、モデルを簡単に検出し、Excel。</p>


  <p>実験サービスと モデル管理 サービスは、モデルの作成に使用されるトレーニング ジョブまで、デプロイされたモデルのガバナンスと一覧を提供するために一緒に動作します。 デプロイされたモデルでテレメトリを有効にすると、決定を可視化し、その決定をモデルを作成した実験まで追跡できます。 これにより、モデルのエンド エンド ライフサイクル全体にわたるデバッグと診断のストーリーが提供されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ead4d1d1-a549-45b8-bee2-c13d07c462f7.png"><img alt="Model Management Image" border="0" height="644" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5c4e1254-dfb2-486c-ac56-1a6fec44a677.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="モデル管理 イメージ" width="704"></a></p>


  <h3>ワークベンチ</h3>


  <p>この作業を開始した時点で、サービスがコマンド ラインから完全に操作可能な動作を確保できるよう取り組みしました。 しかし、環境の設定、データ ラングリング、実行比較の視覚化には課題があるという話も聞かされました。 現在&rsquo;の開発プロセスAzure Machine Learningとして、Azure Machine Learning Workbench&rsquo; を構築しました。ご意見をお寄せいただきありがとうございます。 Azure Machine Learning Workbench は、Windows Mac 上で実行されるクライアント アプリケーションです。 セットアップとインストールが簡単で、構成済みの Python 環境をインストールし、Conda、Jupyter など、Azure のすべてのバックエンド サービスへの接続を備えています。 開発ライフサイクルのコントロール パネルであり、サービスの使用を開始するための最適な方法である予定です。</p>


  <p>また&rsquo;、さまざまなツールと手法を使用したシングル クリック トレーニングを使用して、豊富なサンプル セットをアプリケーションに組み込みます。 [新しいファイル] をクリックすると&ldquo;、Project。&rdquo;実験サービスの一部として説明されている実験履歴管理を次に示します。 実行の履歴に関する主要なメトリックの進化を一目で確認し、個々の実行の詳細なビューを取得し、パフォーマンスを並べて比較することができます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/14899f09-2081-42ae-81ca-810c1b4e829d.png"><img alt="Workbench" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a903e2f8-f00f-4d6a-b996-e97821543256.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="ワークベンチ" width="1200"></a></p>


  <p>たとえば、&rsquo;matplotlib を使用してコードに組み込んだ視覚化はアーカイブされ、実行の詳細の一部として格納されます。 次のスクリーンショットでは、ドキュメント分析の後に出力されているワードクラウドを確認できます。 また、Git コミット ID が含まれているので、この実験を使用した場所から編集を開始する場合は、そのコミットから簡単にチェックアウトできます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/aa4cd0d3-1d19-4bad-8745-b37b94e1abe4.png"><img alt="Workbench 2" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d007e29e-99b5-4fea-8adb-95907b815c42.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 2" width="1200"></a></p>


  <p>最後に、実行を比較し、並べて評価できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4fd83894-8cd6-4edb-9821-10e5a862d6c7.png"><img alt="Workbench 3" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6bf89edd-8c87-4b0c-b299-2207094a4592.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 3" width="1200"></a></p>


  <p>Azure Machine Learning Workbench では、ローカルカーネルまたはリモート カーネルをターゲットにするように構成できる Jupyter Notebook もホストし、ノート PC 上のノートブック内で反復開発を可能にしたり、HDInsight で実行されている大規模な Spark クラスターに接続したりすることもできます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/9ab2fd20-621b-4e05-a75a-d839f0095e87.png"><img alt="Workbench 4" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4e36be56-fb7c-474a-b30e-2af0a958b300.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 4" width="1200"></a></p>


  <h3>AI を利用したデータ ラングリング</h3>


  <p>時間が費やされる最大の領域の 1 つは、データの準備にあるとわかっています。 データの取得、整形、準備に関する課題 (および時間) に関する一貫したフィードバックがあり、それを改善する必要があります。 &ldquo;&rdquo;モデリングのためのデータを取得する時間と労力を短縮し、データ サイエンティストがデータを準備して理解できるペースを根本的に変更し、データ サイエンスを行う時間を短縮したいと考っています。Azure Machine Learning Workbench&rsquo; の一部として、AI を利用してデータを準備する生産性を高め、新しいデータ ラングリング テクノロジのセットを導入しました。 Microsoft Research のプログラム合成 <a href="https://microsoft.github.io/prose/" target="_blank">(PROSE)</a> とデータ クリーニングに関する高度な調査を使用して、さまざまな手法<a href="https://www.microsoft.com/en-us/research/project/data-cleaning/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Fdatacleaning%2F" target="_blank"></a>を組み合わせて、データの準備に費やされる必要がある時間を大幅に短縮するデータ ラングリング エクスペリエンスを作成しました。 データ サイエンティストは、データ ソースを処理する単純なライブラリ セットを含めることで、環境間を移動するときにファイル パスと依存関係を変更する代わりではなく、コードに集中できます。 これらのエクスペリエンスを組み合わせて構築することで、データ サイエンティストは、実行対象の環境を選択するだけで、クラウド コンピューティング エンジン全体で透過的にスケールアウトされるのと同じツールを小規模および大規模で活用できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dd5e3107-cc1e-4af0-90b4-5b34ca16d59b.png"><img alt="Workbench 5" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/02635b00-1f98-457c-ba05-00d9a1af5c47.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 5" width="1200"></a></p>


  <p>このデータ ラングリング ツールの最も強力な機能の 1 つは、例を使用してデータ変換を構築することです。 数値と日付の形式と変換に多くの時間が費やされ、例を示してデータの変換が簡単に行えるのはわかっています。 ここでは、&rsquo;datetime 文字列を取得し、後でデータ セットを結合または集計するために使用できる 1 日 + 2 時間のバケットに変更します。 提供された変換が&rsquo;&rsquo;必要な変換に適合しない場合は、データのフィルター処理または変換に使用できるカスタム Python コードまたはライブラリを簡単に挿入できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7a71ffbe-8ac8-4b62-b1c7-ad1c467127bb.png"><img alt="Workbench 6" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b4e88cae-5431-44a2-bf39-3e5e7d1e0cf5.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 6" width="1200"></a></p>


  <p>構築したデータ変換は、変換の結果を含む pandas データフレームを簡単に返して、Python コードに簡単に組み込むことできます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dbf64e08-7268-4cdc-bf25-0d7d5e76f034.png"><img alt="Workbench 7" border="0" height="900" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a5ab54c3-3df4-472e-91b7-3e6e370494b8.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Workbench 7" width="1200"></a></p>


  <p>データフレームを生成すると、次のコードが作成されます。</p>


  <pre class="prettyprint">

  # Use the Azure Machine Learning data wrangling package

  from azureml.dataprep import package

  # Use the Azure Machine Learning data collector to log various metrics

  from azureml.logging import get_azureml_logger

  logger = get_azureml_logger()

  # This call will load the referenced package and return a DataFrame.

  # If run in a PySpark environment, this call returns a

  # Spark DataFrame. If not, it will return a Pandas DataFrame.

  df = package.run(&#39;bikes.dprep&#39;, dataflow_idx=0)

  # Remove this line and add code that uses the DataFrame

  df.head(10)

  </pre>


  <h3>Visual Studio Code Tools for AI</h3>


  <p>最後に、お&rsquo;客様が選択した開発ツールを使用することが重要であり、そのエクスペリエンスを Azure の新しいサービスとシームレスに連携させる必要があります。 初&rsquo;めてのエディターと、Visual Studio Code <a href="https://marketplace.visualstudio.com/items?itemName=ms-toolsai.vscode-ai#overview">Tools for AI のリリースをお知らせします</a>。 この拡張機能は、ローカルおよびクラウドでジョブを実行し、モデル管理 サービスにデプロイする実験サービスと統合しながら、<a href="https://www.microsoft.com/en-us/cognitive-toolkit/" target="_blank">Microsoft Cognitive Toolkit (CNTK)</a>、<a href="https://www.tensorflow.org/" target="_blank">Google TensorFlow</a>、Theano、<a href="https://keras.io/" target="_blank">Keras</a>、<a href="https://caffe2.ai/" target="_blank">Caffe2</a> などのディープ ラーニング フレームワークを使用してモデルを構築する機能の豊富なセットを提供します。 &nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/704b64c0-a6d6-47d1-b3d1-2edc711f86b0.png"><img alt="Visual Studio Code Tools for AI" border="0" height="656" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/aa2b485c-00a8-46de-ab42-4dce8db98cae.png" style="border-left-width: 0px; border-right-width: 0px; background-image: none; border-bottom-width: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; border-top-width: 0px; margin-right: auto" title="Visual Studio Code Tools for AI" width="1024"></a></p>


  <h2>作業の開始</h2>


  <p>詳細については&rsquo;、Azure に新しいアカウントをデプロイする方法に関するドキュメントをご覧ください。 また、一連のクイック スタート ガイドや、サービスの機能を詳しく説明したチュートリアルも用意されています。</p>


  <ul>
   <li><a href="https://aka.ms/aml-blog-setup" target="_blank">セットアップとインストール</a></li>
   <li><a href="https://aka.ms/aml-blog-iris" target="_blank">クイック スタートのサンプル &ndash; Iris</a>&nbsp;</li>
   <li><a href="https://aka.ms/aml-blog-more-iris" target="_blank">詳細、3 部構成のあやめ分類チュートリアル</a>&nbsp;</li>
   <li><a href="https://aka.ms/aml-blog-data-prep" target="_blank">詳細なデータ ラングリングのチュートリアル</a></li>
  </ul>


  <p>チームのデータ サイエンティストは、サンプル データを含む詳細なシナリオ チュートリアルをまとめ、いくつかの興味深い課題に取り組むか、次の問題にそれらの手法を適応することができます。</p>


  <ul>
   <li><a href="https://aka.ms/aml-blog-image-class" target="_blank">航空画像の分類</a></li>
   <li><a href="https://aka.ms/aml-blog-document-analysis" target="_blank">ドキュメント コレクション分析</a></li>
   <li><a href="https://aka.ms/aml-blog-predictive-maintenance" target="_blank">予測メンテナンス</a></li>
   <li><a href="https://aka.ms/aml-blog-time-series" target="_blank">時系列ベースの予測</a></li>
  </ul>


  <p>常&rsquo;にドキュメントの更新に取り組み、コメントや提案がある場合は、お知らせください。</p>


  <h2>次の&rsquo;情報</h2>


  <p>現在、これらのサービスとツールは、Azure のパブリック プレビューとして利用できます。 今後数か月で、お客様と引き続き取り組み、フィードバックを使用して主要な機能、更新プログラム、グローバル ロールアウトをガイドしながら、サービスを GA に提供します。 フィードバック サイト、<a href="https://social.msdn.microsoft.com/forums/azure/en-US/home?forum=MachineLearning" target="_blank">MSDN</a><a href="https://feedback.azure.com/forums/257792-machine-learning" target="_blank"></a><a href="https://twitter.com/search?q=%23AzureML&amp;src=typd" target="_blank">#</a> フォーラムを通じてチームと関わるか、Twitter で AzureML にタグ付けしてください。 シニア PM Ted Way は、さらに学習することに<a href="https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Finfo.microsoft.com%2Fbuilding-ai-applications.html&amp;data=02%7C01%7Ctedway%40microsoft.com%7Cb20082a1ab514d4eb16608d4fafc4d8a%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636409408943049382&amp;sdata=YFNhwzeD3ApDzv1GDER%2BnaUpP4Pr1pBmDbEHmgdhu%2F4%3D&amp;reserved=0" target="_blank"></a>関心がある場合は、2017&rsquo; 年 10 月 4 日にウェビナーを発表します。</p>


  <p>これは楽しい体験の始&rsquo;めであり、お客様と一緒に作業を行うのを待つ必要があります。</p>
