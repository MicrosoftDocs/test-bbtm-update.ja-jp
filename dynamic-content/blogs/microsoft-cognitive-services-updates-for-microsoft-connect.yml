### YamlMime:Yaml
ms.openlocfilehash: 63e073e60daa93b4bdcaa6f9567433620871766f
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139895418"
Slug: microsoft-cognitive-services-updates-for-microsoft-connect
Title: Microsoft Cognitive Services() の更新プログラムConnect更新プログラム);
Summary: Microsoft Cognitive Servicesを使用すると、開発者は、自然なコミュニケーション方法を使用して、ニーズを表示、聞き、話し、理解、解釈する機能を備え、次世代のアプリケーションを拡張できます。 データ サイエンスの専門知識を持たなくても、視覚と音声認識、感情と感情の検出、言語の理解、検索をアプリケーションに追加できる可能性について考えてみましょう。
Content: >-
  <p>Microsoft Cognitive Servicesを使用すると、開発者は、自然なコミュニケーション方法を使用して、ニーズを表示、聞き、話し、理解、解釈する機能を備え、次世代のアプリケーションを拡張できます。 データ サイエンスの専門知識を持たなくても、視覚と音声認識、感情と感情の検出、言語の理解、検索をアプリケーションに追加できる可能性について考えてみましょう。</p>


  <p>本日は、いくつかのサービス更新をお知らせいたします。</p>


  <ul>
   <li><strong>この&rsquo;暦年の終わりまでに一Azure Bot Service、Language Understanding Intelligent Service に関する取り組みも継続しています。</strong></li>
   <li><strong>Text Analytics API のリージョンと言語</strong> - 11 月の初めから、Text Analytics API は、オーストラリア東部、ブラジル、米国中南部、米国東部、北ヨーロッパ、東アジア、米国西部 2 の新しいリージョンで利用できます。 また、キー フレーズ (スウェーデン語、イタリア語、フィンランド語、ポルトガル語、ポーランド語、オランダ語) の新しい言語もリリースされます。</li>
   <li><strong>翻訳ツール API</strong> -1 年前、Microsoft 翻訳ツールニューラル 機械翻訳 (NMT) と呼ばれるニューラル ネットワークを利用した言語が開始されました。 ニューラル ネットワークは、高品質の翻訳とより人間に聞こえる出力を使用して、完全な文のコンテキストをキャプチャします。 現在、Microsoft 翻訳ツール チームは、ニューラル機械翻訳テクノロジのいくつかの開発を発表し、高度な AI 翻訳のアクセス性を高めました (&rsquo;詳細な発表ブログ記事を参照することをためらわずに)。<a href="https://aka.ms/trscnct"></a> <ul>
    <li>ニューラル機械翻訳では、翻訳ツール Text API、翻訳ツール Speech API、および Microsoft 翻訳ツール アプリとサービスの両方で、合計 21 のサポートされる言語について、<strong>10</strong> の新しい言語を使用できます。 10 の新しい言語は、デンマーク語、チェコ語、デンマーク語、オランダ語、ヒンディ語、ノルウェー語、ポルトガル語、スウェーデン語、トルコ語に対応しています。</li>
    <li><strong>中国語とヒンディー語のすべての API トラフィックは、ニューラル機械翻訳によって利用されます。</strong> つまり、開発者は、これらの &ldquo;新しいシステムの恩恵を受けるのに、アプリで generalnn&rdquo; カテゴリを呼び出す必要があります。</li>
    <li><strong>新 &ldquo;しいハイブリッド&rdquo; 翻訳</strong> は、API とアプリのユーザーにも同様に使用できます。NMT ではまだ利用できない言語にニューラル翻訳の利点をもたらします。 ニューラル機械翻訳を使用している 2 つの言語の 1 つだけがニューラル機械翻訳を利用している場合でも、翻訳のそのセクションに対して Microsoft 翻訳ツール によって NMT が自動的に使用されるので、翻訳の品質が向上します。翻訳のこの部分は改善され、翻訳全体が改善されます。</li>
    <li><strong>音声翻訳は、Long Short Term Memory (LSTM)</strong> テクノロジを使用してエンド エンド で機能します。 これは機械翻訳の品質に直接影響します。音声認識の精度が高い方が、結果として得られる翻訳の精度が高いからです。</li>
    <li><strong>ニューラル機械翻訳がオンプレミス サービスとして利用できる</strong> -オンプレミスオファ<a href="https://www.microsoft.com/en-us/translator/onprem.aspx">リングMicrosoft 翻訳ツール&rsquo;詳細については、以下を参照してください</a>。</li>
   </ul>
   </li>
   <li><strong>Custom Visionモデルのエクスポート</strong> - Custom Vision Service のモバイル モデル エクスポートが利用可能Custom Visionしています。 この新機能を使用すると、分類子をアプリケーションに直接埋め込み、デバイス上でローカルで実行できます。 エクスポートするモデルはモバイル デバイスの制約に合って最適化され、デバイスでリアルタイムで簡単に分類できます。 REST エンドポイントで分類子をホストするだけでなく、iOS 11 用の CoreML 形式へのエクスポートから始め、オフラインで実行するモデルをエクスポートできます。 数週間&rsquo;以内に Android にもエクスポートできます。 この新しい機能により、モバイル アプリケーションにリアルタイムの画像分類を追加する作業が簡単になりました。 モデルを使用して独自のデータを作成およびエクスポートするCustom Vision詳細については、以下を参照してください。</li>
  </ul>


  <p>&nbsp;</p>


  <h2>モデルを使用して独自のデータを作成Custom Visionする方法</h2>


  <p>新&rsquo;しいカスタム ビジョン機能と、開始する <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier">方法について説明します。</a></p>


  <p>Custom Vision サービスは、トレーニング、デプロイ、および改善によって独自のカスタム イメージ分類子を簡単に作成するためのツールです。 探しているカテゴリごとに&rsquo;複数の画像を使用すると、数分で独自の画像分類子の作成とトレーニングを開始できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/02958116-538b-463a-bce9-69ebb6416bbd.png"><img alt="image" border="0" height="265" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1961ef69-b48a-4408-a595-972002cf289c.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="487"></a></p>


  <p>REST エンドポイントでトレーニングした分類子をホストする上で、iOS 11 用の CoreML 形式へのエクスポートから始め、オフラインで実行するモデルをエクスポートできます。</p>


  <p>まず、分類&rsquo;子を構築します。 には&rsquo; が必要です。</p>


  <ul>
   <li>有効な <a href="https://account.microsoft.com/account">Microsoft</a> アカウントまたは Azure Active Directory OrgID (仕事または学校アカウント) です。そのため、customvision.ai にサインインして作業を開始できます (&quot;&quot;国内クラウドから AAD ユーザーの OrgID ログインは現在サポートされていません)。<a href="https://www.microsoft.com/en-us/trustcenter/cloudservices/nationalcloud"></a></li>
   <li>分類子をトレーニングする一連の画像 (タグあたり少なくとも 30 の画像が必要です)。</li>
   <li>分類子のトレーニング後、分類子をテストするための複数の画像。</li>
  </ul>


  <h2>分類子の開始</h2>


  <ul>
   <li>Custom Vision Service について説明した前の投稿では、各手順をコーディングして画像分類子をすばやく作成する方法を説明しました。</li>
   <li>ここでは、サービス&rsquo; UI を使用してCustom Visionします。 最初に、&rsquo; で Custom Vision サービス サイトにアクセスします <a href="https://customvision.ai">https://customvision.ai</a>。</li>
   <li>[<strong>新しいプロジェクトProject</strong>をクリックして、最初のプロジェクトを作成します。</li>
   <li>[新しいProject] ダイアログ ボックスが表示され、名前、説明を入力し、ドメインを選択できます。</li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8d6494a1-aef0-4240-9a47-817281770f26.png"><img alt="image" border="0" height="320" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c2143b2a-7594-413f-afd5-e469cf08e5ee.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; display: inline; background-image: none;" title="イメージ" width="397"></a></p>


  <p>分類子をエクスポートするには、&rsquo;コンパクト ドメインを選択する必要があります。 詳細なドメインの <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/getting-started-build-a-classifier">説明については、</a> 完全なチュートリアルを参照してください。</p>


  <h2>分類子をトレーニングする画像の追加</h2>


  <ul>
   <li>たとえば&#39;犬と犬を区別する分類子が必要だとします。 システムの最小値がカテゴリごとに 5 つの画像を含む場合でも、少なくとも 30 の犬の画像と 30 の猫の画像をアップロードしてタグ付けする必要があります。</li>
   <li>カメラの角度、照明、背景、種類、スタイル、グループ、サイズなど、さまざまな画像をアップロードしてみてください。分類子がいかなる方法でも偏りを持たず、適切に一般化できるよう、写真にはさまざまな種類を使用することをお勧めします。</li>
   <li>[イメージ <strong>の追加] をクリックします。</strong></li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e7c68ab7-1db7-4579-b5da-987e39fd069b.png"><img alt="image" border="0" height="208" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a5cb14a8-ebfa-43a5-8d68-ca2b8b049621.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="519"></a></p>


  <ul>
   <li>トレーニング画像の場所を参照します。</li>
  </ul>


  <p><strong>注</strong>: URL からトレーニング画像をREST APIを使用できます。 Web アプリは、ローカル コンピューターからのトレーニング画像のみをアップロードできます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ca75e1b8-10f3-49e0-94af-fbb02ee20a75.png"><img alt="image" border="0" height="363" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/25a9e23d-e423-4afe-8f72-6d1a640099de.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="282"></a></p>


  <ul>
   <li>[開く] をクリックして最初のタグの画像を選択し、選択した画像を開きます。</li>
   <li>選択したら、割り当&rsquo;<strong>+</strong>てるタグを入力してタグを割り当て、ボタンを押してタグを割り当てる必要があります。 画像には、一度に複数のタグを追加できます。</li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c09fcefa-244f-4c1f-b3c0-72522b0c13eb.png"><img alt="image" border="0" height="473" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5bb1f5dc-fa72-412c-9b20-4b639d5de691.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="407"></a></p>


  <ul>
   <li>タグの追加が完了したら、[number<strong>] ファイルアップロードをクリックします</strong>。 多数のイメージがある場合やインターネット接続が遅い場合は、アップロードに時間がかかる場合があります。</li>
   <li>ファイルがアップロードされた後、[完了] を <strong>クリックします</strong>。</li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/9a1b0282-0562-4a9c-9ccd-13294851b078.png"><img alt="image" border="0" height="278" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a88b5380-ed2e-4ce0-82c2-69872e727688.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="598"></a></p>


  <h3>分類子をトレーニングする</h3>


  <p>画像がアップロードされると、分類子をトレーニングする準備が整います。 必要な操作は、[トレーニング] ボタン <strong>をクリックする必要</strong> があります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5b506bbc-2167-43e0-9e96-fca4ad94d0ec.png"><img alt="image" border="0" height="28" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4fd45cb4-de05-4f04-af76-bdb1d5151726.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="549"></a></p>


  <p>分類子のトレーニングには数分しかかからずに行う必要があります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/88221d30-0a3b-4906-84b9-e6e34efa0ecd.png"><img alt="image" border="0" height="212" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/57e06c26-0531-4b91-b5a9-b25d3a97123c.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="565"></a></p>


  <p>精度インジケーターと呼び戻しインジケーターは、自動テストに基づいて分類子の精度を推定します。 Custom Vision サービスでは、k フォールドクロス検証と呼ばれるプロセスを使用して、トレーニング用に送信した画像を使用してこれらの数値 <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">を計算します</a>。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ab6325c8-0612-4100-a7fd-6d4a302058b4.png"><img alt="image" border="0" height="403" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/36c5b67d-3cc9-417a-a3b0-35a4e5056689.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="427"></a></p>


  <p><strong>メモ：</strong> [トレーニング] ボタンを <strong>クリックする</strong> たび、分類子の新しいイテレーションを作成します。 古いイテレーションはすべて [パフォーマンス] タブで表示でき、古い可能性があるイテレーションはすべて削除できます。 イテレーションを削除すると、一意に関連付けられているイメージが削除されます。</p>


  <p>分類子は、すべての画像を使用して、各タグを識別するモデルを作成します。 モデルの品質をテストするために、分類子はモデル上の各画像を試して、モデルが見つけたものを確認します。</p>


  <h3>分類子のエクスポート</h3>


  <ul>
   <li>エクスポートを使用すると、分類子をアプリケーションに直接埋め込み、デバイス上でローカルで実行できます。 エクスポートするモデルはモバイル デバイスの制約に合って最適化され、デバイス上でリアルタイムで分類できます。</li>
   <li>以前に既存の分類子がある場合は、それをコンパクト ドメインに変換する必要があります。このチュートリアルを <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model">参照してください</a>。</li>
   <li>前のセクションでプロジェクトのトレーニングが完了したら、モデルをエクスポートできます。</li>
   <li>[パフォーマンス] <strong>タブに</strong> 移動し、エクスポートするイテレーション (おそらく最新のイテレーション) を選択します。</li>
   <li>このイテレーションでコンパクト ドメインを使用した場合は、上部のバーにエクスポート ボタンが表示されます。</li>
   <li>[エクスポート <strong>] を</strong>クリックし、形式を選択します (現在、iOS/CoreML を使用できます)。</li>
   <li>[エクスポート] <strong>をクリック</strong> し <strong>、ダウンロードして</strong> モデルをダウンロードします。</li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7cfafaf3-b92b-4b13-98ab-659f4f2e13de.png"><img alt="image" border="0" height="285" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2e0faf7a-2279-4b52-bd0d-93e4ed3f707f.png" style="border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="602"></a></p>


  <h3>iOS アプリケーションでエクスポートされたモデルを使用する</h3>


  <p>最後の手順では、Custom Vision Service からエクスポートされたモデルのサンプル <a href="https://github.com/Azure-Samples/cognitive-services-ios-customvision-sample">iOS</a> アプリケーションの Swift ソースと、Xamarin を使用した <a href="https://github.com/xamarin/ios-samples/tree/master/ios11/CoreMLAzureModel">デモ CoreML モデルを参照してください</a>。</p>


  <p>コーディングをお楽しみください!</p>


  <p>- Microsoft Cognitive Services チーム</p>
