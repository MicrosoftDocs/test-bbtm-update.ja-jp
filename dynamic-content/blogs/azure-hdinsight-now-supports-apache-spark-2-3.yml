### YamlMime:Yaml
ms.openlocfilehash: 380a710a5e145474436f20671ceb012749c18406
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139891782"
Slug: azure-hdinsight-now-supports-apache-spark-2-3
Title: Azure HDInsight 2.3 Apache Sparkがサポートされる
Summary: Apache Spark 2.3.0 は、マネージド ビッグ データ サービス サービス で実稼働環境で使用Azure HDInsight。 バグ修正 (このリリースでは 1400 枚を超えるチケットが修正されました) から、新しい試験的機能 Apache Spark 2.3.0 まで、統合データ プラットフォームのすべての領域に進歩と洗練が加わります。
Content: >-
  <p>Apache Spark 2.3.0 は、マネージド ビッグ データ サービス サービス で実稼働環境で使用Azure HDInsight。 バグ修正 (このリリースでは 1400 枚を超えるチケットが修正されました) から新しい試験的機能まで、Apache Spark 2.3.0 では、統合データ プラットフォームのすべての領域に進歩と洗練が加わります。</p>


  <p>Python UDF に依存するデータ エンジニアは、Spark ランタイムと Python の間でオブジェクトのシリアル化が改良された結果、10 倍から 100 倍の速度になります。 データ科学者、TensorFlow のような Deep ラーニング フレームワークと Spark Machine Learning パイプラインの統合が向上します。 ビジネス アナリストは、ORC ファイル形式の高速ベクター化リーダーの可用性を高め、最終的に Spark の対話型分析を、この一般的な列形式のデータ形式に対して実用的にします。 リアルタイム アプリケーションを構築する開発者は、Spark Structured Streaming で新しい継続的処理モードを試し、イベント処理の待機時間をミリ秒レベルにすることに関心がある場合があります。</p>


  <h2>Python UDF でのベクター化されたオブジェクトのシリアル化</h2>


  <p>DataFrame API を使用している限り、PySpark は既に高速であり、コア Spark エンジンでベクター化されたデータ処理を利用します。 これは、Spark 2.x のベスト プラクティスに従う場合のほとんどの使用事例<a href="https://channel9.msdn.com/Shows/Data-Exposed/Spark-Performance-Series-1-with-Maxim-Lukiyanov" target="_blank"></a>を表すので、良いニュースです。 ただし、Spark 2.3 までは、この規則に大きな例外が 1 つ発生しました。 Python UDF を使用してデータを処理した場合、Spark は標準の Python Pickle シリアル化メカニズムを使用して、Java ランタイムと Python ランタイム間で一度に 1 行のデータを渡します。 Pickle は堅牢なメカニズムですが、ビッグ&rsquo; データ ワークロードがテラバイト単位のデータを日常的に処理する場合、この設定では効率的ではありません。 バージョン 2.3 より、Spark では、Java ランタイムと Spark ランタイム間で共通のバイナリ形式で列形式のデータ表現を使用する新しい Arrow シリアライザーを使用することを選択します。 これにより、最新のプロセッサでベクター化された処理が可能になります。これにより、パフォーマンスが大幅に向上します。 新しい機能は、新しい Pandas UDF API を通じて公開されます。これにより、Python UDF で一般的な Pandas API を使用できます。 新しい Pandas UDF API を使用して UDF をプログラムすると、パフォーマンスが 10 倍から 100 倍大幅に向上します。 新しい機能は既定では無効になっています。 有効にするには、次のプロパティを true に設定します。</p>


  <pre style="margin-left: 40px;">

  spark.sql.execution.arrow.enabled = true</pre>


  <h2>ORC 形式の高速ネイティブ リーダー</h2>


  <p>ORC ファイル形式の Spark のサポートは、競合する Parquet と比較してサブパーでした。 どちらの形式でも、効率的な列指向のデータへのアクセスという同じ問題が解決されます。 しかし、長い間、Spark は ORC よりもはるかに優れた Parquet ファイルで動作しました。 Spark 2.3.0 でのこれらの変更はすべて、Hortonworks が ORC ファイル形式の高速ネイティブ ベクター化リーダーを提供しました。 新しいネイティブ リーダーによってクエリが 2 倍から 5 倍高速化され、Parquet の速度でヘッド コンペティションが行えます。 このレベルのパフォーマンスにより、混合シナリオが実用的になります。 たとえば、HDInsight を使用しているお客様は、Hive LLAP <a href="https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-interactive-query-get-started" target="_blank"></a> テクノロジを利用するクラスター Interactive Query ORC 形式を頻繁に選択します。 これで、共有 ORC データセットに対して Spark でデータ サイエンスを効率的に実行できます。</p>


  <p>新しいベクター化されたリーダー/ライターは、ネイティブ実装を実現するだけでなく、古いコード ベースのいくつかの問題を解決する、完全に再設計されたコード ベースです。 現在、ORC ライターは、最新の ORC 形式との互換性のあるバージョンを生成し、述語のプッシュダウンをサポートし、構造化ストリーミング ジョブでの形式の使用に関する問題を解決します。 その新しい ORC 形式に加え、スキーマの進化がサポートされ、ユーザーはテーブルに追加されたデータ ファイルの進化に合わせて列を追加/削除できます。 Parquet リーダーとは異なり、列の型に対する変更もサポートされます(例: float -&gt; double)。 これにより、ORC リーダーは Parquet より先行しますが、制限の一部は残っています。 そのうちの 1 つは強力な手法バケットです。これは ORC リーダーではまだサポートされていませんが、Parquet でのみ使用できます。 Spark 2.3.0 では、下位互換性のために、新しいネイティブ リーダーが既定で有効になっていません。 この機能を有効にするには、次のプロパティを変更します。</p>


  <pre style="margin-left: 40px;">

  spark.sql.orc.impl=native

  spark.sql.hive.convertMetastoreOrc=true</pre>


  <h2>構造化ストリーミングでの継続的処理 (試験段階)</h2>


  <p>継続的処理モードが Spark Structured Streaming の一部になります。 これは、Spark のマイクロバッチ 処理アーキテクチャから離れ、個々のイベントの真のストリーミング処理を実現するストリーミング ジョブ用の新しい実行エンジンです。 新しいモードの利点は、イベント処理の待機時間が大幅に改善され、ミリ秒未満になる可能性があります。 これは、不正行為の検出、広告の配置、メッセージ バス のアーキテクチャなど、待機時間が重要な使用例で重要です。 構造化ストリーミング ジョブで有効にするのは非常に簡単で、トリガー モードを <strong>Trigger.Continuous</strong> に設定しただけで、ジョブの残りの部分は変更されません。</p>


  <p>試験的な機能に加えて、この新機能には大きな制限があります。 連続処理モード (map-select、filter-where) では、マップの種類の操作だけがサポートされ、メッセージ処理の配信保証は脆弱になります。 Structured Streaming の標準マイクロバッチ モードでは 1 回限りがサポートされます。一方、継続的モードでは、少なくとも 1 回のイベント処理の保証しかサポートされません。</p>


  <p style="margin-left: 40px;"><img alt="Code" border="0" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/Spark-2-3-0-continuous-streaming.png" style="border: 0px currentcolor; border-image: none; width: 513px; height: 146px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;"></p>


  <h2>その他の改良</h2>


  <h3>ストリーム間結合</h3>


  <p>もともと、構造化ストリーミングが Spark 2.0 で導入された場合、静的結合へのストリームだけがサポートされました。 これは、2 つのデータ ストリームを関連付ける必要があるシナリオの数に制限されています。 Spark 2.3 では、2 つのストリームを結合できます。 ウォーターマークと時間の制約を使用して、結合を実行するために 2 つのストリーム内のデータをバッファーする量を制御できます。</p>


  <h3>ディープ ラーニングの統合</h3>


  <p>Spark を使用して、一般的な Deep ラーニング ライブラリ TensorFlow (および Keras) のモデルを Spark MLトランスフォーマーとして統合できます。 それに役立つには、ファイルからイメージを読み取り、DataFrame として表す組み込み関数も用意されています。</p>


  <h3>DataSource API v2 (ベータ)</h3>


  <p>Spark の強みの 1 つは、さまざまなデータソースに対する幅広いサポートです。 Cassandra、HBase、Azure Blob Storage、新しい <a href="https://azure.microsoft.com/en-us/blog/a-closer-look-at-azure-data-lake-storage-gen2/" target="_blank">Azure Data Lake Storage (gen2)</a>、Kafka など多数に接続し、Spark を使用して一貫した方法でデータを処理できます。 新しいバージョンでは、このデータ ソースの作成に使用される API が大きなリファクタリングを受け取る。 新しい API は、SparkContext や DataFrame などの上位レベルのクラスへの依存関係を取り除き、より多くの最適化を Datasource 開発者が実装できるより広範な一連の原始点に対して、コンパクトで正確なインターフェイスを提供します。 データ サイズ、パーティション分割情報、ストリーミング ソースのサポート、バッチ指向のもの、トランザクション書き込みのサポートなどです。 これらの変更はすべて、Spark エンド ユーザーに対して透過的です。</p>


  <h3>Kubernetes 上の Spark (試験段階)</h3>


  <p>Kubernetes クラスタリング フレームワークの人気が高くなるにつれて、Spark は、Kubernetes クラスターで Spark ジョブを直接スケジュールするネイティブ機能を利用できます。 ジョブはリポジトリ内のどこかの Docker イメージとして指定する必要があります。ただし、基本的なイメージは Spark で提供され、アプリを動的に読み込むか、独自のカスタム イメージのベースとして使用できます。</p>


  <p><a href="https://azure.microsoft.com/en-us/services/hdinsight/apache-spark/" target="_blank">HDInsight Spark の詳細については、</a>以下を参照してください。 修正された問題の詳細な一覧については、 <a href="https://spark.apache.org/releases/spark-release-2-3-0.html" target="_blank">Spark 2.3.0 リリース ノートを参照してください</a>。</p>


  <h2>今すぐ HDInsight を試す</h2>


  <p>新しい Spark 機能をフルに活用して、新しい Spark を使用して何を構築Azure HDInsight。 <a href="https://azure.microsoft.com/en-us/blog/azure-hdinsight-training-resources-learn-about-big-data-using-open-source-technologies/" target="_blank">この開発者ガイドを読み</a> 、クイック スタート ガイドに従って、これらのパイプラインとアーキテクチャを実装する方法の詳細については、Azure HDInsight。 Twitter HDInsight と でフォローすることで、最新Azure HDInsight最新のニュースと機能<a href="https://twitter.com/search?q=%23HDInsight&amp;src=typd" target="_blank">に関する最新情報を確認してください。#</a> <a href="https://twitter.com/AzureHDInsight" target="_blank">@AzureHDInsight</a> 質問とフィードバックについては、 にお問い合わせください <a href="mailto:AskHDInsight@microsoft.com">AskHDInsight@microsoft.com</a>。</p>


  <h2>HDInsight について</h2>


  <p>Azure HDInsightは、Azure でオープン&rsquo; ソース ワークロードを実行する Microsofts Premium マネージド オファリングです。 本日は、さまざまな OSS フレームワークでいくつかの新機能をお知らせします。</p>


  <p>&rsquo;Azure HDInsight、製造、小売教育、非営利団体、政府機関、医療、メディア、銀行、電気通信、保険など、ETL からデータ ウェアハウス、Machine Learning から IoT まで、さまざまな業界を含む、多くの業界に及ぶ、トップカスタマーのミッション クリティカルなアプリケーションの一部に力を与えています。</p>
