### YamlMime:Yaml
ms.openlocfilehash: dbdadd80d91c4aaeac1dc0dbf2a58abb723df47b
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896214"
Slug: azure-introduces-new-capabilities-for-live-video-analytics
Title: Azure では、ライブ ビデオ分析の新機能が導入されます
Summary: 2020 年 6 月に、インテリジェント エッジからインテリジェント クラウドへのリアルタイム分析を使用してビデオをキャプチャして処理するワークフローを構築できる、Azure Media Services の新しい機能セットである Live Video Analytics プラットフォームのプレビューを発表しました。
Content: >-
  <p>2020 年 6 月に、インテリジェント エッジからインテリジェント クラウドへのリアルタイム分析を使用してビデオをキャプチャして処理するワークフローを構築できる、<a href="https://azure.microsoft.com/blog/introducing-live-video-analytics-on-iot-edge-now-in-preview/" target="_blank">Azure Media Services の新</a>しい機能セットである Live Video Analytics&mdash; プラットフォームのプレビューを発表しました。 お客様の組織の肯定的な成果を引き起Live Video Analytics、IoT Edgeプレビューのアプリを積極的に使用している業界間のお客様を引き続きご覧ください。 先週の Microsoft Ignite では、ソーシャル ディザク点、工場の安全性、セキュリティ境界の監視など、追加のシナリオのロックを解除する新機能、パートナー統合、参照アプリを発表しました。 これらのシナリオを可能にする新しい製品機能は次のとおりです。</p>


  <ul>
      <li><strong>Azure Computer Vision の空間 Cognitive Services分析 :</strong> 物理ドメイン内の人と移動の間の空間リレーションシップを考慮した強化されたビデオ分析。</li>
      <li><strong>Intel OpenVINO Model Server の統合:</strong> Intel CPU (Atom、Core、Xeon)、FPGA、VPUs で実行される最適化された事前トレーニング済みモデルを使用して、OpenVINO ツールキットを利用した複雑で高パフォーマンスのライブ ビデオ分析ソリューションを構築します。</li>
      <li><strong>NVIDIA DeepStream 統合:</strong> NVIDIA GPU の機能と Azure サービスを組み合わせたハードウェア アクセラレータハイブリッド ビデオ分析アプリのサポート。</li>
      <li><strong>Arm64 のサポート:</strong> 低電力で低フットプリントの Linux Arm64 デバイスにライブ ビデオ分析ソリューションを開発してデプロイします。</li>
      <li><strong>Azure IoT Central Custom Vision テンプレート:</strong> コーディングを必要となく、わずか数分から数時間で豊富なカスタム ビジョン アプリケーションを構築します。</li>
      <li><strong>統合を使用した高フレーム レートのCognitive Services Custom Vision:</strong> 工場環境の 6 つの便利なシナリオをサポートする製造業界のリファレンス アプリで示されています。</li>
  </ul>


  <h2>ビデオ AI を使いやすくする</h2>


  <p>幅広い CPU アーキテクチャ (x86-64、Arm など) とハードウェア アクセラレーション オプション (Intel Movidius VPU、iGPU、FPGA、NVIDIA GPU) に加えて、カスタマイズされた AI を構築するデータ サイエンスプロフェッショナルの多くが、従来のビデオ分析ソリューションを組み合わせて使用すると、多大な時間、労力、複雑さを伴います。</p>


  <p>&rsquo;&mdash;本日発表された発表では、Intel、NVIDIA、Arm などの広く使用されているチップ アーキテクチャのサポート、NVIDIA DeepStream や Intel OpenVINO などのハードウェア最適化 AI フレームワークとの統合、Microsoft&rsquo; AI&mdash; エコシステム全体の補完的なテクノロジとの緊密な統合により、ビデオ分析のアクセス性と便利性を高め、すべてのユーザーにとって役に立つものにするためのミッションをさらに進めています。Computer Vision分析と Cognitive Services Custom Vision に関するページと、Azure IoT Central Custom Vision テンプレートと製造フロア参照アプリケーションを使用した開発エクスペリエンスの向上に関するページを参照してください。</p>


  <h2>空間分析用の Computer Visionライブ ビデオ分析</h2>


  <p>Azure Cognitive Service の一部である Computer Vision の空間分析機能は、Live Video Analytics on IoT Edge と組み合わせて使用して、物理的な環境での人と移動の間の空間関係をよりよく理解できます。 &rsquo;カメラ&rsquo;の視野内の指定されたゾーン内の人をカウントしたり、人が指定された線やエリアを越えた場合、または人が距離ルールに違反した場合を追跡したりできる新しい操作が追加されました。</p>


  <p>このLive Video Analyticsモジュールは、リアルタイム ストリーミング プロトコル (RTSP) カメラからライブ ビデオをキャプチャし、AI 処理用の空間分析モジュールを呼び出します。 これらのモジュールは、ビデオ分析と、ローカルまたは Azure Blob Storage へのクリップの記録を有効にするように構成できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/70553d6b-5ec6-4245-bdf6-0d49dfd7a757.jpg"><img alt="An architecture diagram showing how Computer Vision Spatial Analysis and Live Video Analytics can be combined to build computer vision solutions that understand spatial relationships in physical environments" border="0" height="676" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/49710bf3-888e-481e-9699-f0083f0a0840.jpg" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="" width="911"></a></p>


  <p>エッジ デバイスLive Video Analytics空間分析モジュールのデプロイは、Azure IoTハブで簡単に行えます。 推奨されるエッジ デバイスは <a href="https://docs.microsoft.com/azure/databox-online/azure-stack-edge-gpu-overview" target="_blank">、Azure Stack Edge NVIDIA T4 Tensor Core GPU で使用できます</a>。 空間分析の詳細については、ドキュメントの「空間 <a href="https://aka.ms/lva-spatial-analysis" target="_blank">分析Computer Visionライブ ビデオ</a> を分析する方法に関するページを参照してください。</p>


  <h2>Live Video Analytics Intels&rsquo; OpenVINO モデル サーバーを使用したインストール</h2>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/50336828-cf8a-4928-b0e5-2f182b305587.jpg"><img alt="An architecture diagram showing how Live Video Analytics can be combined with Intel’s OpenVINO Model Server and your own business logic to build custom vision apps that are optimized to run on a wide range of Intel processors." border="0" height="293" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0beec9ee-6287-48ae-a4ad-a239e6457c4f.jpg" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="" width="1024"></a></p>


  <p>IoT Edge モジュール上の Live Video Analytics と <a href="https://aka.ms/lva-intel-ovms" target="_blank">Intel の OpenVINO Model Server (OVMS) &ndash; AI 拡張機能</a> を組み合わせ、複雑で高パフォーマンスのライブ ビデオ分析ソリューションを構築できます。 OpenVINO モデル サーバー&nbsp;は、Intel で実行されている Computer Vision ワークロード用に高度に最適化された <a href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" target="_blank">OpenVINO</a>&rsquo; ツールキットを搭載した推論サーバーです。 <a href="https://github.com/openvinotoolkit/model_server/tree/master/extras/ams_wrapper" target="_blank"></a>拡張機能として、HTTP サポートとサンプルが OVMS に追加され、推論サーバーと Live Video Analytics <a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/use-intel-openvino-tutorial" target="_blank"></a> モジュールの間でビデオ フレームと推論結果を簡単に交換し、OpenVINO ツールキットでサポートされているオブジェクト検出、分類、またはセグメント化モデルを実行できます。</p>


  <p>推論サーバー モジュールをカスタマイズして、 <a href="https://github.com/openvinotoolkit/open_model_zoo" target="_blank">Open Model Zoo</a> リポジトリで最適化された事前トレーニング済みモデルを使用し、アプリケーションを変更することなく、Intel ハードウェアでサポートされているさまざまな高速化メカニズムから選択できます。CPU (Atom、Core、Xeon)、フィールド プログラミング ゲート アレイ (FPGA)、ビジョン処理ユニット (VPUs) など、用途に最適です。 さらに、開発者キットや市場対応ソリューションなど、さまざまな使用例に固有の Intel ベースのソリューションから選択<a href="https://www.intel.com/content/www/us/en/internet-of-things/ai-in-production/develop.html" target="_blank"></a>し、簡単<a href="https://www.intel.com/content/www/us/en/internet-of-things/ai-in-production/scale.html" target="_blank"></a>にプラグ可能な Live Video Analytics プラットフォームを組み込んでスケールできます。</p>


  <p style="margin-left: 40px;">OpenVINO Model Server for Azure Live Video Analytics を拡張することで、エッジで AI の力を引き<em>出せLive Video Analytics。&ldquo;この拡張機能により、モジュール式分析プラットフォームを使用して複雑なビデオ ソリューションを開発するプロセスが簡略化されます。開発者は、一度&rsquo;クラウド アプリケーションにすばやくエッジを構築し、豊富なエコシステムを通じて Intels の幅広いコンピューティングおよび AI アクセラレータ プラットフォームにデプロイすることができます。&rdquo;&mdash;</em>Adam Burns、VP、Edge AI 開発者ツール、モノのインターネット、Intel</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5744f58e-b73f-46ce-b846-39a18171781e.jpg"><img align="left" alt="#1509 3" border="0" height="121" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1028a828-30db-415a-a4ed-b97746321bd3.jpg" style="border:0px currentcolor; display:inline; background-image:none; float:right" title="#1509 3" width="121"></a></p>


  <p>&nbsp;</p>


  <p>&nbsp;</p>


  <p>&nbsp;</p>


  <h2>Live Video Analytics NVIDIAs&rsquo; DeepStream SDK の使用</h2>


  <p>Live Video Analytics および NVIDIA DeepStream SDK を使用すると、NVIDIA グラフィック処理ユニット (GPU) の機能を azure クラウド サービス (Azure Media Services、Azure Storage、Azure IoT など) と組み合わせたハードウェアアクセラレータを使用した AI ビデオ分析アプリを構築できます。 何千もの場所にまたがってスケーリングできる高度なリアルタイム アプリを構築し、クラウド経由でそれらの場所にあるエッジ デバイス上のビデオ ワークフローを管理できます。 関連するサンプルについては<a href="https://github.com/Azure/live-video-analytics/tree/master/utilities/video-analysis/deepstream" target="_blank">、</a>GitHub。</p>


  <p>Live Video Analytics を使用してエッジとクラウドにまたがるビデオ ワークフローを構築し、DeepStream SDK を組み合わせてパイプラインを構築し、選択した AI を使用してビデオから分析情報を抽出できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1df3ed02-2c2c-4395-a344-f23c96495dd4.jpg"><img alt="An architectural flow diagram that illustrate show you can use LVA to build video workflows that span the edge and cloud, and then combine DeepStream SDK to build pipelines to extract insights from video using the AI of your choice. " border="0" height="536" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2612dd29-62da-451c-8bac-c31729507091.jpg" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="" width="856"></a></p>


  <p>上の図は、AI イベントによってトリガーされたビデオ クリップを記録して、クラウド内でAzure Media Servicesする方法を示しています。 このサンプルは、両方のプラットフォームの堅牢な設計と開放性に対する優れた機能です。</p>


  <p style="margin-left: 40px;"><em>&ldquo;NVIDIA DeepStream SDK と NVIDIA コンピューティング スタックを利用した Live Video Analytics の強力な組み合わせは、世界クラスのビデオ分析の開発とデプロイを加速するのに役立ちます。Microsoft とのパートナーシップにより、AI 対応のビデオ分析のエッジからクラウドへの導入が、すべての業界と使用事例にわたって促進されます。&rdquo;&mdash;</em>Deepu Talla、NVIDIA、Edge Computing の副社長兼ジェネラル マネージャー</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d4467cb5-e869-4679-bc2e-07978d337fa2.png"><img alt="#1509 5" border="0" height="83" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e511e5f7-2aaa-4bfd-b22a-487828607353.png" style="border:0px currentcolor; display:inline; background-image:none; float:right" title="#1509 5" width="240"></a></p>


  <p>&nbsp;</p>


  <h2>&nbsp;</h2>


  <h2>Live Video Analytics Arm で実行される</h2>


  <p><a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/deploy-iot-edge-device" target="_blank">Linux Arm64v8</a> デバイスの Live Video Analytics IoT Edge でアプリケーションを実行し、<a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/" target="_blank">NVIDIA&reg; Jetson&trade;</a> シリーズなどの低電力でフットプリントの低いデバイスを使用できます。</p>


  <h2>IoT Central Video Analytics テンプレートを使用してソリューションを迅速に開発する</h2>


  <p>新しい <a href="https://apps.azureiotcentral.com/build/new/video-analytics-om" target="_blank">IoT Central ビデオ</a>分析テンプレートを使用すると、カメラと Azure クラウド サービスの間のゲートウェイとして機能する Azure IoT Edge デバイスのセットアップが簡略化されます。 Intel によって Azure Live Video Analytics ビデオ推論パイプラインと OpenVINO Model Serveran&mdash; AI Inference Server が統合され、顧客はコードを使用しない完全に動作するエンドツーエンド ソリューションを数時間で構築できます。 クラウド&rsquo;から分析されたビデオをキャプチャ、記録、再生Azure Media Servicesパイプラインと完全に統合されています。</p>


  <p>このテンプレートはIoT Edge IoT Central Gateway、IoT Edge 上の Live Video Analytics、Intel OpenVINO モデル サーバー、ONVIF モジュールなどのモジュールをエッジ デバイスにインストールします。 これらのモジュールは、IoT Central アプリケーションでデバイスの構成と管理、カメラからのライブ ビデオ ストリームの取り込み、車両や人の検出などの AI モデルの適用に役立ちます。 クラウドで同時に、ライブ ビデオ フィードAzure Media Services関連Azure Storageの記録とストリーミングを行います。 開始方法<a href="https://aka.ms/iotshow/VisionAIInIoTCentral" target="_blank"></a>の<a href="https://aka.ms/iotshow/232/youtube" target="_blank">概要とガイダンスについては、IoT Show の</a>エピソードと関連するブログ記事を参照してください。</p>


  <h2>データ モデルCognitive Services Custom Vision統合Live Video Analytics</h2>


  <p>多くの組織では、ビデオ データをキャプチャするために多数のカメラが既に展開されているが、ストリームに対して意味のある分析を行っているのではない。 Live Video Analytics の登場により、基本的な画像分類と物体検出アルゴリズムをライブ ビデオ フィードに適用することで、真に有用な分析情報のロックを解除し、企業の安全性、安全性、効率を高め、最終的には収益性を高めることができます。 次のようなシナリオが考えられます。</p>


  <ul>
      <li>工業/製造工場の従業員が、安全と現地の規制への準拠を確保するためにハード キャップを身に着けている場合の検出。</li>
      <li>製品をカウントしたり、コンベヤ ベルトで欠陥のある製品を検出したりします。</li>
      <li>不要なオブジェクト (人や車両など) がオンプレミスに存在することを検出し、セキュリティに通知します。</li>
      <li>小売店の棚または工場の部品の棚で在庫切れ製品を検出する。</li>
  </ul>


  <p>このようなタスクを実行するために AI モデルをゼロから開発し、エッジ上のライブ ビデオ ストリームで動作するために大規模にデプロイすると、簡単ではない作業が伴います。 スケーラブルで信頼性の高い方法で実行すると、さらに困難でコストが高くなります。 Live Video Analytics IoT Edge Cognitive Services Custom Vision <a href="https://azure.microsoft.com/services/media-services/live-video-analytics/" target="_blank"></a> との統合により、これらのすべてのシナリオに対応する<a href="https://azure.microsoft.com/services/cognitive-services/custom-vision-service/" target="_blank"></a>作業ソリューションを数分から数時間で実装できます。<a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/custom-vision-tutorial" target="_blank"></a></p>


  <p>最初に、事前にラベル付けされた画像をクラウド サービスにアップロードすることで、computer vision モデルを構築Custom Visionします。 これには、&rsquo;データ サイエンス、機械学習、または AI に関する事前の知識が必要です。 次に、Live Video Analytics を使用して、トレーニング済みのカスタム モデルをコンテナーとしてエッジにデプロイし、コスト効率の高い方法で複数のカメラ ストリームを分析できます。</p>


  <h2>Live Video Analyticsを搭載した製造フロア参照アプリ</h2>


  <p>Azure Stack チームと提携して <a href="https://aka.ms/LVAwithASE-ManufacturingAI" target="_blank">、Factory.AI</a> ソリューションを進化させ、データ サイエンスの知識を必要とせずにビジョン モデルを簡単にトレーニングしてデプロイできるターンキー アプリケーションです。 このソリューションには、物体のカウント、従業員の安全性、欠陥検出、機械の不合わせ、ツールの検出、部品の確認の機能が含まれています。 これらのシナリオはすべて、デバイス上で実行されているLive Video Analytics統合によってAzure Stack Edgeされます。</p>


  <p>さらに、このソリューション Factory.AI SDK を使用して独自のカスタム <a href="https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/custom-vision-onnx-windows-ml" target="_blank">ONNX</a> モデルをトレーニングしてデプロイ <a href="https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?pivots=programming-language-csharp" target="_blank">Custom Visionすることもできます</a>。 カスタム モデルがエッジにデプロイされた後、参照アプリは、高フレーム <a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/analyze-live-video-use-your-grpc-model-quickstart?pivots=programming-language-csharp" target="_blank">レートの正確なインフェLive Video Analyticsから gRPC</a> を活用します。 製造リファレンス アプリの詳細については、 <a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank">Microsoft Ignite</a> または Azure インテリジェント エッジ パターンに関する <a href="https://github.com/Azure-Samples/azure-intelligent-edge-patterns/tree/master/factory-ai-vision" target="_blank">ページを参照してください</a>。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1fefde35-a95d-442f-ac9f-b92c8b7de9ef.jpg"><img alt="An architectural flow diagram illustrating how to configure the Factory.ai, powered by the integration of LVA running on Azure Stack Edge devices." border="0" height="659" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/00a9ea66-52f5-44df-bf25-fcf8825c559f.jpg" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="" width="1024"></a></p>


  <h2>概要今日</h2>


  <p>最後に、プレビュー&rsquo;のリリースに既に参加しているすべてのユーザーに感謝Live Video AnalyticsおIoT Edgeしています。 クラウドとエッジの両方でビデオ分析を成功に向け、エンジニアリング チームに継続的なフィードバックをお寄せください。 このテクノロジを使い始&rsquo;めた方には、次の役立つリソースを今すぐ使い始めにお勧めしています。</p>


  <ul>
      <li>概要Live Video Analytics <a href="https://azure.microsoft.com/resources/videos/live-video-analytics/" target="_blank">ビデオをご覧ください</a>。</li>
      <li>詳細については、製品の詳細 <a href="https://azure.microsoft.com/services/media-services/live-video-analytics/" target="_blank">ページを参照してください</a>。</li>
      <li>次のデモ <a href="https://azure.microsoft.com/en-us/resources/videos/live-video-analytics-demo/" target="_blank">Live Video Analyticsしてください</a>。</li>
      <li>Azure 無料 <a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/overview" target="_blank">試用版アカウントLive Video Analytics新</a> しい機能をお試しください。</li>
      <li><a href="https://techcommunity.microsoft.com/t5/azure-media-services/bg-p/AzureMediaServices" target="_blank">Media Services Tech Community に</a>登録し、今後の新機能についてエンジニアリング チームから直接お聞きになり、フィードバックを提供し、ロードマップの要求について話し合います。</li>
      <li>Live Video AnalyticsからIoT Edgeをダウンロード <a href="https://azuremarketplace.microsoft.com/marketplace/apps/azure-media-services.live-video-analytics-edge?tab=Overview" target="_blank">Azure Marketplace</a>。</li>
      <li>概要、<a href="https://github.com/Azure-Samples/live-video-analytics-iot-edge-csharp" target="_blank">C# と Python のコード サンプル</a><a href="https://github.com/Azure-Samples/live-video-analytics-iot-edge-python" target="_blank">を使用してすばやく</a>使用できます。</li>
      <li>製品ドキュメント <a href="https://docs.microsoft.com/azure/media-services/live-video-analytics-edge/overview" target="_blank">を確認してください</a>。</li>
      <li>オープンソース プロジェクト<a href="https://github.com/Azure/live-video-analytics" target="_blank">GitHubのLive Video Analytics</a>を検索します。</li>
      <li>質問については <a href="mailto:amshelp@microsoft.com">amshelp@microsoft.com</a> 、お問い合わせください。</li>
  </ul>


  <hr>

  <p>Intel、Intel ロゴ、Atom、Core、Xeon、OpenVINO は、Intel Corporation または子会社の商標です。</p>


  <p>NVIDIA および NVIDIA ロゴは、米国およびその他の国における NVIDIA Corporation の商標または商標です。 その他の会社名と製品名は、関連付けられているそれぞれの会社の商標である可能性があります。</p>
