### YamlMime:Yaml
ms.openlocfilehash: ddb9c29e882e7fb1e34cceef25e950a1ac61757f
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896026"
Slug: containers-docker-windows-and-trends
Title: 'Containers: Docker, Windows and Trends (コンテナー: Docker、Windows、および傾向)'
Summary: コンテナーとはどのようなものか、そしてそれがどのように機能するかについての基本から、現在最も広く使用されているシナリオ、"コンテナー化" をサポートする最新の傾向について、この重要なクラウドコンピューティング開発を最も効果的に活用する方法を理解するのに役立つように、パースペクティブを共有しました。
Content: >-
  最近、コンテナーについて話をすることなく、クラウドコンピューティングについて説明することはできません。 銀行や大手金融サービス企業から e コマースサイトまで、すべてのビジネスセグメントにわたる組織は、コンテナーとは何か、クラウド内のアプリケーションにとっての意味、および特定の開発および IT 運用シナリオで最適に使用する方法を理解したいと考えています。


  コンテナーとはどのようなものか、そしてそれがどのように機能するかについては、今日で最も広く使用されているシナリオ、"コンテナー化" をサポートする最新の傾向、クラウドアプリケーションをよりシームレスに構築、テスト、デプロイ、管理するために、この重要なクラウドコンピューティング開発に最適な方法を理解するのに役立つように、

  <h2>コンテナーの概要</h2>

  要約すると、すべてのコンピューティングは、プロセッサ、メモリ、ディスク、ネットワークなどの一連の "物理" リソースに対して何らかの "関数" を実行することに基づいています。たとえば、1 + 1 のような単純な数値演算や、複数のコンピューターにまたがる複雑なアプリケーション (Exchange など) を実行します。 時間の経過と共に、物理的なリソースがより強力になり、多くの場合、アプリケーションは物理マシンによって提供されるリソースの一部を利用していませんでした。 このため、基礎となる物理ハードウェアをシミュレートするために "仮想" リソースが作成され、複数のアプリケーションを同時に実行できるようになりました。それぞれが同じ物理マシンの物理リソースの数を利用します。


  一般的に、これらのシミュレーション手法を仮想化と呼びます。多くの人は仮想マシンが仮想化を聞いたときにすぐに考えますが、仮想化の実装は1つだけです。 すべての汎用オペレーティングシステム (OSs) によって実装されるメカニズムである仮想メモリは、コンピューターのメモリが専用であるという錯覚をアプリケーションに提供し、コンピューターが使用できる RAM よりも多くの RAM にアクセスできることをアプリケーションに与えることもできます。


  コンテナーは、OS 仮想化とも呼ばれる別の種類の仮想化です。 Linux の現在のコンテナーでは、完全に分離された独立した OS の認識をアプリケーションに対して作成します。 実行中のコンテナーについては、ローカルディスクは OS ファイルの不自然のコピーのように見えます。メモリは、新しく起動した OS のファイルとデータを保持するためだけに表示され、実行されるのは OS だけです。 これを実現するために、コンテナーを作成する "ホスト" コンピューターはいくつかの機能を備えています。


  最初の方法は、名前空間の分離です。 名前空間には、ファイル、ネットワークポート、実行中のプロセスの一覧など、アプリケーションが操作できるすべてのリソースが含まれます。 名前空間の分離を使用すると、ホストは、表示する必要のあるリソースのみを含む仮想化された名前空間を各コンテナーに付与できます。 この制限付きビューでは、コンテナーは、そのアクセス許可に関係なく、仮想化された名前空間に含まれていないファイルにはアクセスできません。 また、コンテナーに含まれていないアプリケーションを一覧表示したり、対話したりすることもできません。これは、他に数十または数百ものが存在する場合に、システム上で実行されている唯一のアプリケーションであることを fools しています。


  効率を高めるために、OS ファイル、ディレクトリ、および実行中のサービスの多くは、コンテナー間で共有され、各コンテナーの名前空間に投影されます。 既存のファイルを変更したり、新しいファイルを作成したりするなどして、アプリケーションがコンテナーに変更を加えた場合にのみ、コンテナーは基になるホスト OS から個別のコピーを取得しますが、これらの部分のみが変更され、Docker の "書き込み時コピー" の最適化が使用されます。この共有は、1つのホストに複数のコンテナーを展開することが非常に効率的であることの一部です。


  次に、ホストは、コンテナーが使用できるホストのリソースの量を制御します。 CPU、RAM、ネットワーク帯域幅などのリソースを管理することで、コンテナーが想定しているリソースを取得し、ホスト上で実行されている他のコンテナーのパフォーマンスに影響を与えないようにすることができます。 たとえば、コンテナーは、CPU の10% を超えることができないように制限することができます。 つまり、その中のアプリケーションが試行する場合でも、他のコンテナーに割り当てることができる他の90% にアクセスすることはできません。また、ホスト自体を使用することもできます。 Linux は、"cgroups" と呼ばれるテクノロジを使用して、このようなガバナンスを実装します。 リソース管理は、同じホスト上に配置されたコンテナーが連携している場合には必要ありません。これにより、アプリケーションコードの需要の変化に適応する標準 OS 動的リソース割り当てが可能になります。


  OS の仮想化から得られるインスタントスタートアップと、名前空間の分離とリソースガバナンスからの信頼性の高い実行の組み合わせにより、コンテナーはアプリケーションの開発とテストに最適です。 開発プロセス中に、開発者はすばやく反復処理を行うことができます。 環境とリソースの使用量はシステム間で一貫しているため、開発者のシステムで動作するコンテナー化されたアプリケーションは、別の実稼働システムでも同じように動作します。 アプリケーションは迅速にスケールアウトすることができ、さらに多くのアプリケーションインスタンスを VM 内に配置してリソース使用率を最大化するよりも、クラウドのシナリオにもメリットがあります。


  仮想マシンとコンテナーを使用するシナリオを比較すると、共有によって得られる効率が明らかになります。 次に示す例では、ホストコンピューターに3つの Vm があります。 Vm 内のアプリケーションを完全に分離するために、それぞれに os ファイル、ライブラリ、アプリケーションコードの独自のコピーと共に、OS のメモリ内の完全なインスタンスがあります。 新しい VM を起動するには、ホストまたは既存の Vm が同じバージョンのインスタンスを既に実行していて、アプリケーションライブラリをメモリに読み込んでいる場合でも、別の OS インスタンスを起動する必要があります。 各アプリケーション VM は、OS ブートのコストと、独自のプライベートコピーのメモリ内フットプリントを支払います。これにより、ホスト上で実行できるアプリケーションインスタンス (Vm) の数も制限されます。


  <a href="https://acom.azurecomcdn.net/80C57D/blogmedia/blogmedia/2015/08/17/App-Instances-on-Host.png"><img style="background-image: none; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; margin-right: auto; border: 0px;" title="ホスト上のアプリインスタンス" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/App-Instances-on-Host_thumb.png" alt="App Instances on Host" width="640" height="324" border="0" /></a>


  次の図は、コンテナーと同じシナリオを示しています。 ここでは、コンテナーは、カーネルとライブラリを含むホストオペレーティングシステムを共有するだけなので、OS を起動したり、ライブラリを読み込んだり、それらのファイルに対してプライベートメモリコストを支払う必要はありません。 使用できる増分領域は、コンテナー内でアプリケーションを実行するために必要なメモリとディスク領域だけです。 アプリケーションの環境は専用の OS のように感じられますが、アプリケーションは専用のホストと同様にデプロイされます。 コンテナー化されたアプリケーションは数秒で起動し、VM の場合よりも多くのアプリケーションインスタンスをマシンに適合させることができます。


  <a href="https://acom.azurecomcdn.net/80C57D/blogmedia/blogmedia/2015/08/17/Containers-on-Host.png"><img style="background-image: none; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; margin-right: auto; border: 0px;" title="ホスト上のコンテナー" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/Containers-on-Host_thumb.png" alt="Containers on Host" width="640" height="260" border="0" /></a>

  <h2>Docker の魅力</h2>

  OSs に関連する名前空間の分離とリソースガバナンスの概念は、長時間にわたり、BSD 途中、Solaris ゾーン、および基本的な UNIX chroot (変更ルート) メカニズムに戻ります。 ただし、共通のツールセット、パッケージモデル、およびデプロイメカニズムを作成することにより、Docker は、Linux ホスト上の任意の場所で実行できるアプリケーションのコンテナー化と配布を大幅に簡略化しました。 この一般的なテクノロジは、任意のホストに対して、同じ管理コマンドを提供することにより管理を合理化するだけでなく、シームレスな DevOps の貴重な機会も作成されます。


  開発者のデスクトップからテスト マシン、実稼働コンピューター群に至るまで、環境全体にまったく同じように展開する Docker イメージを作成できます。 これにより、DockerHub を使用して、大量かつ急増するアプリケーションのエコシステムが Docker コンテナーでパッケージ化されるようになりました。DockerHubは、Dockerが維持するパブリック コンテナ化アプリケーション レジストリで、現在 180,000 以上のアプリケーションをパブリック コミュニティ レジストリーで発行しています。さらに、パッケージ形式が普遍的であることを保証するために、Docker は最近、オープンコンテナーイニシアチブ (OCI) を構成しています。これは、コンテナーのパッケージ化がオープンで構造的な形式であることを保証するためのものであり、Microsoft は設立メンバーの1つです。

  <h2>Windows サーバーとコンテナー</h2>

  すべての開発者にコンテナーを活用するために、過去10月には Windows Server にコンテナーテクノロジを実装する計画を発表しました。 Linux docker コンテナーを使用する開発者が Windows Server とまったく同じエクスペリエンスを実現できるようにするために、docker とのパートナーシップを発表し、Windows サーバーコンテナーをサポートする docker API とツールセットを拡張することも発表しました。 私たちにとって、これは Linux と Windows の両方において、すべてのお客様に恩恵を受けるチャンスでした。 <a href="https://www.youtube.com/watch?v=8vSPpPSd00w#t=1h16m07s">dockercon</a>で最近説明したように、開発者とシステム管理者は、Windows Server と Linux の両方で構成されたコンテナー化されたアプリケーションをデプロイするための統合されたオープンエクスペリエンスを作成することができます。 オープン<a href="https://github.com/docker/docker">Docker GitHub リポジトリ</a>でこれを開発しています。


  Windows Server 2016 では、2つの種類のコンテナーをリリースします。これらはどちらも docker api と docker クライアントを使用して展開できます。 Windows サーバーコンテナーと hyper-v コンテナーです。 linux コンテナーには、ホストカーネルからの linux api が必要です。また Windows サーバーコンテナーには、カーネル Windows ホストの Windows api が必要です。そのため、linux コンテナーは、linux ホスト上の Windows server ホストまたは Windows サーバーコンテナーでは実行できません。 ただし、同じ Docker クライアントですべてのコンテナーを管理できますが、Linux でパッケージ化された Windows コンテナーを実行することはできませんが、Windows コンテナーパッケージは、両方とも Windows カーネルを利用するため Windows サーバーコンテナーと hyper-v コンテナーと連携します。


  Windows サーバーコンテナーと hyper-v コンテナーのどちらを使用するかという質問があります。 カーネルの共有により、高速な起動と効率的なパッキングが可能になりますが、Windows サーバーコンテナーは OS とホストを共有します。 共有データと Api の量は、設計によって、または名前空間の分離またはリソースガバナンスの実装の欠陥によって、アプリケーションがコンテナーをエスケープアウトしたり、ホストや他のコンテナーに対してサービスを拒否したりする方法があることを意味します。 アプリケーションが利用できる欠陥の例として、オペレーティングシステムベンダーの修正プログラムによってローカルに昇格される特権の脆弱性があります。


  このため、Windows サーバーコンテナーは、OS がホストされるアプリケーションを信頼し、すべてのアプリケーションが相互に信頼するようなシナリオに適しています。 つまり、ホスト OS とアプリケーションは同じ信頼境界内にあります。 これは、多くの複数コンテナーアプリケーション、大規模なアプリケーションの共有サービスを構成するアプリケーション、および場合によっては同じ組織のアプリケーションに当てはまります。


  ただし、同じホスト上の異なる信頼境界からアプリケーションを実行することが必要になる場合があります。 たとえば、マルチテナントの PaaS や SaaS を実装している場合に、顧客が独自のコードを提供してサービスの機能を拡張できるようにするとします。 1人の顧客のコードがサービスに干渉したり、他の顧客のデータにアクセスしたりする必要はありませんが、VM よりもアジャイルで、Docker エコシステムを利用するコンテナーが必要です。 Azure Automation や Machine Learning など、Azure にはこのようなサービスの例がいくつか用意されています。 "悪意のあるマルチテナント" で実行される環境を呼び出すことになります。これは、分離を意図的に妨害する顧客がいることを前提としているためです。 このような環境では、Windows サーバーコンテナーを分離することによって十分な保証が得られず、hyper-v コンテナーの開発が導入されます。


  Hyper-v コンテナーは、コンテナー化に少し異なるアプローチを採用しています。 より多くの分離を作成するために、hyper-v コンテナーにはそれぞれ独自の Windows カーネルのコピーがあり、それらに直接メモリが割り当てられます。これは、厳密な分離の重要な要件です。 CPU、メモリ、および IO 分離 (ネットワークや記憶域など) に Hyper-v を使用して、Vm と同じレベルの分離を提供しています。 Vm の場合と同様に、ホストは、ホストリソースの通信と共有を行うために、小さな制約付きインターフェイスをコンテナーに公開するだけです。 この非常に制限された共有とは、hyper-v コンテナーの起動時間と密度が Windows サーバーコンテナーよりも少し効率が低く、信頼されていない "悪意のあるマルチテナント" アプリケーションを同じホストで実行するために必要な分離です。


  Hyper-v コンテナーは Vm と同じではありませんか。 hyper-v コンテナーは、物理マシンではなくコンテナー内にあることを完全に認識しているため、OS の最適化に加えて、Docker のマジックを使用して hyper-v コンテナーを展開し、Windows Server コンテナーで実行されるのとまったく同じパッケージを使用できます。 したがって、分離レベルと効率性/機敏性のトレードオフは、開発時の決定ではなく、ホストの所有者によって作成された、デプロイ時の決定です。

  <h2>オーケストレーション</h2>

  コンテナーを採用したため、お客様は課題を発見しました。 アプリケーションを構成する数十、数百、または数千のコンテナーを展開する場合、展開を追跡して管理するには、管理とオーケストレーションの両方を進める必要があります。 コンテナーオーケストレーションは、複数のオプションとソリューションによってイノベーションの新しい分野になってきました。 コンテナーオーケストレーターは、サーバー (vm またはベアメタルサーバー) のプールが割り当てられます。これらのサーバーには、通常 "クラスター" および "スケジュール" の展開と呼ばれます。 また、負荷分散、コンテナー名の解決、ローリングアップデートなどが含まれている場合もありますが、さまざまなサーバー上のコンテナー間のネットワークを構成することもできます。 一部は拡張可能であり、アプリケーションフレームワークでこれらの追加機能を利用できます。


  オーケストレーションソリューションの詳細については、他のすべての投稿が必要になる場合がありますが、Azure でサポートされているいくつかのテクノロジの概要を次に示します。

  <ol>
   <li><a href="https://www.docker.com/docker-compose">Docker Compose</a> と、単純な複数コンテナーアプリケーションの定義が可能になります。 <a href="https://www.docker.com/docker-swarm">Docker 群れ</a> は、1つの docker ホストで使用されるのと同じ API を使用して、複数のホストにわたる docker コンテナーを管理および整理します。 <a href="https://azure.microsoft.com/blog/2015/02/26/sunny-and-swarmy-in-azure">Docker によって構築された完全なオーケストレーションテクノロジを提供するために、群れと構成が連携し</a>ています。</li>
   <li>登場は、Docker を実際には使用していますが、その組み込みの application framework Marathon に Docker のサポートを追加した、オーケストレーションおよび管理<a href="https://mesos.apache.org/">ソリューションです。</a> <a href="https://mesosphere.com/">Mesosphere</a>によって構築されたオープンでコミュニティ主導のソリューションです。 Microsoft では、 <a href="https://mesosphere.com/blog/2015/04/29/mesosphere-dcos-debuts-on-microsoft-azure/">Azure での Azure での Azure での Azure での Azure へ</a>の統合を紹介しています。</li>
   <li><a href="https://kubernetes.io/">Kubernetes</a> は、Google オファリングコンテナーによって構築されたオープンソースソリューションで、複数のホスト間での管理のための "ポッド" に分類されています。 <a href="https://azure.microsoft.com/blog/2014/07/10/azure-collaboration-with-google-and-docker/">これは、Azure でもサポートされて</a>います。</li>
   <li><a href="https://deis.com/">Deis</a> は、Docker と統合されたアプリケーションをデプロイおよび管理するためのオープンソースの PaaS プラットフォームです。 <a href="https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-deis-cluster/">Azure に Deis クラスターをデプロイする簡単な方法が用意されてい</a>ます。</li>
  </ol>

  多くの一般的なオーケストレーションソリューションに対して Azure のサポートを利用しており、時間の経過に伴う関心と使用量の増加に応じて、これらのコミュニティへの参加をさらに強化することを期待しています。

  <h2>マイクロサービス</h2>

  コンテナーの使用量をすぐに lucrative することに重点を置いて、クラウドまたはオンプレミスにデプロイされたサービスの実稼働フローを簡単にテストできるようにするための DevOps を簡素化しました。 しかし、コンテナーが非常に説得力のあるシナリオも増えています。 マイクロサービスは、アプリケーションのすべての部分が、個別にスケーリングおよび更新できるマイクロサービスと呼ばれる完全な自己完結型コンポーネントとしてデプロイされるアプリケーション開発のアプローチです。 たとえば、パブリックインターネットからの要求を受信するアプリケーションのサブシステムは、バックエンドサブシステムがデータベースに対して読み取りと削除を行うために、要求をキューに入れるサブシステムとは別のものである場合があります。 マイクロサービスを使用してアプリケーションを構築すると、各サブシステムがマイクロサービスになります。 開発/テスト環境では、マイクロサービスごとに1つのインスタンスが存在する場合がありますが、実稼働環境で実行すると、顧客の要求レベルが上昇していくにつれて、リソースの需要に応じて、サーバーのクラスター全体で異なる数のインスタンスにスケールアウトできます。 制作チームが別にいる場合、そのチームが独自にそれらを更新することもできます。


  マイクロサービスは、プログラミングの新しいアプローチではなく、コンテナーに明示的に関連付けられていませんが、複雑なマイクロサービスベースのアプリケーションに適用すると、Docker コンテナーの利点が拡大されます。 機敏性とは、マイクロサービスが負荷の増加に合わせて迅速にスケールアウトできることを意味します。コンテナーの名前空間とリソースの分離によって、1つのマイクロサービスインスタンスが他のマイクロサービスインスタンスに干渉するのを防ぐことができます。 優れたマイクロサービスアーキテクチャを使用すると、お客様は、コンテナーベースのサービスの管理、デプロイ、オーケストレーション、修正プログラムの適用のニーズを解決できます。これにより、高い機敏性を維持しながら可用性が失われるリスクが軽減されます。


  現在、マイクロサービスを使用してアプリケーションモデルを構築するためのソリューションがいくつかあり、それらの多くを Azure でパートナーとしています。 Docker Compose と Mesosphere Marathon は2つの例です。 ビルドの直前に、独自のマイクロサービスアプリケーションプラットフォームである Service Fabric の開発者プレビューが<a href="https://azure.microsoft.com/blog/2015/04/20/announcing-azure-service-fabric-reducing-complexity-in-a-hyper-scale-world/">発表</a>され、リリースされました。 これには、ロールバック、パーティション分割、配置の制約などを伴うローリングアップデートを含む、マイクロサービスライフサイクル管理機能の豊富なコレクションが含まれています。 特に、ステートレスマイクロサービスに加えて、ステートフルマイクロサービスがサポートされています。これは、マイクロサービスが同じサーバーに共存するデータを管理するという事実で区別されます。 実際、Service Fabric は、クラスター管理に直接構築された状態管理とレプリケーションフレームワークを使用するステートフルマイクロサービスを提供する唯一の PaaS プラットフォームです。 このアプリケーションモデルは、ステートフルレプリケーションでハイパースケールに拡張できるように内部サービス用に開発されており、Cortana、Azure SQL Database、Skype for Business などのサービスが構築されています。 今年の後半では、Service Fabric のパブリックプレビューをリリースしますが、その間<a href="https://azure.microsoft.com/en-us/documentation/articles/service-fabric-overview/">に Service Fabric で</a>詳細を確認できます。


  上の例では、Microsoft のコンテナービジョン、最も一般的なコンテナーのユースケース、およびコンテナーに関する新たな業界の傾向について、役に立つ情報をお役立てください。 いつでも、フィードバックをお寄せください。特に、さらに学習する必要がある分野がある場合は、ぜひお寄せください。
