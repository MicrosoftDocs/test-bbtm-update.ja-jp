### YamlMime:Yaml
ms.openlocfilehash: 1c985135d805bda6e67cb72e8976145bd9b9a7ad
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139893825"
Slug: process-more-files-than-ever-and-use-parquet-with-azure-data-lake-analytics
Title: これまで以上に多くのファイルを処理し、Azure Data Lake Analytics で Parquet を使用する
Summary: Azure Data Lake Analytics (ADLA) は、Azure のサーバーレス PaaS サービスであり、Azure Data Lake Store または Azure Blob Storage に格納されている大量のデータを、比類のないスケールで準備および変換します。 ADLA では、Parquet を含むあらゆる形式のファイルを処理するための、優れた拡張性を備えた新しい機能が提供されるようになりました。
Content: >-
  <p><a href="https://azure.microsoft.com/en-us/services/data-lake-analytics/">Azure Data Lake Analytics</a> (ADLA) は、Azure のサーバーレス PaaS サービスであり、 <a href="https://azure.microsoft.com/en-us/services/data-lake-store/">Azure Data Lake Store</a>または<a href="https://azure.microsoft.com/en-us/services/storage/blobs/">Azure Blob Storage</a>に格納されている大量のデータを、比類のないスケールで準備および変換します。</p>


  <p>ADLA では、Parquet を含むあらゆる形式のファイルを処理するための、優れた拡張性を備えた新しい機能が提供されるようになりました。</p>


  <h2>以前は、数十のファイルを処理するのは困難です。</h2>


  <p>多くのお客様は、大量のファイルを処理することは困難であり、お客様が試みたすべてのビッグデータシステムで作らが困難な場合には困難 &ndash; です。 図1は、common data lake systems におけるファイルの分布を示しています。 ほとんどのファイルは 1 GB 未満ですが、大きくなることがあります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7ec46113-70a0-4f91-af24-99d6fe630156.png"><img alt="1636-1" border="0" height="790" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7fc2cd74-63e8-495a-94a0-da6b68aec79c.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-1" width="1932"></a></p>


  <p style="text-align: center;"><em>図 1: 多数の小さなファイルの問題</em></p>


  <p>ADLA は、当初はスケールアウトに役立つ内部構造を持つ非常に大規模なファイルを操作するように設計されたシステムから開発されていますが、約3000のファイルに対しては数百にしか操作できません。 また、ファイルに1つの extract 頂点を与えることによって小さいファイルを処理するときに、過剰に割り当てられたリソースも使用されます (頂点は、データのパーティション上でスクリプトの特定の部分を実行し、作成と破棄に時間をかかるコンピューティングコンテナーです)。 そのため、他の分析エンジンと同様に、多くの小さなファイルの一般的なケースを処理するのは適切ではありませんでした。</p>


  <h2>1つの U-SQL ジョブで数十万のファイルを処理します。</h2>


  <p>最近のリリースでは、ADLA は、さまざまな形式の大量のファイルを次のレベルに処理する機能を利用できます。<br>

  &nbsp;&nbsp; <a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/43b04d9f-86a6-4568-a961-d89d97393ce8.png"><img alt="1636-2" border="0" height="644" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3594573f-3a13-401b-9120-d0c7767851fb.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-2" width="1612"></a></p>


  <p style="text-align: center;"><em>図 2: 多数の小さなファイルの処理の改善</em></p>


  <p>ADLA によって、スキーマのスケール制限が向上し、いわゆるファイルセットを使用して1つの U-SQL ジョブで<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#input-file-set-scales-orders-of-magnitudes-better-finally-released">数百千のファイルが処理</a>されます。 さらに、最大 1 GB のデータの最大200ファイルを1つの頂点 (プレビュー) にグループ化することで、 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#input-file-set-uses-less-resources-when-operating-on-many-small-files-is-in-public-preview">多数の小さなファイルの処理を改善</a> しました (図2を参照)。 エクストラクターは一度に1つのファイルを処理しますが、頂点の作成はより多くのデータにわたって償却されるようになりました。また、抽出フェーズ中に、システムで使用されるリソース (分析単位) が大幅に少なくなります。</p>


  <p>図3は、ジョブが頂点を作成し、1秒未満でデータを処理して、さらに多くの頂点を使用した場合に約5秒間の作業にかかったことを示しています。 右側の画像では、ファイルセットの処理が改善され、リソース (Au) の消費量が大幅に減少し、割り当てられたリソースをより効果的に使用できるようになりました。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d296d0c7-36ab-47f6-ae0f-b59949f2fab5.png"><img alt="1636-3" border="0" height="386" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cc52e2f4-74f4-486f-9b19-c4ae3eb240f1.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-3" width="1484"></a></p>


  <p style="text-align: center;"><br>

  <em>図 3: 多数の小さなファイルから抽出するときのジョブの頂点使用方法: ファイルのグループ化とファイルのグループ化を行わない</em></p>


  <p>これらのファイルセットの機能強化を使用しているお客様は、ジョブのパフォーマンスが10倍に向上しています。これにより、コストが大幅に削減され、1つのジョブで多くのファイルを処理できるようになります。</p>


  <p>ただし、処理するファイルのサイズを最大にすることをお勧めします。これは、大規模なファイルについても、システムのパフォーマンスがさらに向上するためです。</p>


  <h2>さらに、現在、ADLA では Parquet ファイルがネイティブにサポートされています。</h2>


  <p>U-SQL では、組み込みのネイティブエクストラクターを使用して、ファイルにデータを書き戻すことができます。また、ユーザーが独自のエクストラクターを追加する機能も提供されます。 この最新リリースでは ADLA、<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#built-in-parquet-extractor-and-outputter-is-in-public-preview">一般的な Parquet ファイル形式のネイティブエクストラクターとアウトプッター</a>のパブリックプレビューと &ldquo; ORC のプライベート &rdquo; プレビューが追加され、これらの一般的なデータ形式を大規模に簡単に使用して生成することができます。 これにより、以前に CSV 形式を使用するのではなく、HDInsight &rsquo; s HIVE LLAP や Azure DataBricks などのオープンソースのビッグデータ分析ソリューションとデータを交換するための効率的な方法が提供されます。</p>


  <p><a href="https://blogs.msdn.microsoft.com/azuredatalake">Azure Data Lake のブログ</a>を参照して、3 TB のファイルを 1万 Parquet ファイルにクックする方法についてのエンドツーエンドの例を確認し、U-SQL の新しいファイルセットのスケーラビリティでそれらのファイルを処理し Azure Databricks &rsquo; Spark でクエリを実行します。</p>


  <h2>でも、 &rsquo; しばらくお待ちください。</h2>


  <p>動的にパーティション分割されたファイルの生成のプレビューなど、多くの新機能が追加されて &nbsp; います (ユーザーの声のトップ ask!)。<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#adl-tools-for-visualstudio-provides-an-improved-analytics-unit-modeler-to-help-improve-a-jobs-performance-and-cost">ジョブのコストとパフォーマンスのトレードオフを最適化する新しい AU モデル</a>、 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#built-in-textcsvtsv-extractors-and-outputters-support-ansiwindows-8-bit-codepage-encodings">Windows コードページを使用するファイルから抽出</a>する機能、を<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-job-information-system-variable-jobinfo">介し @JobInfo てスクリプトにジョブ情報を</a>追加する機能 ラムダと<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-temporary-script-bound-meta-data-objects-with-declare-statements">スクリプトスコープの U-SQL オブジェクト</a>を使用した、自己完結型<a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-c-func-typed-variables-in-declare-statements-named-lambdas">の</a>スクリプト開発。 新たに導入されたすべての機能については、 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md">spring のリリースノート</a> を参照してください。</p>
