### YamlMime:Yaml
ms.openlocfilehash: bd4ce07a87a3f7bfdbca3a607a53bfbf4b1eed1c
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139896782"
Slug: getting-ai-ml-and-devops-working-better-together
Title: AI/ML の取得と DevOps の連携の向上
Summary: '人工知能 (AI) および機械学習 (ML) テクノロジは、デジタルアシスタント、顔認識、フォトキャプション、銀行サービス、および製品に関する推奨事項を通じて、今すぐに発見されているソフトウェアアプリケーションの機能を拡張します。 AI または ML とアプリケーションの統合について難しい部分は、テクノロジ、数値演算、または科学アルゴリズムではありません。 '
Content: >-
  <p>人工知能 (AI) および機械学習 (ML) テクノロジは、デジタルアシスタント、顔認識、フォトキャプション、銀行サービス、および製品に関する推奨事項を通じて、今すぐに発見されているソフトウェアアプリケーションの機能を拡張します。 AI または ML とアプリケーションの統合について難しい部分は、テクノロジ、数値演算、または科学アルゴリズムではありません。 この課題は、モデルを運用環境にデプロイし、運用とサポートを維持することです。 ソフトウェア開発チームは、ビジネスアプリケーションとクラウドサービスを提供する方法を理解しています。 AI/ML チームは、ビジネスを変革するモデルの開発方法を理解しています。 しかし、この2つを一緒に使用して、AI/ML &mdash; に固有のアプリケーションパイプラインを実装し、それを自動化し、適切な配置方法 &mdash; に合わせて処理を行うには、プロセスに何らかの作業が必要になります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e5d7405f-6a42-4f6f-b874-0bfd1cb7f12c.png"><img alt="image" border="0" height="336" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2c0b9f41-16cf-4862-a907-e3f5dcc86d57.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="絵" width="522"></a></p>


  <h2>開発アプローチの調整が必要</h2>


  <p>DevOps は、クラウドサービスの事実上の開発標準になりました。 プロセスや自動化に重点を置き、チーム間で連携する新しい方法を促進する文化を促進します。 DevOps は、アプリケーション中心のパラダイムであり、アプリケーションをサポートするために必要なインフラストラクチャはどのようなものですか。 自動化に使用できるツール QA/production のリリースプロセスは何ですか?&nbsp;</p>


  <p>AI/ML プロジェクトには、<a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">より明瞭な DM</a>や<a href="https://azure.microsoft.com/en-gb/documentation/learning-paths/data-science-process/" target="_blank">Microsoft Team Data サイエンス Process</a> (tdsp) などの独自の開発方法論があります。 DevOps と同様に、これらの方法は実際のプロジェクトから学んだ原則とプラクティスによって接地されています。 AI/ML チームは、データサイエンスプロジェクトに固有のアプローチを使用します。この方法では、データの特徴、モデル、および分析の質問を調整するために、頻繁に小規模なイテレーションがあります。 これは、AI/ML モデルの開発にビジネス上の問題を合わせること &rsquo; を目的としたプロセスです。 リリースプロセスは、簡単な DM や TDSP には焦点を当てません。運用チームとのやり取りはほとんどありません。 DevOps チーム (今日) は、データサイエンスプロジェクトのツール、言語、および成果物にまだ慣れていません。&nbsp;</p>


  <p>DevOps と ai/ML 開発は、ai アプリケーションを運用環境に配置するという一般的な目標を持つ2つの独立した手法です。 今日では、2つのアプローチ間のギャップを埋める労力が必要です。 ai/ML プロジェクトには、運用とデプロイのプラクティスの一部を組み込む必要があります。 DevOps 有効にするには、ai/ML モデルのデプロイとリリースプロセスを自動化するために、DevOps プロジェクトが ai/ML 開発プロセスに対応する必要があります。</p>


  <h2>AI/ML チーム、プロセス、ツールの統合</h2>


  <p><a href="https://download.microsoft.com/download/0/1/5/0150425C-14C7-41F4-97EA-3DE57B678C51/IndSG_FraudDetection.pdf" target="_blank">モバイル銀行の不正行為ソリューション</a>を含むいくつかの Microsoft プロジェクトから学んだ教訓に基づいて、DevOps と AI/ML プロジェクト間のギャップを埋めるためのいくつかの推奨事項に従います。</p>


  <h3>AI/ML の DevOps</h3>


  <p>AI/ML の DevOps は、モデルのリリースプロセスを安定化し、合理化することができます。 多くの場合、 <a href="https://en.wikipedia.org/wiki/CI/CD" target="_blank">継続的インテグレーション/継続的デプロイ (CI/CD)</a>をサポートするためのプラクティスとツールセットとペアになっています。 AI/ML のワークストリームで CI/CD を考慮する方法をいくつか次に示します。</p>


  <ul>
   <li>AI/ML プロセスは、モデルの実験とイテレーションに依存しており、モデルのトレーニングとテストに数時間または数日かかることがあります。 モデルのビルドとテストサイクルのタイムラインと成果物を格納するために、個別のワークフローを分割します。 時間を区別するアプリケーションビルドを AM/ML モデルビルドに適用しないようにします。</li>
   <li>AI/ML チームの場合は、モデルの1回限りの構築ではなく、時間の経過と共に価値を提供すると予測されるモデルについて考えてみてください。 モデルのライフサイクルと進化を計画し、許可するプラクティスとプロセスを採用します。</li>
   <li>DevOps は、ビジネス、開発、リリース、運用に関する専門知識をまとめて、ソリューションを提供するという特性があります。 AI/ML が機能チームで表現され、設計、開発、および運用セッション全体に含まれていることを確認します。</li>
  </ul>


  <h3>AI/ML のパフォーマンスメトリックと運用テレメトリを確立します</h3>


  <p>メトリックとテレメトリを使用して、どのモデルがデプロイおよび更新されるかを通知します。 メトリックは <a href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank">、有効桁数、再呼び出し、または F1 スコア</a>のような標準のパフォーマンス測定値にすることができます。 または、不正行為モデル &rsquo; のパフォーマンスについて不正行為マネージャーに通知するために開発された業界標準の不正行為メトリックなどのシナリオ固有の手段になる場合もあります。 AI/ML メトリックをアプリケーションソリューションに統合するには、次の方法があります。&nbsp;</p>


  <ul>
   <li>モデルの精度のメトリックを定義し、モデルのトレーニング、検証、テスト、およびデプロイによって追跡します。</li>
   <li>ビジネスメトリックを定義して、運用におけるモデルのビジネスへの影響を把握します。 例については、「 <a href="https://gist.github.com/jspoelstra/9577c07d3c9d1087072b87051abd3c59" target="_blank">R notebook</a>」を参照してください。</li>
   <li>データセットのサイズ、ボリューム、更新頻度、ディストリビューション、カテゴリ、データ型などのデータメトリックをキャプチャします。 モデルのパフォーマンスは、さまざまな理由で予期せず変化する可能性があり、データが変更されているかどうかを判断するのには&#39;が適しています。</li>
   <li>モデルに関する運用テレメトリの追跡: どのくらいの頻度で呼び出されますか。 &nbsp; アプリケーションまたはゲートウェイによって、 問題はありますか。 精度と使用状況の傾向について教えてください。 モデルで使用されるコンピューティングまたはメモリの量を確認できます。</li>
   <li>モデルのバージョン、パフォーマンスメトリック、およびデータセットを追跡するモデルパフォーマンスダッシュボードを作成します。</li>
  </ul>


  <p>AI/ML モデルは、定期的に更新する必要があります。 時間の経過と共に、新しいデータやさまざまなデータが利用できる &mdash; ようになったり、顧客や季節や動向の変化 &mdash; に応じて、モデルを再トレーニングして引き続き有効にする必要があります。 メトリックとテレメトリを使用して、更新戦略を調整し、モデルを再トレーニングする必要がある時期を判断します。</p>


  <h3>エンドツーエンドのデータとモデルパイプラインを自動化する</h3>


  <p>ai/ML パイプラインは、必要なツール、プロセス、およびデータ要素を接続して ai/ML モデルを生成し、運用化するため、重要な概念です。 また、DevOps プロセスの複雑さの別のディメンションも導入されています。 DevOps の基本的な柱の1つは自動化ですが、エンドツーエンドのデータとモデルパイプラインの自動化は byzantine の統合の課題です。</p>


  <p>AI/ML パイプラインのワークストリームは、一般に、プロセスの各ステップが非常に詳細で複雑な、専門家のチーム間で分けられています。 要件、ツール、言語に違いがあるため、パイプライン全体で自動化することは実用的ではありません。 データ変換スクリプト、データおよびモデルの品質チェックなど、簡単に自動化できるプロセスの手順を特定します。 次のようにワークストリームを考えてみます。&nbsp;&nbsp;</p>


  <table border="1" cellpadding="1" cellspacing="0">
   <tbody>
    <tr>
     <td valign="top"><em>はなし</em></td>
     <td valign="top"><em>説明</em></td>
     <td valign="top"><em>Automation</em></td>
    </tr>
    <tr>
     <td valign="top"><em>データ分析</em>&nbsp;&nbsp;&nbsp;</td>
     <td valign="top">データの取得と、探索、プロファイリング、クリーンアップ、および変換に焦点を当てることができます。 には、モデリング用のデータの追加とステージングデータも含まれています。</td>
     <td valign="top">データを移動して検証するためのスクリプトとテストを開発します。 また、データ品質、変更、ボリューム、および一貫性に関するレポートを作成するスクリプトも作成します。</td>
    </tr>
    <tr>
     <td valign="top"><em>実験</em>&nbsp;&nbsp;&nbsp;</td>
     <td valign="top">特徴エンジニアリング、モデルの調整、およびモデルの評価が含まれます。</td>
     <td valign="top">スクリプト、テスト、ドキュメントを開発して、手順を再現し、モデルの出力とパフォーマンスをキャプチャします。</td>
    </tr>
    <tr>
     <td valign="top"><em>リリースプロセス</em></td>
     <td valign="top">モデルとデータパイプラインを運用環境にデプロイするプロセスについて説明します。</td>
     <td valign="top">AI/ML パイプラインをリリースプロセスに統合する</td>
    </tr>
    <tr>
     <td valign="top"><em>運用化</em></td>
     <td valign="top">操作とパフォーマンスのメトリックのキャプチャが含まれます。</td>
     <td valign="top">AI/ML パイプラインの運用インストルメンテーションを作成します。 以降のモデル再トレーニングサイクルでは、モデルの入力と出力をキャプチャして保存します。</td>
    </tr>
    <tr>
     <td valign="top">
     <p><em>モデルの再トレーニングと洗練化</em></p>
     </td>
     <td valign="top">モデルの再トレーニングのリズムを決定します。</td>
     <td valign="top">AI/ML パイプラインにアラートと通知をインストルメント化して、再トレーニングを開始します。</td>
    </tr>
    <tr>
     <td valign="top"><em>視覚化</em></td>
     <td valign="top">AI/ML ダッシュボードを開発して、モデルとデータに関連する情報とメトリックを一元化します。 精度、運用特性、事業影響、履歴、およびバージョンが含まれます。</td>
     <td valign="top">N/A</td>
    </tr>
   </tbody>
  </table>


  <p>ai/ML パイプラインの自動化されたエンドツーエンドのプロセスでは、ai/ML プロジェクト間で開発を高速化し、再現性、一貫性、効率を向上させることができます。</p>


  <h3>バージョン管理&nbsp;</h3>


  <p>バージョン管理とは、アプリケーション &rsquo; の成果物と成果物に対する変更を追跡することです。</p>


  <p>ソフトウェア開発プロジェクトには、コード、スクリプト、ドキュメント、ファイルが含まれています。 同様の方法は AI/ML プロジェクト &mdash; にとっても重要なことです。通常 &mdash; は複数のコンポーネントがあり、それぞれに個別のリリースサイクルとバージョン管理サイクルがあります。 AI/ML プロジェクトでは、成果物には次のものが含まれます。</p>


  <ul>
   <li>データ: トレーニングデータ、推定データ、データメトリック、グラフ、プロット、データ構造、スキーマ</li>
   <li>モデル: トレーニング済みのモデル、スコアリングモデル、A/B テストモデル</li>
   <li>モデルの出力: 予測、モデルのメトリック、ビジネスメトリック&nbsp;</li>
   <li>アルゴリズム、コード、ノートブック</li>
  </ul>


  <p>バージョン管理は次の機能を提供するのに役立ちます。</p>


  <ul>
   <li>複数のコラボレーターからのモデル変更の追跡可能性</li>
   <li>プロジェクト成果物の監査証跡</li>
   <li>どのアプリケーションから呼び出されるかに関する情報</li>
  </ul>


  <p>AI/ML チームのバージョン管理の重要性の実際の例としては、モデルのパフォーマンスが予期せず変更され、変更にモデル自体に対する処理が何もない場合に発生します。 入力、依存関係、モデル、およびデータセットの各バージョンを簡単にトレースできるため、数日または数週間の労力を節約できます。</p>


  <p>少なくとも、一貫性のある名前付け規則を決定し、データファイル、フォルダー、および AI/ML モデルに使用します。 モデリングプロセスにはいくつかの異なるチームが関係しており、名前付け規則がないと、使用するデータセットまたはモデルバージョンについて混乱が生じます。</p>


  <h3>コンテナーのアーキテクチャを検討する</h3>


  <p>コンテナーアーキテクチャでは、モデルの開発、テスト、およびデプロイを効率化し、簡素化することができます。 また、パッケージベースのインターフェイスとして、コンテナーを使用すると、ソフトウェアアプリケーションが簡単に接続できるようになります。 コンテナーは、モデルと基になるインフラストラクチャの間に抽象化レイヤーを作成します。 これにより、AI/ML チームは、プラットフォームについて心配することなく、モデル開発に専念できます。 コンテナーでは、次のことを簡単に実現できます。</p>


  <ul>
   <li>A/B テスト&nbsp;</li>
   <li>複数の環境へのデプロイ (IoT edge、ローカルデスクトップ、Azure インフラストラクチャ)</li>
   <li>一貫した環境構成とセットアップにより、より高速なモデル開発、テスト、およびリリースサイクルを実現</li>
   <li>モデルの移植性とスケーラビリティ</li>
  </ul>


  <h3>推奨される次の手順</h3>


  <p>DevOps の導入は、ソフトウェア開発チームと運用チームを統合して、展開とリリースプロセスを簡素化および改善するうえで非常に効果的でした。 AI と ML アプリケーションの重要なコンポーネントになるにつれて、組織 &rsquo; の DevOps モデルの一部であることを保証するために、より多くのプレッシャーが発生します。 提示された提案は、2つの方法論の統合に向けて移行するためのいくつかの手順の例です。 使用を開始するには、以下のリンクをご利用ください。ご意見やご感想をお寄せください。</p>


  <ul>
   <li>データパイプラインで可能な統合ポイントとしてオートメーションを使用する ML/ai ソリューションの使用例については、「<a href="https://download.microsoft.com/download/0/1/5/0150425C-14C7-41F4-97EA-3DE57B678C51/IndSG_FraudDetection.pdf" target="_blank">モバイルバンクの不正行為ソリューションガイド」</a>を参照してください。</li>
   <li><a href="https://blogs.technet.microsoft.com/machinelearning/2017/09/25/using-the-team-data-science-process-tdsp-in-azure-machine-learning/?WT.mc_id=devopsai-acomblog-kbaroni" target="_blank">Azure Machine Learning の「Team Data サイエンス Process (TDSP) の使用」を</a>参照してください。</li>
   <li><a href="https://docs.microsoft.com/azure/machine-learning/team-data-science-process/ci-cd-flask?WT.mc_id=devopsai-acomblog-kbaroni" target="_blank">ai アプリケーションの DevOps チュートリアルを完了します。 Docker と Kubernetes を使用して Azure で継続的インテグレーションパイプラインを作成すると</a>、ai アプリケーション用の継続的インテグレーション (CI)/継続的デリバリー (CD) パイプラインを設定する例を参照できます。</li>
   <li><a href="https://blogs.msdn.microsoft.com/dotnet/2017/08/02/microservices-and-docker-containers-architecture-patterns-and-development-guidance/?WT.mc_id=devopsai-acomblog-kbaroni" target="_blank">マイクロサービスと Docker コンテナーを読み取ります。アーキテクチャ、パターン、開発ガイダンス</a>を参照してください。 このガイドでは、Docker コンテナーとマイクロサービスの概要について説明します。</li>
  </ul>
