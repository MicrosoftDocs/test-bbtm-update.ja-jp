### YamlMime:Yaml
ms.openlocfilehash: 4a7a8cb58bfedd4fed2462adc3ec71dd2da99dbe
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139892059"
Slug: structured-streaming-with-databricks-into-power-bi-cosmos-db
Title: Azure Databricks を使用した構造化ストリーミング Power BI & Cosmos DB
Summary: このブログでは、構造化ストリーミングの概念について説明します。また、ほぼリアルタイムでデータのストリーミングを可能にする Azure Databricks 使用して、データインジェストパスを直接作成する方法についても説明します。
Content: "<p>このブログ &rsquo; では、構造化ストリーミングの概念と、 <a href=\"https://docs.microsoft.com/en-gb/azure/azure-databricks/what-is-azure-databricks\" target=\"_blank\">Azure Databricks</a> を使用したデータインジェストパスの作成方法について説明します。これにより、ほぼリアルタイムでデータをストリーミングできるようになります。 ここ &rsquo; では、Databricks <a href=\"https://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/overview\" target=\"_blank\">Text Analytics API</a> utilising 内から直接呼び出すことができるいくつかの分析機能について説明し、さらに分析とレポートを行うために Databricks を直接<a href=\"https://powerbi.microsoft.com/en-us/\" target=\"_blank\">Power BI</a>に接続する方法についても説明します。 最後の手順として、Databricks からのストリーミングデータを永続ストレージとして<a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/introduction\" target=\"_blank\">Cosmos DB</a>に送信する方法について説明します。</p>\n\n<p>構造化ストリーミングはストリーム処理エンジンであり、ストリーミングデータ (Twitter フィードなど) に高速計算を適用できます。 この意味では、静的なデータセットに対してバッチ計算を実行する方法と非常によく似ています。 計算は、Spark SQL エンジンによって段階的に実行されます。これにより、のストリーミングデータフローと同様に、継続的なプロセスとして結果が更新されます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0536037d-88b5-4f9f-bf55-014c8e8fa41c.png\"><img alt=\"clip_image002\" border=\"0\" height=\"440\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/145f5167-d149-47f5-ba94-19dc930f3738.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"clip_image002\" width=\"752\"></a></p>\n\n<p>上のアーキテクチャでは、Databricks を使用して Twitter からデータをストリーム配信するためのインジェストパスとして直接使用する方法について説明しています ( <a href=\"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-what-is-event-hubs\" target=\"_blank\">Event Hubs</a>を介して、バッファーとして機能します)。データにインテリジェンスを適用し、最後にデータを Power BI と Cosmos DB に直接送信するために、 <a href=\"https://docs.microsoft.com/en-gb/azure/cognitive-services/welcome\" target=\"_blank\">Cognitive Services</a> Text Analytics API を呼び出します。</p>\n\n<h2>構造化ストリーミングの概念</h2>\n\n<p>データストリームから受信するすべてのデータは、バインドされていない入力テーブルとして扱われます。 データストリーム内の新しいデータごとに、バインドされていない入力テーブルに新しい行が追加されます。 入力 &rsquo; の全体が格納されるわけではありませんが、最終的な結果は、入力全体を保持し、バッチジョブを実行することと同じです。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a8a1ff2d-fddc-4194-9389-b4f249d57a34.png\"><img alt=\"image\" border=\"0\" height=\"324\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/662c8096-5b42-4212-8a40-d4d071b322f0.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"602\"></a></p>\n\n<p>入力テーブルを使用すると、静的なテーブルの場合と同様に、それ自体に対してクエリを定義できます。これにより、出力シンクに書き込まれる最終的な結果テーブルが計算されます。 このバッチに似たクエリは、 <strong>増分実行</strong>と呼ばれるプロセスを介して、Spark によってストリーミング実行プランに自動的に変換されます。</p>\n\n<p>増分実行は、レコードが到着するたびに結果を更新するために必要な状態を Spark がネイティブに計算する場所です。 組み込みのトリガーを利用して、結果をいつ更新するかを指定できます。 トリガーが起動されるたびに、Spark は入力テーブル内の新しいデータを検索し、増分ベースで結果を更新します。</p>\n\n<p>入力テーブルに対してクエリを実行すると、結果テーブルが生成されます。 すべてのトリガー間隔 (例: 3 秒おき) に対して、新しい行が入力テーブルに追加されます。このとき、増分実行のプロセスによって、結果テーブルが更新されます。 結果テーブルが更新されるたびに、変更された結果が出力として書き込まれます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ded7c1d8-31df-4422-babd-065520b5372a.png\"><img alt=\"image\" border=\"0\" height=\"281\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e2a471ab-7233-4fc5-89d2-0ba449ec8c8d.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"461\"></a></p>\n\n<p>出力では、外部ストレージに書き込まれる内容 (Databricks ファイルシステムに直接配置するかどうか、または CosmosDB の例) を定義します。</p>\n\n<p>これを Azure Databricks 内部で実装するために、受信ストリーム関数を呼び出して、指定された入力 (この例の Twitter データ) に基づいて StreamingDataFrame を開始します。 次のコードスニペットに示すように、ストリームは処理され、内部 Databricks file ストレージに parquet 形式として書き込まれます。</p>\n\n<pre>\nval streamingDataFrame = incomingStream.selectExpr(&quot;cast (body as string) AS Content&quot;)\n.withColumn(&quot;body&quot;, toSentiment(%code%nbsp;&quot;Content&quot;))\n \nimport org.apache.spark.sql.streaming.Trigger.ProcessingTime\nval result = streamingDataFrame\n.writeStream.format(&quot;parquet&quot;)\n.option(&quot;path&quot;, &quot;/mnt/Data&quot;)\n.option(&quot;checkpointLocation&quot;, &quot;/mnt/sample/check&quot;)\n.start()</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/419123be-0b0a-4cec-af9d-210c9e04ef1f.png\"><img alt=\"image\" border=\"0\" height=\"224\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/768d3765-f86b-4b65-bca8-621fff57ab16.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"602\"></a></p>\n\n<h2>Databricks 内でのファイルシステムのマウント (CosmosDB)</h2>\n\n<p><a href=\"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction\" target=\"_blank\">Blob Storage</a>、 <a href=\"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview\" target=\"_blank\">Data Lake Store</a> 、 <a href=\"https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is\" target=\"_blank\">SQL Data Warehouse</a>など、いくつかの異なるファイルシステムを Databricks 内に直接マウントできます。 このブログでは、Databricks と Cosmos DB 間の接続機能について説明 &rsquo; します。</p>\n\n<p>Apache Spark と Azure Cosmos DB 間の高速接続により、データを迅速に保存して Azure Cosmos DB を使用して取得できる、迅速なデータサイエンスの問題を解決できるようになります。 Spark to Cosmos DB コネクタを使用すると、 &rsquo; IoT のシナリオを解決し、分析の実行時に列を更新し、プッシュダウン述語のフィルター処理を行い、一貫性、可用性、低待機時間、スループットの保証された sla を使用して、geo レプリケートされた管理対象ドキュメントストアに対する高度な分析を実行できます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/77217cc4-fea9-4988-aaef-24fecced3112.png\"><img alt=\"image\" border=\"0\" height=\"285\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/81dffcb2-bf54-410f-9250-fce4b6fbd89b.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"602\"></a></p>\n\n<ul>\n <li>Databricks 内から、Spark マスターノードから Cosmos DB ゲートウェイノードへの接続が確立され、Cosmos からパーティション情報を取得します。</li>\n <li>パーティション情報は、Spark マスターノードに変換され、worker ノード間で分散されます。</li>\n <li>その情報は Spark に戻され、ワーカーノード間で分散されます。</li>\n <li>これにより、クエリが行われたときに、Spark worker ノードが Cosmos DB パーティションに直接対話できるようになります。 作業中のノードでは、必要なデータを抽出し、そのデータを Spark worker ノード内の Spark パーティションに戻すことができます。</li>\n</ul>\n\n<p>spark ワーカーノードと Cosmos DB データノードの間でデータの移動が行われるため、spark と Cosmos DB 間の通信が大幅に高速化されます。</p>\n\n<p>Azure Cosmos DB spark コネクタ (現在プレビュー段階) を使用すると、次のコードスニペットに示すように、Databricks 内から Cosmos DB ストレージアカウントに直接接続して、Cosmos DB を Spark ジョブの入力ソースまたは出力シンクとして機能させることができます。</p>\n\n<pre>\nimport com.microsoft.azure.cosmosdb.spark.CosmosDBSpark\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\nval writeConfig = Config(Map(&quot;Endpoint, MasterKey<ins datetime=\"2018-06-21T19:46\">, Database, PreferredRegions, Collection, WritingBatchSize</ins>&quot;))\n\nimport org.apache.spark.sql.SaveMode\nsentimentdata.write.mode(SaveMode.Overwrite).cosmosDB(writeConfig)</pre>\n\n<h2>Databricks を PowerBI に接続しています</h2>\n\n<p>Microsoft Power BI は、セルフサービスのビジネスインテリジェンス機能を備えた対話型の視覚化機能を提供するビジネス分析サービスです。これにより、エンドユーザーは、情報技術スタッフやデータベース管理者に依存することなく、レポートやダッシュボードを自分で作成できます。</p>\n\n<p>Azure Databricks は、Power BI を使用した直接データソースとして使用できます。これにより、Azure Databricks のパフォーマンスとテクノロジの利点を、すべてのビジネスユーザーにとってデータ科学者やデータエンジニアを超えるものにすることができます。</p>\n\n<p>Power BI Desktop は、組み込みの Spark コネクタ (現在プレビュー段階) を使用して Azure Databricks クラスターに直接接続できます。 コネクタを使用すると、DirectQuery を使用して処理を Databricks にオフロードすることができます。これは、大量のデータ &rsquo; が Power BI に読み込まれない場合や、このブログ記事全体で説明したほぼリアルタイムの分析を実行する場合に適しています。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1225955d-d8a4-45dc-9e95-021ec868980a.png\"><img alt=\"image\" border=\"0\" height=\"267\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/895289b5-384d-4583-bc1b-f037c4bd330d.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"602\"></a></p>\n\n<p>このコネクタは、DirectQuery を使用して JDBC/ODBC 接続をはし、Databricks を介して入力するストリーミングデータに対して、マウントされたファイルストアにライブ接続を使用できるようにします。 Databricks を使用して、ストリーミングされたデータをファイルストアに書き込むスケジュール (5 秒ごとなど) を設定したり、データのほぼリアルタイムのストリームを取得するために定期的にこの Power BI をプルすることができます。</p>\n\n<p>Power BI 内では、さまざまな分析と visualisations を、ストリーミングされたデータセットに適用して有効にすることができます。</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/292c6de5-5b3d-4248-9836-63219fcdceec.png\"><img alt=\"image\" border=\"0\" height=\"301\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ff2e2567-64b4-4a65-b17e-3faf0ca458ca.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"絵\" width=\"602\"></a></p>\n\n<p>このアーキテクチャを構築するにはどうすればよいですか。 Databricks のその他の例については、公式の <a href=\"https://github.com/giulianorapoz/DatabricksStreamingPowerBI\" target=\"_blank\">Azure のドキュメント</a>を参照してください。</p>\n\n<ul>\n <li><a href=\"https://docs.microsoft.com/en-us/azure/azure-databricks/databricks-extract-load-sql-data-warehouse\" target=\"_blank\">Databricks で ETL 操作を実行</a>します。</li>\n <li><a href=\"https://docs.databricks.com/spark/latest/structured-streaming/index.html\" target=\"_blank\">Databricks での構造化ストリーミング</a>。</li>\n <li><a href=\"https://docs.azuredatabricks.net/spark/latest/structured-streaming/kafka.html\" target=\"_blank\">HDInsight Kafka からデータをストリーム配信</a>します。</li>\n</ul>\n\n<p><a href=\"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-power-bi-dashboard\" target=\"_blank\">Power BI に</a>ついては Stream Analytics を参照してください。</p>"
