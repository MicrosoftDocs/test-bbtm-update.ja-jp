### YamlMime:Yaml
ms.openlocfilehash: 3da9f5bab9a89907db2af90190616ed09daccf2b
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139891663"
Slug: controlling-costs-in-azure-data-explorer-using-down-sampling-and-aggregation
Title: ダウンサンプリングと集計をAzure Data Explorerを使用してコストを管理する
Summary: Azure Data Explorer (ADX) は、クラウド サービスと IoT デバイスからの高速テレメトリ データを継続的に取り込み、保存する優れたサービスです。
Content: >-
  <p>Azure Data Explorer (ADX) は、クラウド サービスと IoT デバイスからの高速テレメトリ データを継続的に取り込み、保存する優れたサービスです。 何十億ものレコードに対してクエリを実行するために、その最初の速度のパフォーマンスを活用して、サービスの正常性、生産プロセス、使用状況の傾向の監視など、さまざまな分析情報についてテレメトリ データをさらに分析できます。 データの速度と保持ポリシーに応じて、データ サイズをペタバイト単位のデータに迅速にスケーリングし、データ ストレージに関連するコストを増やします。 大規模なデータセットを長時間保存する一般的なソリューションは、異なる解像度でデータを格納することです。 最新のデータは最大解像度で格納されます。つまり、すべてのイベントは未加工の形式で格納されます。 古いデータは縮小された解像度で格納され、フィルター処理または集計されます。 このソリューションは、ホット ストレージのコストを制御するために時系列データベースによく使用されます。</p>


  <p>このブログでは、イベント&rsquo;のパブリック GitHubをプレイグラウンドとして使用します。 詳細については、ブログ「GitHub を使用したイベントの探索」を参照して、GitHub イベントを独自の A <a href="https://medium.com/microsoftazure/exploring-github-events-with-azure-data-explorer-69f28eb705b9" target="_blank">GitHub</a> DX &ldquo; クラスターにストリーミングする方法Azure Data Explorer。&rdquo;ADX&rsquo;&ldquo; ユーザーがストアド関数、.set-or-append&rdquo; コマンド、および Azure Kusto コネクタを使用する方法Microsoft Flow説明します。 これは、ストレージ コストを制御するために、フィルター処理、ダウンサンプリング、および集計されたデータを使用してテーブルを作成および更新するのに役立ちます。 実行した手順を次に示します。</p>


  <h2>ダウンサンプリングと集計のための関数を作成する</h2>


  <p>ADX demo11 クラスターには、 という名前のデータベースGitHub。 2016 年から <a href="https://www.gharchive.org/" target="_blank">、GHArchive</a> のすべてのイベントが <strong>GitHubEvent </strong>テーブルに取り込み、合計で 10 億件を超えるレコードが追加されました。 各GitHubは、リポジトリ、作成者、コメントなどについてイベント関連の情報を含む 1 つのレコードで表されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5d8bdba1-908b-4472-94d2-09fbbda9691d.png"><img alt="Screenshot of Azure Data Explorer demo11 and GitHub database" border="0" height="700" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/49ea1297-5fe8-4648-bf2d-d913f8ea507e.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="demo11 Azure Data ExplorerデータベースのGitHubスクリーンショット" width="1851"></a></p>


  <p>最初に、特定の週のすべてのリポジトリ内のイベントの総数をカウントする、ストアド関数 <strong>AggregateReposWeeklyActivity</strong> を作成しました。</p>


  <pre>

  .create-or-alter function with (folder = &quot;TimeSeries&quot;, docstring = &quot;Aggregate Weekly Repos Activity&rdquo;)

  AggregateReposWeeklyActivity(StartTime:datetime)

  {
       let PeriodStart = startofweek(StartTime);
       let Period = 7d;
       GithubEvent
       | where CreatedAt between(PeriodStart .. Period)
       | summarize EventCount=count() by RepoName = tostring(Repo.name), StartDate=startofweek(CreatedAt)
       | extend EndDate=endofweek(StartDate)
       | project StartDate, EndDate, RepoName, EventCount
  }</pre>


  <p>この関数を使用して、毎週のリポジトリ アクティビティのダウンサンプリングされたデータセットを生成できます。 たとえば、2017 年の最初の週に <strong>AggregateReposWeeklyActivity</strong> 関数を使用すると、867,115 レコードのデータセットが生成されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2aff8f34-ce61-4f8c-b83f-a00ec4807aac.png"><img alt="Screenshot of AggregateReposWeeklyActivity function yielding dataset results" border="0" height="424" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0ef99b73-b8f0-431e-bc3e-cfcaf4133ccc.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="データセットの結果を生成する AggregateReposWeeklyActivity 関数のスクリーンショット" width="1850"></a></p>


  <h2>Kusto クエリを使用して、古いデータを含むテーブルを作成する</h2>


  <p>元のデータセットは 2016 年に始まるので、 <strong>ReposWeeklyActivity</strong> という名前のテーブルを作成し、 <strong>それを GitHubEvent</strong> テーブルから毎週集計されたデータでバックフィルするプログラムを作成しました。 クエリは、. &ldquo;set-or-append コマンドを使用して、毎週集計されたデータセットの並列インジェストで実行&rdquo; されます。 最初のインジェスト操作では、集計データを保持するテーブルも作成されます。</p>


  <pre>

  .show table GithubEvent details

  | project TableName, SizeOnDiskGB=TotalExtentSize/pow(1024,3), TotalRowCount


  .show table ReposWeeklyActivity details

  | project TableName, SizeOnDiskGB=TotalExtentSize/pow(1024,3), TotalRowCount


  Code sample:

  using Kusto.Data.Common;

  using Kusto.Data.Net.Client;

  using System;

  using System.Collections.Generic;

  using System.Linq;

  using System.Text;

  using System.Threading.Tasks;


  namespace GitHubProcessing

  {
       class Program
       {
           static void Main(string[] args)
           {
               var clusterUrl = &quot;https://demo11.westus.kusto.windows.net:443;Initial Catalog=GitHub;Fed=True&quot;;
               using (var queryProvider = KustoClientFactory.CreateCslAdminProvider(clusterUrl))
               {
                   Parallel.For(
                       0,
                       137,
                       new ParallelOptions() { MaxDegreeOfParallelism = 8 },
                       (i) =&gt;
                       {
                           var startDate = new DateTime(2016, 01, 03, 0, 0, 0, 0, DateTimeKind.Utc) + TimeSpan.FromDays(7 * i);
                           var startDateAsCsl = CslDateTimeLiteral.AsCslString(startDate);
                           var command = $@&quot;
                           .set-or-append ReposWeeklyActivity &lt;|
                           AggregateReposWeeklyActivity({startDateAsCsl})&quot;;
                           queryProvider.ExecuteControlCommand(command);

                          Console.WriteLine($&quot;Finished: start={startDate.ToUniversalTime()}&quot;);
                       });
               }
           }
       }
  }</pre>


  <p>バックフィルが完了すると、 <strong>ReposWeeklyActivity </strong>テーブルには 1 億 5,300 万レコードが含まれます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/15fa586f-cdbf-484e-b47f-8621636c5c5d.png"><img alt="Screenshot of the ReposWeeklyActivity table yielding 153 million records" border="0" height="608" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0a2d5630-bebf-4077-a6e7-292d4c05375a.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="1 億 5,300 万レコードが生成された ReposWeeklyActivity テーブルのスクリーンショット" width="1857"></a></p>


  <h2>azure Kusto コネクタと Microsoft Flowを使用して週単位の集計ジョブを構成する</h2>


  <p><strong>ReposWeeklyActivity</strong> テーブルが作成され、古いデータが入力された後は、毎週新しいデータが追加された状態で更新された状態を確認する必要があります。 その目的のために、Azure Kusto コネクタMicrosoft Flowを利用して週単位で集計データを取り込むフローを Microsoft Flow で作成しました。 フローは、次の 2 つの簡単な手順で構築されます。</p>


  <ol>
   <li>週単位のトリガー Microsoft Flow。</li>
   <li>&ldquo;.set-or-append&rdquo; を使用して、過去 1 週間の集計データを取り込みます。</li>
  </ol>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8bf9a895-fbf6-4b57-9636-5669657f805f.png"><img alt="image" border="0" height="389" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4d9f889f-c9fe-4ccf-9873-503127c6bbb6.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="イメージ" width="678"></a></p>


  <p>アプリケーションと一緒に使用するMicrosoft FlowについてはAzure Data Explorer <a href="https://docs.microsoft.com/en-us/azure/kusto/tools/flow" target="_blank">Azure Kusto Flowしてください</a>。</p>


  <h2>保存を開始する</h2>


  <p>ダウンサンプリングのコスト削減の可能性を示す上で、Ive&rsquo;&ldquo; は .show table &lt;name&gt; details&rdquo; コマンドを使用して、元の <strong>GitHubEvent </strong>テーブルとダウンサンプリングされたテーブル <strong>ReposWeeklyActivity</strong> のサイズを比較しました。</p>


  <pre>

  .show table GithubEvent details

  | project TableName, SizeOnDiskGB=TotalExtentSize/pow(1024,3), TotalRowCount


  .show table ReposWeeklyActivity details

  | project TableName, SizeOnDiskGB=TotalExtentSize/pow(1024,3), TotalRowCount</pre>


  <p>次の表にまとめられた結果は、同じ期間にダウンサンプリングされたデータがレコード数の約 10 倍小さく、ストレージ サイズが約 180 倍小さいことを示しています。</p>


  <table border="1" cellpadding="0" cellspacing="0">
   <tbody>
    <tr>
     <td valign="top" width="284">
     <p>&nbsp;</p>
     </td>
     <td valign="top" width="170">
     <p><b>元のデータ</b></p>
     </td>
     <td valign="top" width="223">
     <p><b>ダウンサンプリング/集計データ </b></p>
     </td>
    </tr>
    <tr>
     <td valign="top" width="284">
     <p><b>期間</b></p>
     </td>
     <td valign="top" width="170">
     <p>2016-01-01 &hellip; 2018-09-26</p>
     </td>
     <td valign="top" width="223">
     <p>2016-01-01 &hellip; 2018-09-26</p>
     </td>
    </tr>
    <tr>
     <td valign="top" width="284">
     <p><b>レコード数</b></p>
     </td>
     <td valign="top" width="170">
     <p>1,048,961,967</p>
     </td>
     <td valign="top" width="223">
     <p>153,234,107</p>
     </td>
    </tr>
    <tr>
     <td valign="top" width="284">
     <p><b>ディスク上の合計サイズ (インデックス付きおよび圧縮済み)</b></p>
     </td>
     <td valign="top" width="170">
     <p>725.2 GB</p>
     </td>
     <td valign="top" width="223">
     <p>4.38 GB</p>
     </td>
    </tr>
   </tbody>
  </table>


  <p>コスト削減の可能性を実際の節約に変換するには、さまざまな方法で実行できます。 さまざまな方法の組み合わせは、通常、コストを制御する上で最も効率的です。</p>


  <ul>
   <li><strong>クラスター のサイズとホット ストレージのコスト</strong>を制御する: 元のデータ テーブルとダウンサンプリングされたテーブルに対して異なるキャッシュ ポリシーを設定します。 たとえば、元のデータのキャッシュは 30 日、ダウンサンプリング テーブルの場合は 2 年間です。 この構成により、生データを対話的に探索するために ADX の一流のパフォーマンスを利用し、何年ものアクティビティの傾向を分析できます。 クラスターサイズとホット ストレージのコストを制御しながらすべて。</li>
   <li><strong>コールド ストレージ のコストを制御</strong>する: 元のデータ テーブルとダウンサンプリングされたテーブルに対して異なる保持ポリシーを設定します。 たとえば、元のデータのリテンション期間は 30 日、ダウンサンプリング テーブルの場合は 2 年間です。 この構成により、コールド ストレージ のコストを制御しながら、生データを調査し、長年のアクティビティの傾向を分析できます。 別の注意点として、生データにはユーザーを特定できる情報が含まれている可能性があります。また、集計されたデータは通常匿名である可能性があります。この構成はプライバシー要件を満たす場合にも一般的です。</li>
   <li><strong>分析には、ダウンサンプリングされた</strong>テーブルを使用します。時系列傾向分析のためにダウンサンプリングされたテーブルに対してクエリを実行すると、CPU とメモリのリソースの消費が少なになります。 次の例では、すべてのリポジトリの週単位のアクティビティの合計を計算する一般的なクエリのリソース消費量を比較します。 クエリ統計では、ダウンサンプリングされたデータセットで毎週のアクティビティ傾向を分析する方が、CPU 消費量の約 17 倍、メモリ消費量の約 8 倍の効率を示しています。</li>
  </ul>


  <p>元の <strong>GitHubEvent</strong> テーブルでこのクエリを実行すると、合計 CPU 時間の約 56 秒と 176 MB のメモリが消費されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/08a80c51-bd6b-4bf3-b689-a9184c73f362.png"><img alt="Screenshot of a command comparing GitHubEvent and ReposWeeklyActivity table sizes" border="0" height="612" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bd1aff94-f23c-4208-a48d-0f80b9ebcc40.png" style="border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="GitHubEvent と ReposWeeklyActivity テーブルのサイズを比較するコマンドのスクリーンショット" width="1850"></a></p>


  <p>集計された <strong>ReposWeeklyActivity </strong>テーブルに対する同じ計算では、合計 CPU 時間の約 3 秒と 16 MB のメモリしか消費されません。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3df5cf97-b5da-45ac-bb9e-79d37546ac5d.png"><img alt="Screenshot showing CPU time and MB of memory being used by demo11 query" border="0" height="612" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/df02271c-e8d3-4a46-baee-f44eb44f3246.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="demo11 クエリで使用されている CPU 時間とメモリ MB を示すスクリーンショット" width="1871"></a></p>


  <h2>次の手順</h2>


  <p>Azure Data Explorer、クラウドの弾力性を活用してペタバイトサイズのデータにスケールアウトし、優れたパフォーマンスを示し、高いクエリ ワークロードを処理します。 このブログでは、ダウンサンプリングと&rsquo;集計を実装して、大規模なデータセットに関連するコストを制御する方法について説明しました。</p>


  <p>この方法の詳細についてはAzure Data Explorer次の方法があります。</p>


  <ul>
   <li><a href="https://azure.microsoft.com/services/data-explorer/" target="_blank">今すぐAzure Data Explorer</a> プレビューで試してみてください。</li>
   <li><a href="https://azure.microsoft.com/pricing/details/data-explorer" target="_blank">価格情報を見つける</a> for Azure Data Explorer。</li>
   <li><a href="https://docs.microsoft.com/en-us/azure/data-explorer/" target="_blank">アクセス に関するドキュメント</a> for Azure Data Explorer。</li>
  </ul>
