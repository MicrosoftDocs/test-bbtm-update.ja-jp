### YamlMime:Yaml
ms.openlocfilehash: 5ca287ae4c328a4105ec9ecc6335f22bba796eeb
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139904901"
Slug: create-big-data-pipelines-using-azure-data-lake-store-analytics-azure-data-factory
Title: Azure Data Lake と Azure Data Lake を使用してビッグ データ パイプラインを作成Azure Data Factory
Summary: Microsoft は、新しく拡張された Azure Data Lake を発表し、ビッグ データの処理と分析を簡単かつアクセスしやすくしました。
Content: >-
  <p>今週 <a href="https://blogs.technet.com/b/dataplatforminsider/archive/2015/09/28/microsoft-expands-azure-data-lake-to-unleash-big-data-productivity.aspx" target="_blank">、Microsoft は</a> 、ビッグ データの処理と分析を簡単かつアクセスしやすくする、新しく拡張された Azure Data Lake を発表しました。 拡張された Azure Data Lake には、Azure Data Lake Store、Azure Data Lake Analytics、Azure HDInsight。</p>


  <p>Azure Data Lake Storeは、アプリケーションにデータ スケールとして変更を適用することなく、任意のサイズ、種類、速度のデータを簡単にキャプチャできる単一のリポジトリを提供します。 Azure Data Lake Analyticsは Apache YARN&nbsp; 上に構築された新しいサービスであり、U-SQL(SQL の利点とユーザー コードの表現力を統合する言語) が含まれています。 サービスは動的にスケーリングされます。ビジネス目標に集中できます。 このサービスを使用すると、エンタープライズ レベルのセキュリティを使用して、任意の種類のデータに対して分析を行Azure Active Directory。</p>


  <p>Azure Data Lake Store Pipelines と Azure Data Lake Analytics を使用して、Azure Data Factory でビッグ データ データを作成できるだけでなく、Azure HDInsight の既存のサポートも使用できます。 この機能は、Azure Data Lake Store と Azure Data Lake Analytics年の後半にプレビューで使用できる場合に ADF に追加されます。 次の操作を実行できます。</p>


  <h2><font color="#000000">(ソース) および (シンク) Azure リソースから (シンク) にデータを移動Data Lake Store</font></h2>


  <p>次のソースから <u>Azure リソースに</u>データを移動Data Lake Store。</p>


  <ul>
   <li>Azure BLOB</li>
   <li>Azure SQL データベース</li>
   <li>Azure テーブル</li>
   <li>オンプレミスの SQL Server データベース</li>
   <li>Azure DocumentDB</li>
   <li>Azure SQL DW</li>
   <li>オンプレミスのファイル システム</li>
   <li>オンプレミスの Oracle データベース</li>
   <li>オンプレミスの MYSQL データベース</li>
   <li>オンプレミスの DB2 データベース</li>
   <li>オンプレミスの Teradata データベース</li>
   <li>オンプレミスの Sybase データベース</li>
   <li>オンプレミスの PostgreSQL データベース</li>
   <li>オンプレミスの HDFS</li>
   <li>汎用 OData</li>
   <li>汎用 ODBC</li>
  </ul>


  <p>また、<u>Azure Data Lake Store</u> から多数のシンク viz にデータを移動できます。Azure BLOB、Azure SQL Database、オンプレミスのファイル システムなどです。</p>


  <p>データ ソースを追加し、毎月サポート マトリックスを拡張するために継続的に取り組み中です。 次に例を示します。</p>


  <p>次のパイプラインでは、Azure Blob Storage から Azure Data Lake Storeへのデータ移動を、Azure Data Factory のコピー アクティビティを使用して紹介します。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/90c8681a-f883-4ace-975f-a69dea10a34b.png"><img alt="Data Movement Pipeline" border="0" height="360" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b9845942-6155-4a8b-93f8-0067a2954b4b.png" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; padding-top: 0px; padding-left: 0px; border-left: 0px; display: inline; padding-right: 0px" title="データ移動パイプライン" width="1024"></a></p>


  <h2>E2E ビッグ データ ADF パイプラインを作成し、U-SQLサービスの処理ステップとしてスクリプトをAzure Data Lake Analyticsします</h2>


  <p>たとえば、複数の業界 (小売、金融、ゲーム) の非常に一般的な用途は、ログ処理です。 以下の E2E ビッグ データ ワークフローでは、次の点が示されています。</p>


  <ul>
   <li>Azure Blob Storage から Azure Data Lake Store にログ データを移動する ADF パイプライン。</li>
   <li>ADF パイプラインは、前の手順で Azure Data Lake Store アカウントにコピーされたログを使用し、処理ステップの 1 つとして Azure Data Lake Analytics で U-SQL スクリプトを実行してログを処理します。 このU-SQLは、ダウンストリーム プロセスで使用できるリージョン別のイベントを計算します。</li>
  </ul>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6314a890-a935-4e64-b9a0-06a9021bdbec.png"><img alt="ADF Pipeline" border="0" height="240" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/85ee693b-d2b6-4b95-840f-d5f9b5b2cf54.png" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; padding-top: 0px; padding-left: 0px; border-left: 0px; display: inline; padding-right: 0px" title="ADF パイプライン" width="1024"></a></p>


  <p><br>

  要約すると、Azure Data Factory を使用して E2E ビッグ データ パイプラインを構築できます。このパイプラインを使用すると、多数のソースから Azure Data Lake Store にデータを移動できます。その逆も可能です。 さらに、処理ステップの 1 U-SQL として Azure Data Lake Analytics スクリプトを実行し、ニーズに応じて動的にスケーリングすることができます。 ビッグ データの処理と分析のワークフローを運用可能にするソリューションに引き続き投資します。</p>


  <p><a href="https://technet.microsoft.com/en-us/dn282640">Microsoft Cloud</a> Platform チームの Data Lake Microsoft Azure詳細については、こちらをクリックしてください。 データ ファクトリを使用して簡単かつ迅速Azure Data Factoryパイプラインを構築し<a href="https://azure.microsoft.com/en-us/documentation/services/data-factory/"></a>、データ ファクトリを試す場合は、こちらを参照してください。 機能に関するリクエストがある場合、またはデータ ファクトリに関するフィードバックを提供したい場合は、Azure Data Factory <a href="https://feedback.azure.com/forums/270578-azure-data-factory">してください</a>。</p>
