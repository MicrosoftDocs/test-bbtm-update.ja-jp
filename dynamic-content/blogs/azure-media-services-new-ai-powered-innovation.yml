### YamlMime:Yaml
ms.openlocfilehash: 2eae42778f737d02dd7df6948ad3c11ad896fbfa
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139909987"
Slug: azure-media-services-new-ai-powered-innovation
Title: Azure Media Services AI を活用した新しいイノベーション
Summary: Microsoft のミッションは、地球のすべての人と組織が、より多くの成果を達成する力を与えるという目的です。 メディア業界は、このミッションを例示しています。私たちは、より多くの方法で、およびより多くのデバイスで、より多くのコンテンツが作成および使用されている時代に生き続け、
Content: >-
  <h2>アニメーション化された文字認識、多言語音声の文字起こしなど、</h2>


  <p>Microsoft のミッションは、地球のすべての人と組織が、より多くの成果を達成する力を与えるという目的です。 メディア業界は、このミッションを例示しています。 私たちは、より多くの方法で、およびより多くのデバイスで、より多くのコンテンツが作成および使用されている時代に生き続け、 IBC 2019&rsquo;&rsquo; では、現在取り組んでいる最新のイノベーションと、メディア ワークフローの変革に役立つ方法を共有して、私たちは楽しませていました。 詳細については、9 月 13 日から 17 日までアムステルダムの RAI の Hall 1 ブース C27 で製品チームとパートナーに参加してください。</p>


  <h2>Video Indexer、アニメーションと多言語コンテンツのサポートが追加されます</h2>


  <p>昨年、IBC&rsquo; <a href="https://azure.microsoft.com/en-us/updates/azure-media-services-and-video-indexer/" target="_blank">でAzure Media Services Video Indexer</a>一般提供され、今年はさらに良くなりました。 Video Indexerは、機械学習の専門家である必要なく、メディア ファイルから、音声の単語、顔、感情、トピック、ブランドなどの分析情報とメタデータを自動的に抽出します。 最新のお知らせには、アニメーション化された文字認識と多言語音声の文字起こしに対して要求され差別化された 2 つの機能のプレビューと、Video Indexer で現在利用可能な既存のモデルへのいくつかの追加が含まれます。</p>


  <h2>アニメーション化された文字認識</h2>


  <p>アニメーションコンテンツやキャラクターは最も人気のあるコンテンツの種類の 1 つですが、人間の顔用に構築された標準的な AI ビジョン モデルは、特にコンテンツに人間の特徴のない文字がある場合はうまく機能しません。 この新しいプレビュー ソリューションでは、Video Indexer は Microsofts&rsquo; Azure Custom Vision サービスと力を合体させて、アニメーション化されたキャラクターを自動的に検出して<strong></strong>グループ化し、統合されたカスタム ビジョン モデルを使用<strong></strong>して簡単にタグ付けして認識できる新しいモデル セットを提供します。 これらのモデルは 1 つのパイプラインに統合されています。これにより、すべてのユーザーが以前の機械学習スキルなしでサービスを使用できます。 結果は、独自のアプリケーションに簡単に統合Video IndexerポータルまたはREST APIコードなしポータルを使用して使用できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b84e2ada-e789-4591-8ba0-ff33def5f868.png"><img alt="Image of the AMS Video Indexer recognizing animated characters." border="0" height="530" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/39fbf00e-87ff-4a0b-9768-9b3bf86391bc.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="スポンジ" width="1024"></a></p>


  <p>これらのアニメーション化されたキャラクター モデルは、トレーニングとテストのために実際のアニメーション コンテンツを投稿した一部のお客様と共同で構築しました。 新しい機能の価値は、Viacom International Media Networks &ldquo;の Studio &amp; Post-Production Technology のシニア ディレクターである Andy Gutte gut 氏によって明確に示されています。これは、データ共同作成者の 1 人でした。信頼性の高い AI ベースのアニメーション検出を追加することで、コンテンツ ライブラリから文字メタデータを迅速かつ効率的に検出し、カタログ化することができます。 最も重要なのは、クリエイティブ チームが必要なコンテンツをすぐに見つけ、メディア管理に費やされる時間を最小限に抑え、クリエイティブに集中できる力を与える点です。&rdquo;</p>


  <p>アニメーション化された文字認識の使用を開始するには、ドキュメント <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/animated-characters-recognition" target="_blank">ページを参照してください</a>。</p>


  <h2>多言語での識別と文字起こし</h2>


  <p>ニュース、現在の文化、インタビューなど、一部のメディア資産には、さまざまな言語を使用する話者とのオーディオが含まれているものがあります。 既存の音声テキスト変換機能のほとんどでは、音声認識言語を事前に指定する必要があります。これは、多言語ビデオの文字変換の障害となります。 複数のコンテンツに対する新しい自動音声言語識別機能では、機械学習テクノロジを利用して、メディア資産で使用されるさまざまな言語を識別します。 検出されると、各言語セグメントは識別された言語で自動文字起こしプロセスを行い、すべてのセグメントが複数の言語で構成される 1 つの文字起こしファイルに統合されます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b9004594-bdc8-49f2-b96e-00a08e9ee2b6.png"><img alt="An image of the Video Indexer screen, showing multilingual transcription." src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e558a1e2-090c-41ae-8201-848ba0401f9f.png" style="border: 0px currentcolor; border-image: none; width: 1024px; height: 501px; margin-right: auto; margin-left: auto; display: block; background-image: none;" title="740 ブログ"></a><br>

  結果の文字起こしは、JSON 出力の一Video Indexerクローズド キャプション ファイルの両方として使用できます。 出力トランスクリプトは Azure Search と統合され、さまざまな言語セグメントを動画全体ですぐに検索できます。 さらに、Video Indexer ポータル エクスペリエンスの一部として、複数言語の文字起こしを利用できます。そのため、トランスクリプトと識別された言語を時間別に表示したり、各言語のビデオ内の特定の場所に移動したり、ビデオの再生時にキャプションとして複数言語の文字起こしを確認したりすることができます。 ポータルと API を使用して、出力を 54 の異なる言語に前後に変換することもできます。</p>


  <p>新しい多言語オプションの詳細と、その使い方については、Video Indexer <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/multi-language-identification-transcription" target="_blank">ドキュメントを参照してください</a>。</p>


  <h2>その他の更新および改善されたモデル</h2>


  <p>また、以下を含む、新しいモデルと既存のモデルVideo Indexerを追加しています。</p>


  <h3>人と場所のエンティティの抽出</h3>


  <p>現在&rsquo;のブランド検出機能を拡張し、パリのエトロビエー・サン・ピエーやロンドンのビッグ ベンなど、よく知られている名前と場所も組み込むまで拡張しました。 これらは、光学式文字認識 (OCR) を介して生成されたトランスクリプトまたは画面に表示されると、特定の分析情報が作成されます。 この新しい機能を使用すると、ビデオに表示されたすべてのユーザー、場所、ブランドと、その期間、説明、および詳細については、Bing 検索エンジンへのリンクを確認して検索できます。</p>


  <p>&nbsp;<a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/68c2dedf-9b5c-4ece-a8fc-54aa9639ae46.png"><img alt="Azure Video Indexer entity extraction in the insight pane." border="0" height="403" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4904e33c-386c-4622-85f5-b580b64b106d.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="エンティティの最終" width="1024"></a></p>


  <h3><br>

  編集ショット検出モデル</h3>


  <p>&ldquo;&rdquo;この新機能では、分析情報 JSON の個々のショットにアタッチされたメタデータにタグのセットが追加され、編集の種類 (ワイド ショット、中ショット、クローズ アップ、極端なクローズ アップ、2 ショット、複数の人、屋外と屋内など) が表されます。 これらのショットタイプの特性は、ビデオをクリップやトレーラーに編集する場合や、特定のスタイルのショットを検索して写真を撮影する場合に便利です。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4a311d35-1b5b-46ca-a6fa-58db1f2ff1c8.png"><img alt="Azure Video Indexer editorial shot type example." border="0" height="379" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/179e5ee4-f863-4375-a58f-abc2d88f726a.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="編集ショットの種類の例。" width="1024"></a><br>

  <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/scenes-shots-keyframes" target="_blank">詳細については、編集用のショット</a> の種類の検出に関する記事を参照Video Indexer。</p>


  <h3>IPTC マッピングの粒度の拡張</h3>


  <p>このトピックのインフェレンシング モデルでは、文字起こし、光学式文字認識 (OCR)、検出された著名人に基づいて、ビデオのトピックを決定します(トピックが明示的に指定されていない場合でも)。 これらの推論されたトピックを、Wikipedia、Bing、IPTC、IAB の 4 つの異なる項目にマップします。 この機能強化により、レベル 2 の IPTC 分類が追加されます。</p>


  <p>これらの機能強化の利点は、現在のライブラリにインデックスを再設定するのと同Video Indexerです。</p>


  <h2>新しいライブ ストリーミング機能</h2>


  <p>また、プレビューで 2 つの新しいライブ ストリーミング機能を導入し、Azure Media Services。</p>


  <h3>ライブ文字起こしは、AI を使用してライブ イベントをスーパーチャージします</h3>


  <p>このAzure Media Servicesを使用してライブ イベントをストリーム配信し、ビデオとオーディオのコンテンツに加えて、自動的に生成されたテキスト トラックを含む出力ストリームを取得できます。 このテキスト トラックは、投稿フィードのオーディオの AI ベースのライブ文字起こしを使用して作成されます。 カスタム メソッドは、エンド ユーザー エクスペリエンスを向上させるために、音声テキスト変換の前と後に適用されます。 テキスト トラックは、DASH、HLS CMAF、または HLS TS で配信するかどうかに応じて、IMSC1、TTML、または WebVTT にパッケージ化されます。</p>


  <h3>24 時間 365 日のオーバーザトップ (OTT) チャネルのライブ 線形エンコード</h3>


  <p>v3 API を使用すると、OTT サービスのライブ チャネルを作成、管理、ストリーミングできます。また、ライブ ビデオ オンデマンド (VOD)、パッケージ化、デジタル著作権管理 (DRM) など、Azure Media Services の他のすべての機能を利用できます。</p>


  <p>これらのプレビュー機能を試す場合は、次のページ<a href="https://docs.microsoft.com/en-us/azure/media-services/latest/media-services-community" target="_blank">Azure Media Services Community</a>してください。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5d325469-c5d8-4c18-aab7-7d4cada58e27.png"><img alt="An image showing live transcription signal flow." border="0" height="376" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/914497a4-4138-486c-bbac-1623905ce4ea.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="ライブ エンコード" width="1024"></a></p>


  <h2>新しいパッケージ化機能</h2>


  <h3>オーディオ説明トラックのサポート</h3>


  <p>ブロードキャスト コンテンツには、通常のプログラム オーディオに加えて、画面のアクションに関する逐語的な説明を含むオーディオ トラックが含まれる場合が多い。 これにより、特にコンテンツが非常に視覚的である場合は、視覚障がいのある視聴者がプログラミングにアクセスしやすくなっています。 新しい<a href="https://docs.microsoft.com/en-us/azure/media-services/latest/dynamic-packaging-overview#signaling-audio-description-tracks" target="_blank"></a>オーディオ説明機能を使用すると、お客様はオーディオ トラックの 1 つにオーディオ説明 (AD) トラックとして注釈を付け、プレーヤーが AD トラックを閲覧者が検出可能にできます。</p>


  <h3>ID3 メタデータの挿入</h3>


  <p>広告の挿入またはクライアント プレーヤーでのカスタム メタデータ イベントの挿入をシグナル通知するために、ブロードキャスタはビデオ内に埋め込まれた時間指定メタデータを利用することがよくあります。 SCTE-35 シグナルモードに加えて、クライアント アプリケーションで使用するためにアプリケーション開発者によって定義された <a href="https://docs.microsoft.com/en-us/azure/media-services/media-services-specifications-live-timed-metadata#2-timed-metadata-ingest" target="_blank">ID3v2</a> または他のカスタム スキーマもサポートされています。</p>


  <h2>Microsoft Azureパートナーがエンドツーエンドのソリューションを示す</h2>


  <p><a href="https://bitmovin.com" target="_blank">Bitmovin は</a>、Bitmovin Video Encoding と Bitmovin Video Player を Microsoft Azure。 お客様は、Azure でこれらのエンコードおよびプレーヤー ソリューションを使用し、3 パス エンコード、AV1/VVC コーデックのサポート、多言語クローズド キャプション、QoS、広告、ビデオ追跡用の事前統合ビデオ分析などの高度な機能を利用できます。</p>


  <p><a href="https://www.evergent.com" target="_blank">Evergent は</a> 、Azure 上のユーザー ライフサイクル管理プラットフォームを示しています。 収益および顧客ライフサイクル管理ソリューションの主要プロバイダーである Evergent は、Azure AI を活用して、Premium エンタテインメント サービス プロバイダーが、顧客ライフサイクルの重要なポイントで対象となるパッケージとオファーを生成することで、顧客の獲得とリテンション期間を改善できます。</p>


  <p><a href="https://www.haivision.com" target="_blank">Haivision</a> では、インテリジェント なメディア ルーティング クラウド サービスである SRT Hub を紹介します。これは、Avid、Telestream、Wowza、Cinegy、および Make.tv の Hublets を使用した <a href="https://azure.microsoft.com/en-us/services/databox/" target="_blank">Azure Data Box Edge</a> とメディア ワークフロー変換を使用した取り込みから始まるエンドツーエンドのワークフローを変換するのに役立ちます。</p>


  <p><a href="https://www.ses.com" target="_blank">SES</a> は、サテライト接続とマネージド メディア サービスのお客様向けのブロードキャスト レベルのメディア サービスのスイートを Azure で開発しました。 SES では、マスター プレイアウト、ローカライズされた再生と広告の検出と置換、Azure での 24 時間 365 日の高品質マルチチャネル ライブ エンコードなど、フル マネージドのプレイアウト サービスのソリューションが表示されます。</p>


  <p><a href="https://syncwords.com" target="_blank">SyncWords では</a> 、キャプションオートメーション テクノロジとユーザー に優しいクラウドベースのツールを Azure で使用できます。 これらのオファリングにより、メディア組織は、Azure 上のリアルタイムおよびオフラインのビデオ処理ワークフローに、自動化されたクローズド キャプションと言語の字幕機能を簡単に追加できるようになります。<br>

  &nbsp;<br>

  グローバルな設計およびテクノロジ サービス会社 <a href="https://www.tataelxsi.com" target="_blank">Tata Elxsi</a> は、OTT プラットフォーム SaaS である TEPlay と Azure Media Services を統合して、クラウドから OTT コンテンツを配信しています。 また、Tata Elxsi は、アクション可能なメトリックと分析に焦点を当てたエクスペリエンスの品質 (QoE) 監視ソリューションである、Microsoft Azure。</p>


  <p><a href="https://www.verizondigitalmedia.com/" target="_blank">Verizon Media は</a> 、そのストリーミング プラットフォームを Azure のベータ版で利用できる状態にしています。 Verizon Media Platform は、DRM、広告の挿入、1 対 1 のパーソナライズされたセッション、動的コンテンツの置換、ビデオ配信など、エンタープライズ レベルのマネージド OTT ソリューションです。 この統合により、簡素化されたワークフロー、グローバルなサポートとスケール、Azure で使用できるさまざまな固有の機能へのアクセスが実現されます。</p>


  <p>また、多くのパートナーがブースの会場で発表を行うので、必ず立ち寄ってキャッチしてください。</p>


  <h2>短距離、大きな影響</h2>


  <p><a href="https://4k4charity.com/ibc" target="_blank">4K 4Charity Fun Run</a> をゴールド スポンサーとしてサポートできます。 これは、2014 年からさまざまなメディア業界イベントで開催される実行中および歩くイベントであり、多様性とインクルージョンの増加に重点を置いた非営利団体に対する認識と財務サポートを高めます。 <a href="https://www.cvent.com/events/4k-4charity-fun-run-at-ibc-2019/registration-0848a864b3c947688872e2b718453b59.aspx?fqp=true" target="_blank">登録</a> して、9 月 14 日土曜日の午前 7 時 30 分にアムステルダムの Amstelpark に参加してください。</p>


  <h2>お&rsquo;見逃しなく</h2>


  <p>この&rsquo; IBC の Microsoft ブースでは、さらに多くのことを行っています。 詳細については、お客様とパートナーのコミュニティがメディアや楽楽で Azure でどのようにイノベーションを起こしているのか、またはまだホール 1 のブース C27 に参加してください。 ご利用に&rsquo;<a href="https://vi.microsoft.com/en-us/" target="_blank"></a><a href="https://azure.microsoft.com/en-us/services/media-services/" target="_blank"></a>な&rsquo;&rsquo;れない場合は、申し訳ございませんが、リンクに従ってVideo Indexerを試Azure Media Servicesを試してみてください。</p>
