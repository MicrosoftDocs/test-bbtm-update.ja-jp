### YamlMime:Yaml
ms.openlocfilehash: a2389f51d6b9b1ac9cd4989a06e106e610c80884
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139893468"
Slug: how-is-ai-for-video-different-from-ai-for-images
Title: ビデオの AI と AI がイメージにどのように異なるか
Summary: (AI テクノロジを使用して) ビデオから洞察を抽出すると、イメージと比較して、追加の課題 (および最適化のための機会) が提供されます。 AI がビデオを使用していると誤解しています...
Content: >-
  <p>ビデオから洞察を抽出するか、AI テクノロジを使用すると、イメージと比較して、最適化のための一連の課題と機会が増えます。 ビデオの AI は、ビデオフレームでビデオからフレームを抽出し、コンピューターのビジョンアルゴリズムを実行するだけであると誤解しています。 もちろん、そうすることはできますが、これは本当に後の洞察を得るのには役立ちません。 このブログ投稿では、個々のビデオフレームを処理する方法の欠点について説明するために、いくつかの例を使用します。 これらの欠点を克服するために必要な追加のアルゴリズムの詳細については説明しません。 Video Indexer には、このようなビデオ固有のアルゴリズムがいくつか実装しています。</p>


  <h2>ビデオでの人の有無</h2>


  <p>このビデオの最初の25秒をご覧ください。</p>


  <p><iframe align="center" allowfullscreen="" frameborder="no" height="280" name="azuremediaplayer" scrolling="no" src="//aka.ms/ampembed?url=https%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2F7175d3d0-840c-46c7-b612-829f2db86bbc%2FRuler_PM_Emily.ism%2Fmanifest&amp;autoplay=false" width="500"></iframe></p>


  <p>25秒全体の Doug が存在することに注意してください。</p>


  <p>ビデオに Doug があるときのタイムラインを描画する場合は、次のようになります。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4b2eaeaf-87ab-4ddc-9296-a47e57926e0d.png"><img alt="image" border="0" height="233" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/af8a7441-0f79-49e6-95f0-82b149c40bce.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="絵" width="1200"></a></p>


  <p>&nbsp;</p>


  <p>Doug は常にカメラに接続しているわけではないことに注意してください。 ビデオの7秒は、Emily を見ています。 同じことが23秒で行われます。</p>


  <p>ビデオで顔検出をこれらのタイミングで実行した場合、Doug &rsquo; s フェイスは検出されません (以下のスクリーンショットを参照してください)。</p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f2d791ff-acf0-443b-9d8c-ddf382e99ea3.png"><img alt="image" border="0" height="437" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/26c5916c-705f-422f-b535-d0116eb7db3b.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="絵" width="1193"></a></p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4e7a8216-dc2d-4897-bd06-f6f11e25db2b.png"><img alt="image" border="0" height="443" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a76a9659-b2bc-4ab9-b99e-44204382281c.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="絵" width="1203"></a></p>


  <p>&nbsp;</p>


  <p>つまり、各ビデオフレームで顔検出を行うだけで、上記のようにタイムラインを描画することはできません。 タイムラインを表示するには、ビデオフレーム間で顔を追跡し、その間の顔を並べて表示できるようにする必要があります。 Video Indexer は顔トラッキングを行い、その結果、前に紹介したタイムライン全体が表示されます。</p>


  <h2>光学式文字認識を使用したトピック/キーワードの抽出</h2>


  <p>次の2つのフレームを見てみましょう。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/71f319b5-eac9-4239-8a28-d8b1bd2a56c4.png"><img alt="image" border="0" height="720" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ea4fe55f-e073-4d08-ac7b-567d68e546d5.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="絵" width="886"></a></p>


  <p>この2つのフレームは、プレゼンターがステージ上にあり、バックウォールで imprinted されている Microsoft &rdquo; という言葉 &ldquo; を隠すビデオからのものです。 私たちは、Microsoft &rdquo; という言葉 &ldquo; を知られています。 これら2つのイメージに対して OCR を実行すると、出力として microsc &rdquo; と &ldquo; crosoft &rdquo; が得ら &ldquo; れます。 ビデオクリップ内のフレームの完全なシーケンスを処理する場合は、次のような部分的な単語が多数表示されます。 ノイズを減らし、ショット内の一連のフレームに対して正しい単語を抽出するには、部分的な単語にアルゴリズムを適用する必要があります。 Video Indexer によって、ビデオから洞察を得ることができます。</p>


  <h2>顔認識</h2>


  <p>顔認識システムは、ユーザーごとにトレーニングイメージのセットを使用して構築された face データベースで構成されています。 また、クエリイメージから顔特徴を抽出し、face データベースと照合するジョブを実行するクエリ関数も用意されています。 クエリ関数からの出力は、信頼の値と共に考えられる一致の一覧で構成されます。 クエリ関数の出力の品質は、face データベースとクエリイメージの品質によって異なります。</p>


  <p>ビデオの場合は、複数のビデオフレームがあり、その人がさまざまな顔と照明条件に含まれています。 1つは、ユーザーが存在する各フレームを取得し、顔認識システムにクエリを実行する方法です。 そうすると、異なる信頼の値を持つ face データベースの一致候補の一覧が表示されます。 また、フレームのシーケンス全体で一致する可能性があるという保証もありません。 言い換えると、一致する顔を決定するための追加のロジックレイヤーが必要になります。 また、顔認識システムに対してクエリを実行する適切なフレームのサブセットを選択することで、顔認識システムに対するクエリの数を減らすこともできます。</p>


  <p>また、ビデオでは、複数のビデオフレームのユーザー用に正しいトレーニングイメージを使用して、face データベースを構築し、補強することもできます。 これは、フレーム間でユーザーを追跡するロジックと、バリエーションを評価するヒューリスティックアルゴリズムがある場合に発生する可能性があります。 これにより、提供されたビデオから高品質の face データベースを作成できるように Video Indexer ます。</p>
