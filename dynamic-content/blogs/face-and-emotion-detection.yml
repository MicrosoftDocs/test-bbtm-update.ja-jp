### YamlMime:Yaml
ms.openlocfilehash: a47a88cce646bd961f880ddf4069d42461bc2516
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139910796"
Slug: face-and-emotion-detection
Title: 顔と感情の検出を発表し、Azure Media Analytics
Summary: パブリック プレビュー用の Azure Face Detector Media Processor をお知らせします。
Content: >-
  <p>Azure Media Analyticsは、エンタープライズ規模、コンプライアンス、セキュリティ、グローバルな範囲で提供される音声およびビジョン サービスのコレクションです。 Azure Media Analytics の一部として提供されるサービスは、コア Azure Media Services プラットフォーム コンポーネントを使用して構築されています。そのため、1 日目自体に大規模なメディア処理を処理する準備ができています。 この発表に含まれるその他のメディア プロセッサについては、「In <a href="https://azure.microsoft.com/en-us/blog/introducing-azure-media-analytics" target="_blank">introducing</a> Azure Media Analytics」を参照してください。</p>


  <p>このブログでは、このテクノロジの使用と出力について詳しく説明します。Azure Media Face Detectorの無料パブリック プレビューに関するページを参照してください。 このメディア プロセッサ (MP) は、ユーザーのカウント、移動の追跡、さらに、顔の式を使用した対象ユーザーの参加と反応の測定にも使用できます。 これらの機能には、新しい Azure portal でアクセスするか、以下のプリセットを使用して API を使用するか、無料の Azure Media Services Explorer ツールを使用してアクセスできます。 このサービスには、2 つの機能 (顔検出と感情&rsquo;検出) が含まれているので、その順序で詳細を確認します。</p>


  <h2>顔検出</h2>


  <p>顔検出は、ビデオの中で人の顔を検出して追跡します。 複数の顔を検出した後、画面内の移動を追跡でき、時間と位置のメタデータが JSON ファイルで返されます。 追跡中、この機能は画面内を移動する同じ人の顔には同じ ID をできる限り設定し、顔が遮られたり一瞬フレームの外に出たりしても維持されます。</p>


  <blockquote>

  <p>注: このサービスでは顔認識は実行されない。 顔が遮られたりフレームから外れる時間が長すぎると、戻ったときには新しい ID が設定されます。</p>

  </blockquote>


  <h3>入力プリセット</h3>


  <p>顔&rsquo;検出のための JSON 構成プリセットの例と例を示します。</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>{&quot;version&quot;:&quot;1.0&quot;}</p>


  <h3>入力ビデオ</h3>


  <p><iframe align="center" frameborder="no" height="350" name="azuremediaplayer" scrolling="no" src="//aka.ms/ampembed?url=https%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fc8834d9f-0b49-4b38-bcaf-ece2746f1972%2FMicrosoft%20Convergence%202015%20%20Keynote%20Highlights.ism%2Fmanifest&amp;autoplay=false" width="625"></iframe></p>


  <h3>JSON 出力</h3>


  <p>(切り捨て)</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p><a href="https://nimbuspmblu.blob.core.windows.net/asset-65042ee0-c677-47af-a5f7-b3a10425dae5/Microsoft%20Convergence%202015%20%20Keyn_1280x720_4500_facedetection.json?sv=2012-02-12&amp;sr=c&amp;si=1efac1f3-db57-4ed0-ae66-ed311fda02f3&amp;sig=TvEfqSQB6d8mT7kV7J%2BgfbueQg3TF9BWTDCcdX3JhwQ%3D&amp;se=2026-04-10T18%3A43%3A37Z" target="_blank">完全ダウンロード</a></p>


  <div class="csharpcode-wrapper" id="codeSnippetWrapper">

  <p>{<br>

  &nbsp;&quot;バージョン&quot;: 1、<br>

  &nbsp;&quot;timescale&quot;: 30000、<br>

  &nbsp;&quot;offset&quot;: 0、<br>

  &nbsp;&quot;framerate&quot;: 29.97、<br>

  &nbsp;&quot;width&quot;: 1280、<br>

  &nbsp;&quot;height&quot;: 720、<br>

  &nbsp;&quot;fragments&quot;: [<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;duration&quot;: 60060<br>

  &nbsp;&nbsp;&nbsp; },<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 60060、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;duration&quot;: 60060、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;interval&quot;: 1001、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;events&quot;: [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;id&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;x&quot;: 0.519531、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;y&quot;: 0.180556、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;width&quot;: 0.0867188、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;height&quot;: 0.154167<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;id&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;x&quot;: 0.517969、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;y&quot;: 0.181944、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;width&quot;: 0.0867188、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;height&quot;: 0.154167<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],</p>

  </div>


  <h2>感情検出</h2>


  <p>感情検出は、顔検出 メディア プロセッサのオプションコンポーネントであり、検出された顔から複数の感情属性 (幸せ、悲しみ、恐れ、不安など) に関する分析を返します。 このデータは現在、カスタマイズ可能なウィンドウと間隔でウィンドウ全体の集計値として返されます。</p>


  <h3>入力の構成</h3>


  <p>JSON プリセットのサンプル:</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>{<br>

  &nbsp; &#39;バージョン&#39;: &#39;1.0&#39;、<br>

  &nbsp; &#39;オプション&#39;: {<br>

  &nbsp;&nbsp;&nbsp; &#39;aggregateEmotionWindowMs&#39;: &#39;987&#39;<br>

  &nbsp;&nbsp;&nbsp; &#39;モード&#39;: aggregateEmotion &#39;を&#39;。<br>

  &nbsp;&nbsp;&nbsp; &#39;aggregateEmotionIntervalMs&#39;: &#39;342&#39;<br>

  &nbsp; }<br>

  }</p>


  <table border="0" cellpadding="2" cellspacing="0" width="791">
      <tbody>
          <tr>
              <td valign="top" width="133">
              <p>属性名</p>
              </td>
              <td valign="top" width="677">
              <p>説明</p>
              </td>
          </tr>
          <tr>
              <td valign="top" width="133">モード</td>
              <td valign="top" width="677">Faces: 顔検出のみ<br>
              AggregateEmotion:フレーム内のすべての顔の平均的感情値を返します。</td>
          </tr>
          <tr>
              <td valign="top" width="133">AggregateEmotionWindowMs</td>
              <td valign="top" width="677">AggregateEmotion モードが選択されている場合に使用します。各集計結果の生成に使用されるビデオの長さ (ミリ秒単位)。</td>
          </tr>
          <tr>
              <td valign="top" width="133">AggregateEmotionIntervalMs</td>
              <td valign="top" width="677">AggregateEmotion モードが選択されている場合に使用する: 集計結果を生成する頻度。</td>
          </tr>
      </tbody>
  </table>


  <h3>集計の既定値</h3>


  <p>以下は、集計時間枠と間隔の設定に対して推奨される値です。 ウィンドウは Interval より長くする必要があります。</p>


  <table border="0" cellpadding="2" cellspacing="0" width="400">
      <tbody>
          <tr>
              <td valign="top" width="107">&nbsp;</td>
              <td valign="top" width="107">既定値 ( s)</td>
              <td valign="top" width="97">最大 ( s)</td>
              <td valign="top" width="87">最小 ( s)</td>
          </tr>
          <tr>
              <td valign="top" width="107">ウィンドウの長さ</td>
              <td valign="top" width="107">2</td>
              <td valign="top" width="97">3</td>
              <td valign="top" width="87">1</td>
          </tr>
          <tr>
              <td valign="top" width="107">Interval</td>
              <td valign="top" width="111">0.5</td>
              <td valign="top" width="106">1</td>
              <td valign="top" width="106">0.25</td>
          </tr>
      </tbody>
  </table>


  <h3>出力</h3>


  <p>Aggregate Emotion(truncated) の JSON 出力</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p><a href="https://referencestream-samplestream.streaming.mediaservices.windows.net/2b4a8e81-f2b6-419c-9a1d-0db02cec994c/Microsoft%20Convergence%202015%20%20Keyn_1280x720_4500_aggregateemotion.json" target="_blank">完全ダウンロード</a></p>


  <p>{<br>

  &nbsp;&quot;バージョン&quot;: 1、<br>

  &nbsp;&quot;timescale&quot;: 30000、<br>

  &nbsp;&quot;offset&quot;: 0、<br>

  &nbsp;&quot;framerate&quot;: 29.97、<br>

  &nbsp;&quot;width&quot;: 1280、<br>

  &nbsp;&quot;height&quot;: 720、<br>

  &nbsp;&quot;fragments&quot;: [<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;duration&quot;: 60060、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;interval&quot;: 15015、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;events&quot;: [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;windowFaceDistribution&quot;: {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;neutral&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;最も良&quot;い: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;surprise&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;サディネス&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;anger&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;disgust&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;fear&quot;: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;軽蔑 &quot; : 0<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;windowMeanScores &quot; : {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;ニュートラル &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;しあわせ &quot; 度: 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;驚き &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;悲しみ &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;怒り &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;嫌悪感 &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;心配 &quot; : 0、<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;軽蔑 &quot; : 0<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],</p>


  <h2>出力について</h2>


  <p>顔検出および追跡 API は、高精度の顔位置検出と追跡を行い、ビデオ内で最大 64 個の人の顔を検出できます。 顔が正面を向いているときに最善の結果が得られ、横顔や小さい顔 (24 x 24 ピクセル以下) のときは精度が低下することがあります。</p>


  <p>検出されて追跡される顔に対しては、画像内での顔の位置を示す座標 (左端、上端、幅、高さ、ピクセル単位) と、追跡対象の個人を識別する顔 ID 番号が返されます。 顔 ID 番号は、前向きの顔が失われたりフレーム内で重なったりするとリセットされる場合があり、同じ顔に複数の ID が割り当てられる可能性があります。</p>


  <h3>JSON 参照</h3>


  <p>顔の検出と追跡の操作での出力結果は、顔のメタデータが含まれる JSON 形式ファイルです。</p>


  <p>顔の検出と追跡の JSON には、次の属性が含まれます。</p>


  <ul>
      <li>[<b>バージョン</b>: Video API のバージョンを参照します。</li>
      <li><b>タイムスケール</b>: &ldquo; ビデオの1秒あたりのティック &rdquo; 数。</li>
      <li><b>Offset</b>: タイムスタンプの時間オフセットです。 Video API のバージョン 1.0 では、これは常に 0 になります。 今後サポートされるシナリオでは、変更される可能性があります。</li>
      <li>フレーム<b>レート</b>: ビデオの1秒あたりのフレーム数。</li>
      <li><b>フラグメント</b>: メタデータは、フラグメントと呼ばれるさまざまなセグメントに分割されます。 各フラグメントには、開始、継続時間、間隔数、およびイベントが含まれます。</li>
      <li><b>Start</b>: 最初のイベントの開始時刻 (ティック &rsquo; 単位 &lsquo; )。</li>
      <li><b>Duration</b>: フラグメントの長さ (ティック &rdquo; 単位 &ldquo; )。</li>
      <li><b>Interval</b>: フラグメント内の各イベントエントリの間隔 (ティック &rdquo; 単位 &ldquo; )。</li>
      <li><b>イベント</b>: 各イベントには、その期間内に検出および追跡された顔が含まれます。 これは、イベントの配列の配列です。 外側の配列は、1 つの時間間隔を表します。 内側の配列は、その時点で発生した 0 個以上のイベントで構成されます。 空の角かっこ [] は、顔が検出されなかったことを意味します。</li>
      <li><b>Id</b>: 追跡する顔の id。 この番号は、顔が検出されなくなると変化する可能性があります。 特定の個人にはビデオ全体を通して同じ ID が割り当てられるべきですが、検出アルゴリズム (遮蔽など) の制限により保証できません。</li>
      <li><b>X、y</b>: 0.0 の正規化されたスケールでは、面の境界ボックスの左上の x 座標と y 座標は1.0 になります。
      <ul>
          <li>X 座標と Y 座標は常に横向きに相対的であるため、縦 (または、iOS の場合は反転) のビデオでは、それに応じて座標を入れ替える必要があり&#39;ます。</li>
      </ul>
      </li>
      <li><b>Width</b>、 <b>height</b>: 0.0 の正規化されたスケールでは、面の境界ボックスの幅と高さを1.0 にします。</li>
      <li><b>Facesdetected</b>: これは JSON 結果の最後にあり、ビデオ中にアルゴリズムによって検出された顔の数をまとめたものです。 顔が検出されなくなった場合 (顔が画面から外れる、横を向く、など)、ID が誤ってリセットされることがあるため、この値はビデオ内の顔の正確な数と常に一致しているとは限りません。</li>
  </ul>


  <p>JSON がこのように書式設定された理由は、今後のシナリオで Api を設定することです。ここでは、メタデータを迅速に取得し、大量の結果を管理することが重要になります。 断片化の手法 (時間ベースのチャンクでメタデータを分割し、必要なものだけをダウンロードできます) とセグメント化 (サイズが大きすぎる場合にイベントを分割できるようにする) の両方を使用します。 簡単な計算でデータを変換できます。 たとえば、イベントが 6300 (ティック) に開始し、タイムスケールが 2997 (ティック/秒)、フレームレートが 29.97 (フレーム/秒) である場合、次のようになります。</p>


  <p>&middot; 開始/タイムスケール = 2.1 秒</p>


  <p>&middot; 秒 x (フレームレート/タイムスケール) = 63 フレーム</p>


  <p>顔の検出と追跡のために JSON からフレーム単位の形式を抽出する簡単な例を次に示します。</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>var faceDetectionResultJsonString = operationResult。 ProcessingResult;<br>

  var faceDetecionTracking =<br>

  &nbsp;&nbsp;&nbsp; は、deserializeobject &lt; FaceDetectionResult &gt; (faceDetectionResultJsonString, settings);</p>


  <h2>作業の開始</h2>


  <p>このサービスを使用するには、azure サブスクリプション内に Media Services アカウントを作成し、 <a href="https://azure.microsoft.com/en-us/develop/media-services/">REST API/sdk</a>または &nbsp; <a href="https://aka.ms/amse">Azure Media Services エクスプローラー</a>を使用するだけです。</p>


  <p>サンプルコードについては、 <a href="https://azure.microsoft.com/en-us/documentation/articles/media-services-face-and-emotion-detection/" target="_blank">ドキュメントページ</a>でサンプルコードを確認してください。</p>


  <h3>制限事項</h3>


  <ul>
      <li>サポートされている入力ビデオ形式は、MP4、MOV、WMV です。</li>
      <li>検出可能な顔のサイズは、24 x 24 ～ 2048 x 2048 ピクセルの範囲です。 この範囲から外れる顔は検出されません。</li>
      <li>各ビデオについて、返される顔の最大数は 64 です。</li>
      <li>技術的な課題のために、顔を検出できない場合があります (例: 顔を角度が非常に大きい (頭部姿勢)、遮蔽が大きい)。 顔が正面または正面に近い方向を向いているときに、最善の結果が得られます。</li>
  </ul>


  <h3>お問い合わせ</h3>


  <p><a href="https://azure.microsoft.com/en-us/blog/topics/media-services-2/">Azure Media Services ブログ</a>で、顔検出メディアプロセッサと Media Analytics イニシアチブの詳細についてご紹介します。</p>


  <p>Media Analytics 製品のいずれかについて不明な点がある場合は、に <a href="mailto:amsanalytics@microsoft.com">amsanalytics@microsoft.com</a> 電子メールをお送りください。</p>
