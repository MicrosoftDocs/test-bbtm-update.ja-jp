### YamlMime:Yaml
ms.openlocfilehash: c07a33f066cc31c89a3c8211f0d62371c490ee66
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139904942"
Slug: batch-ai-public-preview
Title: Batch AI プレビューを使用してディープ ラーニングをスケールアップする
Summary: Imagineエポックのトレーニング時間を 30 分から 30 秒に短縮し、多数の異なるハイパーパラメーターの重みを同時にテストします。 パブリック プレビューで利用可能な Batch AI は、Microsoft のデータ サイエンティストが使用するのと同じスケールと柔軟性を備え、ディープ ラーニングや他の AI または機械学習モデルのトレーニングとテストに役立つ新しいサービスです。
Content: >-
  <div style="background:#eee;border:1px solid #ccc;padding:5px 10px;"><strong>更新日: 2018 年 12 月 14 日: </strong>Azure Batch AI機能は、サービスの一部<a href="https://azure.microsoft.com/en-us/services/machine-learning-service/">としてAzure Machine Learning</a>されています。 Azure Batch AIサービスは <a href="https://aka.ms/batchai-retirement">今後数か月間 </a>に廃止される予定です。</div>


  <p>Imagineエポックのトレーニング時間を 30 分から 30 秒に短縮し、多数の異なるハイパーパラメーターの重みを並列でテストします。 パブリック プレビューで利用可能な Batch AI は、Microsoft&rsquo; のデータ サイエンティストが使用するのと同じスケールと柔軟性を備え、ディープ ラーニングや他の AI または機械学習モデルのトレーニングとテストに役立つ新しいサービスです。 GPU のマネージド クラスターを使用すると、大規模なネットワークを設計し、反復時間を短縮し、開発をより簡単かつ生産性を高め、並行して大規模に実験を実行できます。 GPU が必要なときにクラスターを&rsquo;スピンアップし、完了したらクラスターをオフにし、請求を停止します。</p>


  <p>強力な AI の開発には、トレーニング用の大規模なデータ セットと GPU のクラスターを組み合わせて、ハイパーパラメーターのネットワーク設計と最適化を試す必要があります。 サービスとしてのこの機能にアクセスすると、データ サイエンティストや AI 研究者は、より迅速に結果を得て、インフラストラクチャを管理する代わりに、より優れたモデルの構築に集中できます。 ここで、Batch AI Microsoft AI プラットフォームの一部として提供されます。</p>


  <p><em>&quot;ディープ ラーニングの研究者は、ビッグ データを使用して複雑なニューラル ネットワークをトレーニングするために、コンピューティング時間を増やす必要があります。Microsoft Azure の大規模なコンピューティング クラスターは、&#39; の研究者を解決するためのソリューションの 1 つであり、Azure Batch AI はオンプレミスとクラウドの環境を接続するための主要なソリューションになります。優先ネットワークは、Chainer &amp; ChainerMN とこのサービスを統合する方法を楽しみにしています。&quot;</em> &ndash;Preferred Networks, Inc. (Preferred Networks, Inc.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0db5852f-cba9-4fe8-a737-6ffbd4a1d55c.png"><img alt="Secret-to-AI" border="0" height="239" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e9ef631d-ce5f-41ee-b399-1a13e75dea6f.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="シークレットから AI へ" width="640"></a></p>


  <p>Cloud AI Platform のコーポレート バイス プレジデントである The Ignitsh は、最近の Microsoft Ignite カンファレンスで、Azure の AI の包括的なインフラストラクチャ ファミリを持つすべての開発者にクラウド AI を提供する方法、AI 向けのサービス、AI 開発を容易にするツールについて話しました。 Batch AIインフラストラクチャの一部であり、並列トレーニング、テスト、スコア付けのために Azure で簡単に分散されたコンピューティングを実現できます。 必要な数の GPU にスケールアウトします。</p>


  <p>&rsquo;<a href="https://myignite.microsoft.com/videos/56555" target="_blank">「Traineds&rsquo; Ignite</a>」(25 分間) には、データ ラングリング、大規模なトレーニング、Excel でのトレーニング済みの AI モデルの使用に関するエンドツーエンドのエクスペリエンスを示す、素晴らしいデモが用意されています。 このモデルは、最初に Azure の Data Science Virtual Machine <a href="https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/" target="_blank"></a> を使用して開発された後、実験、ハイパーパラメーターチューニング、トレーニングを高速化するためにスケールアウトされました。 Batch AIを使用して、データ サイエンティストはモデルの GPU を 1 から 148 にスケーリングし、エポックあたりのトレーニング時間を 30 分から 30 秒に短縮しました。 これは、何千ものエポックを実行する必要がある場合の生産性に大きな違いを生み出しました。 データ サイエンティストは、ネットワーク設計とハイパーパラメーター値を試し、結果をすばやく確認できます。 このデモの背後にあるコードのバージョンは、Batch AI <a href="https://azure.microsoft.com/en-us/services/machine-learning-services/" target="_blank">および Azure ML Machine Learning Services と Workbench で使用するチュートリアルとして使用できます</a>。</p>


  <h2>使用するBatch AI</h2>


  <p>Batch AIは、AI ワークフローに特化した API とサービスを提供します。 主要な概念はクラスターとジョブです。</p>


  <p>クラスターは、使用するコンピューティング リソースを記述します。 Batch AI有効にする:</p>


  <ul>
   <li>
   <p>必要に応じて GPU または CPU のクラスターをプロビジョニングする</p>
   </li>
   <li>
   <p>コンテナーまたはスクリプトを使用したソフトウェアのインストール</p>
   </li>
   <li>
   <p>コストを管理するための自動または手動スケーリング</p>
   </li>
   <li>
   <p>学習と実験のための優先順位の低い仮想マシンへのアクセス</p>
   </li>
   <li>
   <p>トレーニング データと出力データ用の共有ストレージ ボリュームのマウント</p>
   </li>
  </ul>


  <div>&nbsp;</div>


  <p>ジョブは、パラメーターを使用してコマンド ライン &mdash; を実行するコードです。 Batch AIでは、次の機能がサポートされます。</p>


  <ul>
   <li>
   <p>ディープ ラーニング フレームワークまたは機械学習ツールの使用</p>
   </li>
   <li>
   <p>一般的なフレームワークのオプションの直接構成</p>
   </li>
   <li>
   <p>GPU クォータまたは予約インスタンスを共有する優先順位ベースのジョブ キュー</p>
   </li>
   <li>
   <p>仮想マシンが使用できなくなった場合のジョブの再起動</p>
   </li>
   <li>
   <p>SDK、コマンド ライン、ポータル、ツールの統合</p>
   </li>
  </ul>


  <h2>インテリジェンスのシステムの構築</h2>


  <p>Halliburton Landmark の Yogendra の YogendraYan Pandey 博士 (データ科学者) は、Azure Batch AI と Azure Data Lake を使用して、従来のシミュレーションと比較して、石油フィールド探索の時間とリスクを減らすために、静的な水源モデリング用の予測ディープ ラーニング アルゴリズムを開発しました。 彼は、2017 年のランドマーク イノベーション フォーラム &amp; Expo 2017 で自分の仕事を共有しました。</p>


  <p><em>&ldquo;Azure クラウドの膨大な量のストレージとコンピューティング機能により、予測モデルベースの検出の時代に入っています。Batch AIデータ サイエンティストは、既に知っているツールを簡単に使用できます。モデルAzure Batch AI GPU を使用しない場合、各モデル トレーニング ジョブが完了するために何日もかからずに数時間かかっています。&rdquo;</em></p>


  <p>Batch AI <a href="https://github.com/Azure/BatchAI" target="_blank">には、</a> Azure 仮想マシン、ストレージ、ネットワークの操作の詳細を学習することなく、すぐに始めるのに役立つ一般的な AI フレームワークのレシピが含まれています。 レシピには、Azure CLI インターフェイスで使用するクラスターとジョブ テンプレートと、Python API の使用を示す Jupyter Notebook が含まれています。</p>


  <h2>エンドツーエンドの生産性</h2>


  <p>Batch AIチームは、データ ラングリング、実験管理、トレーニング済みモデルのデプロイ、および ai 用 Visual Studio Code Tools の Azure Machine Learning サービスや Workbench など、Microsoft AI ツールとの統合に取り組まれています。</p>


  <div><br>

  <a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/fc6bf040-410e-4cb5-83cd-330c755db474.png"><img alt="E2E-AI" border="0" height="249" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7509a332-51e5-4744-b6fe-8301f4f58121.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="E2E-AI" width="640"></a></div>


  <div>&nbsp;</div>


  <div>また、世界中のパートナーは、Batch AI を使用して、顧客が Azure と NVIDIA GPU の強力なフリートにトレーニングをスケールアップするのに役立ちます。</div>


  <p><em>&ldquo;私たちは長い間、次のようなサービスを必要Azure Batch AI。ディープ ラーニング エンジニアがディープ ニューラル ネットワークトレーニングハイパー パラメーター検索を高速化する魅力的な &amp; ソリューションです。ディープ&rsquo; ラーニング サービス CSLAYER とディープ ラーニング サービスを統合することで、エンドツーエンドのソリューションを作成Azure Batch AI。&rdquo;</em>&nbsp; &ndash;UeI Corporation の Ceo &amp; である</p>


  <h2>作業の開始</h2>


  <p>Azure でモデルを並列Batch AI大規模にトレーニングする方法を試してみてください。 始める <a href="https://github.com/Azure/BatchAI" target="_blank">のに役立</a> つ一般的な AI フレームワークのサンプル レシピが提供されています。 コストを最小限に抑えるために、優先順位の低い仮想マシンから始めすることをお勧めします。</p>


  <div>

  <p>このBatch AI、トレーニングに使用したコンピューティングとストレージに対してだけ料金を支払います。 クラスター&rsquo;の管理とジョブのスケジュール設定に追加料金はかから"ない"。 GPU を利用する準備が整Batch AI、最もコスト効率の高い方法である低優先度の仮想マシンを使用して学習し、開発します。</p>


  <p>チームは、フィードバックや提案をお寄せください。 Azure&rsquo; Feedback、 <a href="https://feedback.azure.com/forums/905575-batch-ai" target="_blank">Stack Overflow</a> MSDN <a href="https://stackoverflow.com/questions/tagged/azure-batch-ai" target="_blank">、</a>および電子メールでリッスン <a href="mailto:AzureBatchAITrainingPreview@service.microsoft.com ">しています</a>。</p>

  </div>
