### YamlMime:Yaml
ms.openlocfilehash: bd8a083dc927f5b2497adfc40c1621058be0505d
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/11/2022
ms.locfileid: "139892337"
Slug: spoken-language-identification-in-video-indexer
Title: 音声言語識別 (Video Indexer
Summary: 新しい機能である音声Video Indexer識別 (LID) が備わっていません。
Content: >-
  <p>新しい機能である音声Video Indexer識別 (LID) が備わっていません。</p>


  <p>お客様からのよく聞く質問は、手動で言語を指定することなく、ビデオまたはビデオのバッチのインデックス作成を有効にすることでした。 これは、バッチ アップロードで特に重要です。 これをサポートするために、音声による言語の自動識別を導入し、Video Indexer。 識別された言語は、適切な音声テキスト変換モデルを呼び出す場合に使用されます。</p>


  <p>LID は、オーディオに適用される最新のディープ ラーニングに基づいて作成されます。 現在、LID では、英語、中国語、フランス語、ドイツ語、イタリア語、日本語、スペイン語、ロシア語、ポルトガル語を含む 9 つの言語がサポートされています。 高品質から中品質の記録に対して高い精度で動作します。 リストへの言語の追加に取り組むので、ご期待ください。</p>


  <p>の&rsquo; LID の詳細については、以下を参照Video Indexer。</p>


  <h2>VIDEO INDEXER での LID のVideo Indexer</h2>


  <p>LID 機能を使用するには、2 つのオプションがあります。 ポータルを<a href="https://vi.microsoft.com/en-us/">使用する場合</a>は、ビデオのアップロード<strong></strong>時に言語選択コンボ ボックスで [自動検出] を選択できます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/87a063e4-1ea1-4578-8f41-ba3d9c0f90c8.png"><img alt="Fig2" border="0" height="449" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/73b4ce36-42d5-4a84-a87a-ae82b2540bfc.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="Fig2" width="636"></a></p>


  <p>API を使用して <a href="https://api-portal.videoindexer.ai/docs/services/operations/operations/Upload-video?">ビデオを</a> アップロードする場合は、 <strong>言語パラメーターの値として auto</strong> を使用します。</p>


  <p>ルート<strong>/</strong>ビデオ<strong>/</strong>分析情報の下のビデオ インデックス JSON の属性 sourceLanguage <strong>には</strong>、検出された言語と属性 sourceLanguageConfidence が割り当てられます。</p>


  <p><strong><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5f370558-49f3-418f-bd4b-ecf174445f5a.png"><img alt="Fig3" border="0" height="245" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0eb1bdb6-853d-46b7-9103-dcc5927278da.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="Fig3" width="468"></a></strong></p>


  <p>さらに、 <a href="https://api-portal.videoindexer.ai/docs/services/operations/operations/get-video-artifact-download-url/">Artifact 補助 API</a> (型パラメーター値として <strong>languageDetection</strong> を設定) を介した詳細な応答を使用できます。</p>


  <p>成果物には、言語ごとの信頼度が含まれています。これは、言語のサブセット間で信頼度を比較したり、最も可能性の高い複数の言語を識別したりするために役立ちます。 また、複数言語のオーディオを実験するために検出された言語セグメントも提供されます</p>


  <h2>ユーザーへのメモ</h2>


  <ul>
   <li>LID の背後にあるモデルは、ポッドキャスト、講義、チュートリアルなどのブロードキャスト資料やエンタープライズ資料など、明確な録音に最適です。</li>
   <li>このモデルは、ノイズの多い録音、大きなバックグラウンド ミュージックを使用した録音、チャットまたはエコー、低品質の録音、非常にバリアントな音響条件とゆがみ、重いアクセントによって混乱する可能性があります。</li>
   <li>モデルが高い信頼度で結果を生成できない場合、VI は英語に戻されます。</li>
  </ul>


  <h2>背後にある</h2>


  <p>音声による言語識別を含む多くのコグニティブ タスクは、人間にとって簡単ですが、コンピューターでは依然として非常に困難です。 この種のタスクにアプローチする方法の 1 つは、人間の脳を模倣する方法です。 人工ニューラル ネットワークの<strong>最初のアイデアは</strong><a href="https://en.wikipedia.org/wiki/Artificial_neuron">、70 年以上前に提案されました</a>。 この分野の最新技術は Deep <a href="https://en.wikipedia.org/wiki/Deep_learning">ラーニング</a> と呼ばれ、Speech と Language Understanding、Computer Vision の異なるタスクに対して正常に使用され、さらに、スキンがんの診断などの一部のタスクで人間を上回っています。<a href="https://www.nature.com/articles/nature21056.epdf?author_access_token=8oxIcYWf5UNrNpHsUHd2StRgN0jAjWel9jnR3ZoTv0NXpMHRAJy8Qn10ys2O4tuPakXos4UhQAFZ750CsBNMMsISFHIKinKDMKjShCpHIlYPYUHhNzkn6pSnOCt0Ftf6"></a></p>


  <p>VI では、音声言語識別のためのディープ ラーニングの機能を活用します。 ネットワークをトレーニングするには、さまざまな話者から、多様な音響条件を持つ膨大な数の音声例を示します。</p>


  <p>次の図は、ネットワークに対する音声の表現方法を示しています。 この表現は、音声を"スペックグラム" と呼ばれる <a href="https://en.wikipedia.org/wiki/Spectrogram">画像に変換します</a>。 30 秒の音声で 300,000 ピクセルを簡単に必要とすることができるので、スペックグラムを使用すると、音響の複雑さを感じることができます。</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f4706a76-b38c-4a44-b5fc-4ee6aaac9367.png"><img alt="Fig1" border="0" height="311" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f7b9401b-04f5-4199-991d-e84c31210aab.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="Fig1" width="567"></a></p>


  <p><em>凡例: 音声サンプルの音声視覚化。上: <a href="https://en.wikipedia.org/wiki/Waveform">録音</a> されたオーディオの音波表現。下: Spectrogram 表現。</em></p>


  <p>ネットワークは、言語を区別するスペックグラム内のパターンを探して、このような膨大な量のデータから学習します。 良いパターンは、1 つの言語に一般的なパターンです。 ディープ ラーニングは、これらのパターンのランダムな推測から始まります。 その後、各言語の例を使用すると、正しい方向に推測が向上します。 スペイン語のローリング R がスペックグラムでどう見えるかの楽しい<a href="https://lisaloveslinguistics.wordpress.com/2011/03/12/flap-vs-trill-r-vs-%C9%BE/">例を次に示します。&quot; &quot;</a></p>


  <h2>まとめ</h2>


  <p>LID は、主要な言語が知られていないビデオのインデックスを作成する必要がある場合に便利です。 LID は高度なディープ ラーニングモデリングに基づいており、高品質から中品質の記録に最適です。 より多くの音響環境に対応するために、LID を拡張しています。 API の詳細については<a href="https://vi.microsoft.com/">、Video Indexer Web</a> ポータルで LID を試し、<a href="https://aka.ms/viapi"></a>Video Indexer開発者ポータルにアクセスしてください。 LID に関するご意見をお待ちしています。</p>


  <p>質問やフィードバックがある場合や 皆様のご意見をお待ちしております。 UserVoice を使用して、機能に優先順位を付けるか、 に電子メールを送信します <a href="mailto:VISupport@Microsoft.com">VISupport@Microsoft.com</a>。</p>
